{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing with Pandas, part 2\n",
    "\n",
    "This week we will continue developing our skills using [Pandas](https://pandas.pydata.org/) to process real data. \n",
    "\n",
    "## Motivation\n",
    "\n",
    "![Finland April 2019](img/Finland-April-2019.png)\n",
    "*Source: [https://weather.com/news/climate/news/2019-05-20-april-2019-global-temperatures-nasa-noaa](https://weather.com/news/climate/news/2019-05-20-april-2019-global-temperatures-nasa-noaa)*\n",
    "\n",
    "April 2019 was the [second warmest April on record globally](https://weather.com/news/climate/news/2019-05-20-april-2019-global-temperatures-nasa-noaa), and the warmest on record at 13 weather stations in Finland. \n",
    "In this lesson, we will use our data manipulation and analysis skills to analyze weather data from Finland, and investigate the claim that April 2019 was the warmest on record across Finland.\n",
    "\n",
    "Along the way we will cover a number of useful techniques in pandas including:\n",
    "\n",
    "- renaming columns\n",
    "- iterating data frame rows and applying functions\n",
    "- data aggregation\n",
    "- repeating the analysis task for several input files \n",
    "\n",
    "## Input data\n",
    "\n",
    "In the lesson this week we are using weather observation data from Finland [downloaded from NOAA](https://www7.ncdc.noaa.gov/CDO/cdopoemain.cmd?datasetabbv=DS3505&countryabbv=&georegionabbv=&resolution=40). You will be working with data from either 15 or 4 different weather obsercation stations from Finland, depending on your environment. \n",
    "\n",
    "## Downloading the data\n",
    "\n",
    "The first step for today's lesson is to get the data. Which data files you download will depend on the platform you're using for working through the lesson today.\n",
    "\n",
    "### CSC Notebooks users\n",
    "\n",
    "If you're working on the CSC Notebooks platform, you can download the data by opening a new terminal window in Jupyter Lab by going to **File** -> **New** -> **Terminal** in the Jupyter Lab menu bar. Once the terminal is open, you will need to navigate to the directory for Lesson 6 by typing\n",
    "\n",
    "```bash\n",
    "cd notebooks/notebooks/L6/\n",
    "```\n",
    "\n",
    "Once in the correct directory, you can confirm this by typing\n",
    "\n",
    "```bash\n",
    "ls\n",
    "```\n",
    "\n",
    "You should see something like the following output:\n",
    "\n",
    "```bash\n",
    "advanced-data-processing-with-pandas.ipynb errors.ipynb                               img\n",
    "debugging.ipynb                            gcp-assertions.ipynb\n",
    "```\n",
    "\n",
    "If so, you're in the correct directory and you can download the data files by typing\n",
    "\n",
    "```bash\n",
    "wget https://davewhipp.github.io/data/Finland-weather-data-CSC.tar.gz\n",
    "```\n",
    "\n",
    "After the download completes, you can extract the data files by typing\n",
    "\n",
    "```bash\n",
    "tar zxvf Finland-weather-data-CSC.tar.gz\n",
    "```\n",
    "\n",
    "At this stage you should have a new directory called `data` that contains the data for this week's lesson. You can confirm this by typing\n",
    "\n",
    "```bash\n",
    "ls data\n",
    "```\n",
    "\n",
    "You should see something like the following:\n",
    "\n",
    "```bash\n",
    "029440.txt           029720.txt           3505doc.txt          6367598020644stn.txt\n",
    "029700.txt           029740.txt           6367598020644inv.txt\n",
    "```\n",
    "\n",
    "Now you should be all set to proceed with the lesson!\n",
    "\n",
    "### Users with Jupyter on their personal computers\n",
    "\n",
    "If you're working on your own computer, you can download the data by opening a new terminal window in Jupyter Lab by going to **File** -> **New** -> **Terminal** in the Jupyter Lab menu bar. Once the terminal is open, you will need to navigate to the directory for Lesson 6 by typing\n",
    "\n",
    "```bash\n",
    "cd path/to/L6/\n",
    "```\n",
    "\n",
    "where `path/to/` should be replaced with the directories needed to locate the Lesson 6 materials in on your computer. Once in the correct directory, you can confirm this by typing\n",
    "\n",
    "```bash\n",
    "ls\n",
    "```\n",
    "\n",
    "You should see something like the following output:\n",
    "\n",
    "```bash\n",
    "advanced-data-processing-with-pandas.ipynb errors.ipynb                               img\n",
    "debugging.ipynb                            gcp-assertions.ipynb\n",
    "```\n",
    "\n",
    "If so, you're in the correct directory and you can download the data files by typing\n",
    "\n",
    "```bash\n",
    "wget https://davewhipp.github.io/data/Finland-weather-data-full.tar.gz\n",
    "```\n",
    "\n",
    "After the download completes, you can extract the data files by typing\n",
    "\n",
    "```bash\n",
    "tar zxvf Finland-weather-data-full.tar.gz\n",
    "```\n",
    "\n",
    "At this stage you should have a new directory called `data` that contains the data for this week's lesson. You can confirm this by typing\n",
    "\n",
    "```bash\n",
    "ls data\n",
    "```\n",
    "\n",
    "You should see something like the following:\n",
    "\n",
    "```bash\n",
    "028360.txt           029070.txt           029440.txt           029740.txt  6367598020644inv.txt\n",
    "028690.txt           029110.txt           029500.txt           029810.txt  6367598020644stn.txt\n",
    "028750.txt           029170.txt           029700.txt           029820.txt\n",
    "028970.txt           029350.txt           029720.txt           3505doc.txt\n",
    "```\n",
    "\n",
    "Now you should be all set to proceed with the lesson!\n",
    "\n",
    "### Binder users\n",
    "\n",
    "It is not recommended to complete this lesson using Binder.\n",
    "\n",
    "## About the data\n",
    "\n",
    "As part of the download there are a number of files that describe the weather data. These *metadata* files include:\n",
    "\n",
    "- A list of stations\\*: [data/6367598020644stn.txt](metadata/6367598020644stn.txt)\n",
    "- Details about weather observations at each station: [data/6367598020644inv.txt](metadata/6367598020644inv.txt)\n",
    "- A data description (i.e., column names): [data/3505doc.txt](metadata/3505doc.txt)\n",
    "\n",
    "\\*Note that the list of stations is for all 15 stations, even if you're working with only the 4 stations on the CSC Notebooks platform.\n",
    "\n",
    "The input data for this week are separated with varying number of spaces (i.e., fixed width). The first lines and columns of the data look like following:\n",
    "\n",
    "``` \n",
    "  USAF  WBAN YR--MODAHRMN DIR SPD GUS CLG SKC L M H  VSB MW MW MW MW AW AW AW AW W TEMP DEWP    SLP   ALT    STP MAX MIN PCP01 PCP06 PCP24 PCPXX SD\n",
    "029440 99999 190601010600 090   7 *** *** OVC * * *  0.0 ** ** ** ** ** ** ** ** *   27 **** 1011.0 ***** ****** *** *** ***** ***** ***** ***** ** \n",
    "029440 99999 190601011300 ***   0 *** *** OVC * * *  0.0 ** ** ** ** ** ** ** ** *   27 **** 1015.5 ***** ****** *** *** ***** ***** ***** ***** ** \n",
    "029440 99999 190601012000 ***   0 *** *** OVC * * *  0.0 ** ** ** ** ** ** ** ** *   25 **** 1016.2 ***** ****** *** *** ***** ***** ***** ***** ** \n",
    "029440 99999 190601020600 ***   0 *** *** CLR * * *  0.0 ** ** ** ** ** ** ** ** *   26 **** 1016.2 ***** ****** *** *** ***** ***** ***** ***** **\n",
    "```\n",
    "\n",
    "We will develop our analysis workflow using data for a single station. Then, we will repeat the same process for all the stations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data\n",
    "\n",
    "In order to get started, let's import pandas: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you can already have a quick look at the input file `029440.txt` for Tampere Pirkkala and how it is structured. We can notice at least two things we need to consider when reading in the data:\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**NOTE: Input data structure**\n",
    "\n",
    "- **Delimiter:** The data are **separated with varying amount of spaces**. If you check out the documentation for the [read_csv() method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html), you can see that there are two different ways of doing this. We can either use the `sep` or `delim_whitespace` parameter;  `sep='\\s+'` or `delim_whitespace=True` but not both. In this case, we prefer to use `delim_whitespace`.\n",
    "\n",
    "- **No Data values:** No data values in the NOAA data are coded with varyingg number of `*`. We can tell pandas to consider those characters as NaNs by specifying `na_values=['*', '**', '***', '****', '*****', '******']`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\HYapp\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (29,30,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "fp = r\"data/029440.txt\"\n",
    "\n",
    "# Read data using varying amount of spaces as separator and specifying * characters as NoData values\n",
    "data = pd.read_csv(fp, delim_whitespace=True, na_values=['*', '**', '***', '****', '*****', '******'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's see how the data looks by printing the first five rows with the `head()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    USAF   WBAN  YR--MODAHRMN    DIR  SPD  GUS  CLG  SKC   L   M ...     SLP  \\\n",
      "0  29440  99999  190601010600   90.0  7.0  NaN  NaN  OVC NaN NaN ...  1011.0   \n",
      "1  29440  99999  190601011300    NaN  0.0  NaN  NaN  OVC NaN NaN ...  1015.5   \n",
      "2  29440  99999  190601012000    NaN  0.0  NaN  NaN  OVC NaN NaN ...  1016.2   \n",
      "3  29440  99999  190601020600    NaN  0.0  NaN  NaN  CLR NaN NaN ...  1016.2   \n",
      "4  29440  99999  190601021300  270.0  7.0  NaN  NaN  OVC NaN NaN ...  1015.6   \n",
      "\n",
      "   ALT  STP  MAX  MIN  PCP01  PCP06  PCP24  PCPXX  SD  \n",
      "0  NaN  NaN  NaN  NaN    NaN    NaN    NaN    NaN NaN  \n",
      "1  NaN  NaN  NaN  NaN    NaN    NaN    NaN    NaN NaN  \n",
      "2  NaN  NaN  NaN  NaN    NaN    NaN    NaN    NaN NaN  \n",
      "3  NaN  NaN  NaN  NaN    NaN    NaN    NaN    NaN NaN  \n",
      "4  NaN  NaN  NaN  NaN    NaN    NaN    NaN    NaN NaN  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All seems ok. However, we won't be needing all of the 33 columns for detecting warm temperatures in April. We can check all column names by running `data.columns`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['USAF', 'WBAN', 'YR--MODAHRMN', 'DIR', 'SPD', 'GUS', 'CLG', 'SKC', 'L',\n",
       "       'M', 'H', 'VSB', 'MW', 'MW.1', 'MW.2', 'MW.3', 'AW', 'AW.1', 'AW.2',\n",
       "       'AW.3', 'W', 'TEMP', 'DEWP', 'SLP', 'ALT', 'STP', 'MAX', 'MIN', 'PCP01',\n",
       "       'PCP06', 'PCP24', 'PCPXX', 'SD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A description for all these columns is available in the metadata file [data/3505doc.txt](metadata/3505doc.txt). \n",
    "\n",
    "**Let's read in the data one more time.** This time, we will read in only some of the columns using the `usecols` parameter. Let's read in columns that might be somehow useful to our analysis, or at least that contain some values that are meaningful to us, including the station name, timestamp, and data about wind and temperature: `'USAF','YR--MODAHRMN', 'DIR', 'SPD', 'GUS','TEMP', 'MAX', 'MIN'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USAF</th>\n",
       "      <th>YR--MODAHRMN</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPD</th>\n",
       "      <th>GUS</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601010600</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601011300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601012000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601020600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601021300</td>\n",
       "      <td>270.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    USAF  YR--MODAHRMN    DIR  SPD  GUS  TEMP  MAX  MIN\n",
       "0  29440  190601010600   90.0  7.0  NaN  27.0  NaN  NaN\n",
       "1  29440  190601011300    NaN  0.0  NaN  27.0  NaN  NaN\n",
       "2  29440  190601012000    NaN  0.0  NaN  25.0  NaN  NaN\n",
       "3  29440  190601020600    NaN  0.0  NaN  26.0  NaN  NaN\n",
       "4  29440  190601021300  270.0  7.0  NaN  27.0  NaN  NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(fp, delim_whitespace=True, usecols=['USAF','YR--MODAHRMN', 'DIR', 'SPD', 'GUS','TEMP', 'MAX', 'MIN'], na_values=['*', '**', '***', '****', '*****', '******'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so we can see that the data was successfully read to the DataFrame and we also seemed to be able to convert the asterisk (\\*) characters into `NaN` values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming columns\n",
    "\n",
    "Check again the column names in our DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['USAF', 'YR--MODAHRMN', 'DIR', 'SPD', 'GUS', 'TEMP', 'MAX', 'MIN'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names that we have are somewhat ackward. Let's change them into more intuitive ones. \n",
    "This can be done easily using the `rename()` method and a dictionary that lists old and new column names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Dictionaries**\n",
    "\n",
    "[Dictionary](https://docs.python.org/2/tutorial/datastructures.html#dictionaries) is a spesific data structure in Python for storing key-value pairs. During this course, we will use dictionaries mainly when renaming columns in a pandas series, but dictionaries are useful for many different purposes! For more information about Python dictionaries, check out [this tutorial](https://realpython.com/python-dicts/).\n",
    "    \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define the new column names using a [dictionary](https://www.tutorialspoint.com/python/python_dictionary.htm) where we determine \"`key: value`\" -pairs, in which the original column name (the one which will be replaced) is the key, and the new column name is the value.\n",
    "\n",
    "- Let's change:\n",
    "   \n",
    "   - `YR--MODAHRMN` column into `TIME`, \n",
    "   - `SPD` into `SPEED`, and\n",
    "   - `GUS` into `GUST`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SPD': 'SPEED', 'YR--MODAHRMN': 'TIME', 'GUS': 'GUST'}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Create the dictionary with old and new names\n",
    "new_names = {'YR--MODAHRMN': 'TIME', 'SPD': 'SPEED', 'GUS': 'GUST'}\n",
    "\n",
    "# Let's see what they look like and what is the type\n",
    "print(new_names)\n",
    "print(type(new_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above we can see that we have successfully created a dictionary that is of type `dict`. \n",
    "\n",
    "- Now we can change the column names by passing that dictionary into parameter `columns` in `rename()` -function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['USAF', 'TIME', 'DIR', 'SPEED', 'GUST', 'TEMP', 'MAX', 'MIN'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Rename the columns\n",
    "data = data.rename(columns=new_names)\n",
    "\n",
    "# Print the new columns\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect, now our column names are more easy to understand and use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**TASK: Renaming columns**\n",
    "\n",
    "The temperature values are again in Fahrenheit. As you might guess, we will soon convert these temperatures in to Celsius. In order to avoid confusion with the columns, rename column `TEMP` into `TEMP_F`. Also, we could rename `USAF` as`STATION_NUMBER`.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_NUMBER</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>GUST</th>\n",
       "      <th>TEMP_F</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601010600</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601011300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601012000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601020600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601021300</td>\n",
       "      <td>270.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATION_NUMBER          TIME    DIR  SPEED  GUST  TEMP_F  MAX  MIN\n",
       "0           29440  190601010600   90.0    7.0   NaN    27.0  NaN  NaN\n",
       "1           29440  190601011300    NaN    0.0   NaN    27.0  NaN  NaN\n",
       "2           29440  190601012000    NaN    0.0   NaN    25.0  NaN  NaN\n",
       "3           29440  190601020600    NaN    0.0   NaN    26.0  NaN  NaN\n",
       "4           29440  190601021300  270.0    7.0   NaN    27.0  NaN  NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the dictionary with old and new names\n",
    "new_names = {'USAF':'STATION_NUMBER', 'TEMP': 'TEMP_F'}\n",
    "\n",
    "# Rename the columns\n",
    "data = data.rename(columns=new_names)\n",
    "\n",
    "# Check the output\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check dataframe properties\n",
    "\n",
    "As we learned last week, it's always a good idea to check basic properties of the input data before proceeding with data analysis. Let's check:\n",
    "\n",
    "- How many rows and columns we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(757983, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Top and bottom rows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_NUMBER</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>GUST</th>\n",
       "      <th>TEMP_F</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601010600</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601011300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601012000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601020600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601021300</td>\n",
       "      <td>270.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATION_NUMBER          TIME    DIR  SPEED  GUST  TEMP_F  MAX  MIN\n",
       "0           29440  190601010600   90.0    7.0   NaN    27.0  NaN  NaN\n",
       "1           29440  190601011300    NaN    0.0   NaN    27.0  NaN  NaN\n",
       "2           29440  190601012000    NaN    0.0   NaN    25.0  NaN  NaN\n",
       "3           29440  190601020600    NaN    0.0   NaN    26.0  NaN  NaN\n",
       "4           29440  190601021300  270.0    7.0   NaN    27.0  NaN  NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_NUMBER</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>GUST</th>\n",
       "      <th>TEMP_F</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>757978</th>\n",
       "      <td>29440</td>\n",
       "      <td>201910012220</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757979</th>\n",
       "      <td>29440</td>\n",
       "      <td>201910012250</td>\n",
       "      <td>110.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757980</th>\n",
       "      <td>29440</td>\n",
       "      <td>201910012300</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757981</th>\n",
       "      <td>29440</td>\n",
       "      <td>201910012320</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757982</th>\n",
       "      <td>29440</td>\n",
       "      <td>201910012350</td>\n",
       "      <td>110.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        STATION_NUMBER          TIME    DIR  SPEED  GUST  TEMP_F  MAX  MIN\n",
       "757978           29440  201910012220  130.0    3.0   NaN    39.0  NaN  NaN\n",
       "757979           29440  201910012250  110.0    3.0   NaN    37.0  NaN  NaN\n",
       "757980           29440  201910012300  100.0    2.0   NaN    38.0  NaN  NaN\n",
       "757981           29440  201910012320  100.0    3.0   NaN    37.0  NaN  NaN\n",
       "757982           29440  201910012350  110.0    3.0   NaN    37.0  NaN  NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data types of the columns: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATION_NUMBER      int64\n",
       "TIME                int64\n",
       "DIR               float64\n",
       "SPEED             float64\n",
       "GUST              float64\n",
       "TEMP_F            float64\n",
       "MAX               float64\n",
       "MIN               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Descriptive statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       STATION_NUMBER          TIME            DIR          SPEED  \\\n",
      "count        757983.0  7.579830e+05  699256.000000  750143.000000   \n",
      "mean          29440.0  1.999974e+11     233.499846       6.742641   \n",
      "std               0.0  1.629544e+09     209.707258       4.296191   \n",
      "min           29440.0  1.906010e+11      10.000000       0.000000   \n",
      "25%           29440.0  1.989083e+11     130.000000       3.000000   \n",
      "50%           29440.0  2.004042e+11     200.000000       7.000000   \n",
      "75%           29440.0  2.012050e+11     270.000000       9.000000   \n",
      "max           29440.0  2.019100e+11     990.000000      61.000000   \n",
      "\n",
      "               GUST         TEMP_F           MAX           MIN  \n",
      "count  19906.000000  754862.000000  23869.000000  23268.000000  \n",
      "mean      20.147996      40.409778     45.373539     35.783737  \n",
      "std        7.415138      17.898715     18.242679     17.195427  \n",
      "min       11.000000     -33.000000    -26.000000    -32.000000  \n",
      "25%       14.000000      29.000000     32.000000     26.000000  \n",
      "50%       18.000000      39.000000     44.000000     36.000000  \n",
      "75%       26.000000      54.000000     60.000000     49.000000  \n",
      "max      108.000000      91.000000     91.000000     81.000000  \n"
     ]
    }
   ],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that there are varying number of observations per column (see the `count` information), because some of the columns have missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using your own functions in pandas \n",
    "\n",
    "Now it's again time to convert temperatures from Fahrenheit to Celsius! Yes, we have already done this many times before, but this time we will learn how to apply self-made functions to data in a pandas DataFrame.\n",
    "**In short, our task is to define a function for the temperature conversion, and to apply this function for each Celsius value on each row of the DataFrame. Output celsius values should be stored in a new column called** `TEMP_C`.\n",
    "\n",
    "Knowing how to use your own function in pandas can be really useful when doing your own analyses. Here, we will introduce two different approaches for using function in pandas. First, we will see how we can apply the function row-by-row using a `for`-loop and the `DataFrame.iterrows()`-method, and then we will learn how to apply the method to all rows at once using [DataFrame.apply](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.apply.html).\n",
    "\n",
    "For both of these approaches, we first need to define our temperature conversion function from Fahrenheit to Celsius:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fahr_to_celsius(temp_fahrenheit):\n",
    "    \"\"\"\n",
    "    Function to convert Fahrenheit temperature into Celsius.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    temp_fahrenheit: int | float\n",
    "        Input temperature in Fahrenheit (should be a number)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    Temperature in Celsius (float)\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the Fahrenheit into Celsius and return it\n",
    "    converted_temp = (temp_fahrenheit - 32) / 1.8\n",
    "    return converted_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** with such a simple example, we could use the function direcly on a column in the DataFrame in order to conver the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_NUMBER</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>GUST</th>\n",
       "      <th>TEMP_F</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>TEMP_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601010600</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601011300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601012000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601020600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601021300</td>\n",
       "      <td>270.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATION_NUMBER          TIME    DIR  SPEED  GUST  TEMP_F  MAX  MIN  \\\n",
       "0           29440  190601010600   90.0    7.0   NaN    27.0  NaN  NaN   \n",
       "1           29440  190601011300    NaN    0.0   NaN    27.0  NaN  NaN   \n",
       "2           29440  190601012000    NaN    0.0   NaN    25.0  NaN  NaN   \n",
       "3           29440  190601020600    NaN    0.0   NaN    26.0  NaN  NaN   \n",
       "4           29440  190601021300  270.0    7.0   NaN    27.0  NaN  NaN   \n",
       "\n",
       "     TEMP_C  \n",
       "0 -2.777778  \n",
       "1 -2.777778  \n",
       "2 -3.888889  \n",
       "3 -3.333333  \n",
       "4 -2.777778  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"TEMP_C\"] = fahr_to_celsius(data[\"TEMP_F\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to do something more complicated, we need to know how to apply the function row-by-row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over rows\n",
    "\n",
    "We can iterate over the rows of Pandas DataFrame by using the `iterrows()` -method and use the function one row at a time.\n",
    "\n",
    "\n",
    "When iterating over the rows in our `DataFrame`, it is noteworthy to understand that pandas actually keeps track on the `index` value as well. Hence, the contents of a single row actually contains not only the values, but also the `index` of that row (each row is a pandas Series!). \n",
    "\n",
    "- Let's see how `iterrows()` works by printing out the `TEMP` value on each row using a `for`-loop:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0\n",
      "Temp F: 27.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the rows\n",
    "for idx, row in data.iterrows():\n",
    "    # Print the index value\n",
    "    print('Index:', idx)\n",
    "    \n",
    "    # Print the row\n",
    "    print('Temp F:', row[\"TEMP_F\"], \"\\n\")\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**break**\n",
    "\n",
    "When developing a for-loop, you don't always need to go trough the whole loop if you just want to test things out. \n",
    "[break](https://www.tutorialspoint.com/python/python_break_statement.htm) statement in Python terminates the current loop after the first iteration and we used it here just to test check out the values on the first row.\n",
    "With a large data, you might not want to print out thousands of values to the screen!\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the `idx` variable indeed contains the index value at position 0 (the first row) and the `row` variable contains all the data from that given row stored as a pandas `Series`.\n",
    "\n",
    "- Let's now create an empty column `TEMP_C` for the Celsius temperatures and update the values into that column using the `fahr_to_celsius` function we defined earlier:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty column for the DataFrame where the values will be stored\n",
    "new_column = \"TEMP_C\"\n",
    "data[new_column] = None\n",
    "\n",
    "# Iterate over the rows \n",
    "for idx, row in data.iterrows():\n",
    "    # Convert the Fahrenheit to Celsius\n",
    "    celsius = fahr_to_celsius(row['TEMP_F'])\n",
    "    \n",
    "    # Update the value of 'Celsius' column with the converted value\n",
    "    data.at[idx, new_column] = celsius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Reminder: .at or .loc?**\n",
    "\n",
    "Here, you could also use `data.loc[idx, new_column] = celsius` to achieve the same result. \n",
    "    \n",
    "If you only need to access a single value in a DataFrame, [DataFrame.at](https://pandas.pydata.org/pandas-docs/version/0.25/reference/api/pandas.DataFrame.at.html) is faster compared to [DataFrame.loc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html) which is designed for accessing groups of rows and columns. \n",
    "\n",
    "Check out more examples for using `.at` and `.loc` from lesson 5 materials.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's see what we have now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_NUMBER</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>GUST</th>\n",
       "      <th>TEMP_F</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>TEMP_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601010600</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.77778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601011300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.77778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601012000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.88889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601020600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.33333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601021300</td>\n",
       "      <td>270.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.77778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601022000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.77778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601030600</td>\n",
       "      <td>270.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.33333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601031300</td>\n",
       "      <td>270.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.88889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601032000</td>\n",
       "      <td>270.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.44444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601040600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.77778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATION_NUMBER          TIME    DIR  SPEED  GUST  TEMP_F  MAX  MIN   TEMP_C\n",
       "0           29440  190601010600   90.0    7.0   NaN    27.0  NaN  NaN -2.77778\n",
       "1           29440  190601011300    NaN    0.0   NaN    27.0  NaN  NaN -2.77778\n",
       "2           29440  190601012000    NaN    0.0   NaN    25.0  NaN  NaN -3.88889\n",
       "3           29440  190601020600    NaN    0.0   NaN    26.0  NaN  NaN -3.33333\n",
       "4           29440  190601021300  270.0    7.0   NaN    27.0  NaN  NaN -2.77778\n",
       "5           29440  190601022000    NaN    0.0   NaN    27.0  NaN  NaN -2.77778\n",
       "6           29440  190601030600  270.0    7.0   NaN    26.0  NaN  NaN -3.33333\n",
       "7           29440  190601031300  270.0    7.0   NaN    25.0  NaN  NaN -3.88889\n",
       "8           29440  190601032000  270.0    7.0   NaN    24.0  NaN  NaN -4.44444\n",
       "9           29440  190601040600    NaN    0.0   NaN    18.0  NaN  NaN -7.77778"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we have converted our temperatures into Celsius by using our self-made function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas DataFrames and Series also have a dedicated method `.apply()` for applying functions on columns (or rows!). When using `.apply()`, we pass the function name (without parenthesis!) as an argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_NUMBER</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>GUST</th>\n",
       "      <th>TEMP_F</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>TEMP_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601010600</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601011300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601012000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601020600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601021300</td>\n",
       "      <td>270.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATION_NUMBER          TIME    DIR  SPEED  GUST  TEMP_F  MAX  MIN  \\\n",
       "0           29440  190601010600   90.0    7.0   NaN    27.0  NaN  NaN   \n",
       "1           29440  190601011300    NaN    0.0   NaN    27.0  NaN  NaN   \n",
       "2           29440  190601012000    NaN    0.0   NaN    25.0  NaN  NaN   \n",
       "3           29440  190601020600    NaN    0.0   NaN    26.0  NaN  NaN   \n",
       "4           29440  190601021300  270.0    7.0   NaN    27.0  NaN  NaN   \n",
       "\n",
       "     TEMP_C  \n",
       "0 -2.777778  \n",
       "1 -2.777778  \n",
       "2 -3.888889  \n",
       "3 -3.333333  \n",
       "4 -2.777778  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"TEMP_C\"] = data[\"TEMP_F\"].apply(fahr_to_celsius)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** pay attention which column you are applying the function on! Running this code: `data.apply(fahr_to_celsius)` would not give an error, but the results also don't make much sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Should I use .iterrows() or .apply()?**\n",
    "\n",
    "We are teaching the `.iterrows()` method because it helps to understand the structure of a DataFrame and the process of looping trough DataFrame rows. However, using `.apply()` is often more efficient in terms of execution time. \n",
    "    \n",
    "    \n",
    "At this point, the most important thing is that you understand what happens when you are modifying the values in a pandas DataFrame. When doing the course exercises, either of these approaches is ok!\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing dates\n",
    "\n",
    "We will eventually want to group our data based on month in order to see if April temperatures in 2019 were higher than average. Currently, the date and time information is stored in the column `TIME`:\n",
    "\n",
    "`YR--MODAHRMN = YEAR-MONTH-DAY-HOUR-MINUTE IN GREENWICH MEAN TIME (GMT)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a closer look at the date and time information we have by checking the values in that column, and their data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    190601010600\n",
       "1    190601011300\n",
       "2    190601012000\n",
       "3    190601020600\n",
       "4    190601021300\n",
       "5    190601022000\n",
       "6    190601030600\n",
       "7    190601031300\n",
       "8    190601032000\n",
       "9    190601040600\n",
       "Name: TIME, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"TIME\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "757973    201910012050\n",
       "757974    201910012100\n",
       "757975    201910012120\n",
       "757976    201910012150\n",
       "757977    201910012200\n",
       "757978    201910012220\n",
       "757979    201910012250\n",
       "757980    201910012300\n",
       "757981    201910012320\n",
       "757982    201910012350\n",
       "Name: TIME, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"TIME\"].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `TIME` column contains several observations per day (and even several observations per hour). The timestamp for the first observation is `190601010600`, i.e. from 1st of January 1906 (way back!), and the timestamp for the latest observation is `201910012350` (from last week, by the time of writing this!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"TIME\"].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the information is stored as integer values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several different options for proceeding from here. The bottom line is, that we would want to **aggregate the data on a monthly level**, and in order to do so we need to \"label\" each row of data based on the month when the record was observed. \n",
    "In practice, we could create a new column (or an index), which contains information about the month (including the year, but excluding days, hours and minutes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String slicing\n",
    "\n",
    "One approach would be to convert the date and time information into character strings and \"cut\" the needed information from the [string objects](https://docs.python.org/3/tutorial/introduction.html#strings). If we look at the latest time stamp in the data (`201910012350`), you can see that there is a systematic pattern `YEAR-MONTH-DAY-HOUR-MINUTE`. Four first characters represent the year, and six first characters are year + month!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'201910'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = \"201910012350\"\n",
    "date[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing this in pandas requires two steps:\n",
    "  1. Convert the `TIME` column from `int` into `str` datatype.\n",
    "  2. Slice the correct range of characters from the character string using [pandas.Series.str.slice()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.slice.html)\n",
    "\n",
    "- Let's convert the time into string. And check that the data type changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Convert to string\n",
    "data['TIME_STR'] = data['TIME'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   STATION_NUMBER          TIME    DIR  SPEED  GUST  TEMP_F  MAX  MIN  \\\n",
      "0           29440  190601010600   90.0    7.0   NaN    27.0  NaN  NaN   \n",
      "1           29440  190601011300    NaN    0.0   NaN    27.0  NaN  NaN   \n",
      "2           29440  190601012000    NaN    0.0   NaN    25.0  NaN  NaN   \n",
      "3           29440  190601020600    NaN    0.0   NaN    26.0  NaN  NaN   \n",
      "4           29440  190601021300  270.0    7.0   NaN    27.0  NaN  NaN   \n",
      "\n",
      "     TEMP_C      TIME_STR YEAR_MONTH  \n",
      "0 -2.777778  190601010600     190601  \n",
      "1 -2.777778  190601011300     190601  \n",
      "2 -3.888889  190601012000     190601  \n",
      "3 -3.333333  190601020600     190601  \n",
      "4 -2.777778  190601021300     190601  \n"
     ]
    }
   ],
   "source": [
    "# SLice the string\n",
    "data['YEAR_MONTH'] = data['TIME_STR'].str.slice(start=0, stop=6)\n",
    "\n",
    "# Let's see what we have\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Now we have \"labeled\" the rows based on information about day of the year and hour of the day. However, let's have a look at a more clever way of dealing with dates and times.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Pandas datetime**\n",
    "\n",
    "In pandas, we can convert dates and times into a new data type [datetime](https://docs.python.org/3.7/library/datetime.html) using [pandas.to_datetime](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html) function. First, it is important to understand the structure of the input data in order to avoid erroneous conversions, and that's why we first learned string slicing before introducing the datetime functionalities. \n",
    "    \n",
    "Here is one example of how to convert the `TIME_STR`-column in our data set to datetime:\n",
    "    \n",
    "```\n",
    "# Convert to datetime\n",
    "data[\"DATE\"] = pd.to_datetime(data[\"TIME_STR\"])\n",
    "\n",
    "```\n",
    "   \n",
    "        \n",
    "If needed, you can use the `format` parameter to define the output datetime format according to [strftime(format) method](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior). together with `exact=False`, for example like this: \n",
    "    \n",
    "```\n",
    "# Convert to datetime\n",
    "data[\"YEAR_MONTH\"] = pd.to_datetime(data[\"TIME_STR\"], format='%Y%m', exact=False)\n",
    "\n",
    "```\n",
    "In this example, `exact=False` drops out days, hours and minutes, because they are not included in the specified formatting.\n",
    " \n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   1906-01-01 06:00:00\n",
       "1   1906-01-01 13:00:00\n",
       "2   1906-01-01 20:00:00\n",
       "3   1906-01-02 06:00:00\n",
       "4   1906-01-02 13:00:00\n",
       "Name: DATE, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to datetime\n",
    "data[\"DATE\"] = pd.to_datetime(data[\"TIME_STR\"])\n",
    "data[\"DATE\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: in this case, the data type of the values is `datetime`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Pandas Series datetime properties**\n",
    "    \n",
    "There are several methods available for accessing information about the properties of datetime values. Read more from the pandas documentation about [datetime properties](https://pandas.pydata.org/pandas-docs/stable/reference/series.html#datetime-properties).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can extract different time units based on the datetime-column using the [pandas.Series.dt accessor](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1906\n",
       "1         1906\n",
       "2         1906\n",
       "3         1906\n",
       "4         1906\n",
       "5         1906\n",
       "6         1906\n",
       "7         1906\n",
       "8         1906\n",
       "9         1906\n",
       "10        1906\n",
       "11        1906\n",
       "12        1906\n",
       "13        1906\n",
       "14        1906\n",
       "15        1906\n",
       "16        1906\n",
       "17        1906\n",
       "18        1906\n",
       "19        1906\n",
       "20        1906\n",
       "21        1906\n",
       "22        1906\n",
       "23        1906\n",
       "24        1906\n",
       "25        1906\n",
       "26        1906\n",
       "27        1906\n",
       "28        1906\n",
       "29        1906\n",
       "          ... \n",
       "757953    2019\n",
       "757954    2019\n",
       "757955    2019\n",
       "757956    2019\n",
       "757957    2019\n",
       "757958    2019\n",
       "757959    2019\n",
       "757960    2019\n",
       "757961    2019\n",
       "757962    2019\n",
       "757963    2019\n",
       "757964    2019\n",
       "757965    2019\n",
       "757966    2019\n",
       "757967    2019\n",
       "757968    2019\n",
       "757969    2019\n",
       "757970    2019\n",
       "757971    2019\n",
       "757972    2019\n",
       "757973    2019\n",
       "757974    2019\n",
       "757975    2019\n",
       "757976    2019\n",
       "757977    2019\n",
       "757978    2019\n",
       "757979    2019\n",
       "757980    2019\n",
       "757981    2019\n",
       "757982    2019\n",
       "Name: DATE, Length: 757983, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['DATE'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also combine the datetime functionalities with other methods from pandas. For example, we can check the number of unique years in our input data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['DATE'].dt.year.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**TASK:**\n",
    "\n",
    "- Create two new columns: `YEAR` and `MONTH` based on the date column\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_NUMBER</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>GUST</th>\n",
       "      <th>TEMP_F</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>TEMP_C</th>\n",
       "      <th>TIME_STR</th>\n",
       "      <th>YEAR_MONTH</th>\n",
       "      <th>DATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601010600</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.777778</td>\n",
       "      <td>190601010600</td>\n",
       "      <td>190601</td>\n",
       "      <td>1906-01-01 06:00:00</td>\n",
       "      <td>1906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601011300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.777778</td>\n",
       "      <td>190601011300</td>\n",
       "      <td>190601</td>\n",
       "      <td>1906-01-01 13:00:00</td>\n",
       "      <td>1906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601012000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.888889</td>\n",
       "      <td>190601012000</td>\n",
       "      <td>190601</td>\n",
       "      <td>1906-01-01 20:00:00</td>\n",
       "      <td>1906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601020600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.333333</td>\n",
       "      <td>190601020600</td>\n",
       "      <td>190601</td>\n",
       "      <td>1906-01-02 06:00:00</td>\n",
       "      <td>1906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601021300</td>\n",
       "      <td>270.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.777778</td>\n",
       "      <td>190601021300</td>\n",
       "      <td>190601</td>\n",
       "      <td>1906-01-02 13:00:00</td>\n",
       "      <td>1906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATION_NUMBER          TIME    DIR  SPEED  GUST  TEMP_F  MAX  MIN  \\\n",
       "0           29440  190601010600   90.0    7.0   NaN    27.0  NaN  NaN   \n",
       "1           29440  190601011300    NaN    0.0   NaN    27.0  NaN  NaN   \n",
       "2           29440  190601012000    NaN    0.0   NaN    25.0  NaN  NaN   \n",
       "3           29440  190601020600    NaN    0.0   NaN    26.0  NaN  NaN   \n",
       "4           29440  190601021300  270.0    7.0   NaN    27.0  NaN  NaN   \n",
       "\n",
       "     TEMP_C      TIME_STR YEAR_MONTH                DATE  YEAR  MONTH  \n",
       "0 -2.777778  190601010600     190601 1906-01-01 06:00:00  1906      1  \n",
       "1 -2.777778  190601011300     190601 1906-01-01 13:00:00  1906      1  \n",
       "2 -3.888889  190601012000     190601 1906-01-01 20:00:00  1906      1  \n",
       "3 -3.333333  190601020600     190601 1906-01-02 06:00:00  1906      1  \n",
       "4 -2.777778  190601021300     190601 1906-01-02 13:00:00  1906      1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['YEAR'] = data['DATE'].dt.year\n",
    "data['MONTH'] = data['DATE'].dt.month\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating data in Pandas by grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will learn how to use [pandas.DataFrame.groupby](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) which is a handy method for compressing large amounts of data and computing statistics for subgroups.\n",
    "\n",
    "Our practical task is to calculate the average temperatures for each month\n",
    "\n",
    "This can be done by aggregating the data, i.e.:\n",
    "\n",
    "  1. **grouping the data** based on year and month\n",
    "  2. Calculating the average for each month (each group) either by using a for-loop or directly from the grouped object\n",
    "  3. Storing those values into **a new DataFrame** `monthly_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start grouping the data, let's once more check how our input data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows: 757983\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_NUMBER</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>GUST</th>\n",
       "      <th>TEMP_F</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>TEMP_C</th>\n",
       "      <th>TIME_STR</th>\n",
       "      <th>YEAR_MONTH</th>\n",
       "      <th>DATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601010600</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.777778</td>\n",
       "      <td>190601010600</td>\n",
       "      <td>190601</td>\n",
       "      <td>1906-01-01 06:00:00</td>\n",
       "      <td>1906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601011300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.777778</td>\n",
       "      <td>190601011300</td>\n",
       "      <td>190601</td>\n",
       "      <td>1906-01-01 13:00:00</td>\n",
       "      <td>1906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601012000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.888889</td>\n",
       "      <td>190601012000</td>\n",
       "      <td>190601</td>\n",
       "      <td>1906-01-01 20:00:00</td>\n",
       "      <td>1906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601020600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.333333</td>\n",
       "      <td>190601020600</td>\n",
       "      <td>190601</td>\n",
       "      <td>1906-01-02 06:00:00</td>\n",
       "      <td>1906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29440</td>\n",
       "      <td>190601021300</td>\n",
       "      <td>270.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.777778</td>\n",
       "      <td>190601021300</td>\n",
       "      <td>190601</td>\n",
       "      <td>1906-01-02 13:00:00</td>\n",
       "      <td>1906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATION_NUMBER          TIME    DIR  SPEED  GUST  TEMP_F  MAX  MIN  \\\n",
       "0           29440  190601010600   90.0    7.0   NaN    27.0  NaN  NaN   \n",
       "1           29440  190601011300    NaN    0.0   NaN    27.0  NaN  NaN   \n",
       "2           29440  190601012000    NaN    0.0   NaN    25.0  NaN  NaN   \n",
       "3           29440  190601020600    NaN    0.0   NaN    26.0  NaN  NaN   \n",
       "4           29440  190601021300  270.0    7.0   NaN    27.0  NaN  NaN   \n",
       "\n",
       "     TEMP_C      TIME_STR YEAR_MONTH                DATE  YEAR  MONTH  \n",
       "0 -2.777778  190601010600     190601 1906-01-01 06:00:00  1906      1  \n",
       "1 -2.777778  190601011300     190601 1906-01-01 13:00:00  1906      1  \n",
       "2 -3.888889  190601012000     190601 1906-01-01 20:00:00  1906      1  \n",
       "3 -3.333333  190601020600     190601 1906-01-02 06:00:00  1906      1  \n",
       "4 -2.777778  190601021300     190601 1906-01-02 13:00:00  1906      1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"number of rows:\", len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have quite a few rows of weather data, and several observations per day. **Our goal is to create an aggreated data frame that would have only one row per month!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's **group** our data based on unique year and month combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = data.groupby([\"YEAR\", \"MONTH\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**NOTE:**\n",
    "    \n",
    "Here you could also group the data based on the `YEAR_MONTH` column to achieve the same result:\n",
    "    \n",
    "```\n",
    "# Group the data \n",
    "grouped = data.groupby('YEAR_MONTH')\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's see what we have now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:\n",
      " <class 'pandas.core.groupby.groupby.DataFrameGroupBy'>\n",
      "Length:\n",
      " 601\n"
     ]
    }
   ],
   "source": [
    "# What is the type?\n",
    "print(\"Type:\\n\", type(grouped))\n",
    "\n",
    "# How many?\n",
    "print(\"Length:\\n\", len(grouped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okey, interesting. Now we have a new object with type `DataFrameGroupBy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**TASK:**\n",
    "\n",
    "Think: what does the number of groups (length of the grouped object) tell us?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "601"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer: the length of the grouped object should be the same as\n",
    "data[\"YEAR_MONTH\"].nunique()\n",
    "\n",
    "# in other words, the number of groups is the number of unique year and month combinations in our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several methods we can use for extracting information from the grouped data. See [documentation for Pandas GroupBy objects](https://pandas.pydata.org/pandas-docs/stable/reference/groupby.html) for a comprehensive overview. \n",
    "\n",
    "**Checking group names:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the \"names\" of each group (uncomment the next row if you want to print out all the keys)\n",
    "#grouped.groups.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accessing data for one group:**\n",
    "\n",
    "- Let's check the contents for a group representing August 2019 (name of that group is `(2019, 4)` if you grouped the data based on datetime columns `YEAR` and `MONTH`). We can get the values of that hour from the grouped object using the `get_group()` -method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        STATION_NUMBER          TIME    DIR  SPEED  GUST  TEMP_F   MAX   MIN  \\\n",
      "745098           29440  201904010000  280.0    6.0   NaN    30.0   NaN   NaN   \n",
      "745099           29440  201904010020  280.0    7.0   NaN    32.0   NaN   NaN   \n",
      "745100           29440  201904010050  280.0    6.0   NaN    30.0   NaN   NaN   \n",
      "745101           29440  201904010100  280.0    7.0   NaN    30.0   NaN   NaN   \n",
      "745102           29440  201904010120  280.0    6.0   NaN    30.0   NaN   NaN   \n",
      "745103           29440  201904010150  300.0    5.0   NaN    30.0   NaN   NaN   \n",
      "745104           29440  201904010200  290.0    6.0   NaN    30.0   NaN   NaN   \n",
      "745105           29440  201904010220  290.0    6.0   NaN    30.0   NaN   NaN   \n",
      "745106           29440  201904010250  290.0    6.0   NaN    28.0   NaN   NaN   \n",
      "745107           29440  201904010300  290.0    5.0   NaN    29.0   NaN   NaN   \n",
      "745108           29440  201904010320  280.0    6.0   NaN    30.0   NaN   NaN   \n",
      "745109           29440  201904010350  280.0    6.0   NaN    28.0   NaN   NaN   \n",
      "745110           29440  201904010400  280.0    5.0   NaN    29.0   NaN   NaN   \n",
      "745111           29440  201904010420  290.0    6.0   NaN    28.0   NaN   NaN   \n",
      "745112           29440  201904010450  270.0    7.0   NaN    30.0   NaN   NaN   \n",
      "745113           29440  201904010500  270.0    6.0   NaN    30.0   NaN   NaN   \n",
      "745114           29440  201904010520  280.0    8.0   NaN    30.0   NaN   NaN   \n",
      "745115           29440  201904010550  280.0    7.0   NaN    30.0   NaN   NaN   \n",
      "745116           29440  201904010600  290.0    6.0   NaN    31.0  35.0  29.0   \n",
      "745117           29440  201904010620  280.0    8.0   NaN    32.0   NaN   NaN   \n",
      "745118           29440  201904010650  290.0   10.0   NaN    32.0   NaN   NaN   \n",
      "745119           29440  201904010700  300.0    7.0  11.0    33.0   NaN   NaN   \n",
      "745120           29440  201904010720  990.0   10.0   NaN    34.0   NaN   NaN   \n",
      "745121           29440  201904010750  290.0    9.0   NaN    34.0   NaN   NaN   \n",
      "745122           29440  201904010800  290.0    7.0  11.0    35.0   NaN   NaN   \n",
      "745123           29440  201904010820  290.0    9.0   NaN    36.0   NaN   NaN   \n",
      "745124           29440  201904010850  250.0   13.0   NaN    37.0   NaN   NaN   \n",
      "745125           29440  201904010900  260.0    9.0  15.0    37.0   NaN   NaN   \n",
      "745126           29440  201904010920  250.0   14.0   NaN    37.0   NaN   NaN   \n",
      "745127           29440  201904010950  240.0   15.0   NaN    39.0   NaN   NaN   \n",
      "...                ...           ...    ...    ...   ...     ...   ...   ...   \n",
      "747231           29440  201904301400  260.0    6.0   NaN    57.0   NaN   NaN   \n",
      "747232           29440  201904301420  990.0    6.0   NaN    57.0   NaN   NaN   \n",
      "747233           29440  201904301450  990.0    7.0   NaN    59.0   NaN   NaN   \n",
      "747234           29440  201904301500  250.0    8.0  11.0    58.0   NaN   NaN   \n",
      "747235           29440  201904301520  240.0    9.0   NaN    59.0   NaN   NaN   \n",
      "747236           29440  201904301550  990.0    5.0   NaN    57.0   NaN   NaN   \n",
      "747237           29440  201904301600  360.0    0.0   NaN    58.0   NaN   NaN   \n",
      "747238           29440  201904301620  990.0    3.0   NaN    57.0   NaN   NaN   \n",
      "747239           29440  201904301650  190.0    3.0   NaN    57.0   NaN   NaN   \n",
      "747240           29440  201904301700  180.0    2.0   NaN    57.0   NaN   NaN   \n",
      "747241           29440  201904301720  190.0    2.0   NaN    55.0   NaN   NaN   \n",
      "747242           29440  201904301750  190.0    2.0   NaN    54.0   NaN   NaN   \n",
      "747243           29440  201904301800  360.0    0.0   NaN    51.0  58.0  42.0   \n",
      "747244           29440  201904301820  300.0    6.0   NaN    52.0   NaN   NaN   \n",
      "747245           29440  201904301850  280.0    3.0   NaN    50.0   NaN   NaN   \n",
      "747246           29440  201904301900  270.0    5.0   NaN    47.0   NaN   NaN   \n",
      "747247           29440  201904301920  230.0    2.0   NaN    46.0   NaN   NaN   \n",
      "747248           29440  201904301950  990.0    1.0   NaN    41.0   NaN   NaN   \n",
      "747249           29440  201904302000  360.0    0.0   NaN    42.0   NaN   NaN   \n",
      "747250           29440  201904302020  990.0    1.0   NaN    41.0   NaN   NaN   \n",
      "747251           29440  201904302050    NaN    0.0   NaN    39.0   NaN   NaN   \n",
      "747252           29440  201904302100  360.0    0.0   NaN    39.0   NaN   NaN   \n",
      "747253           29440  201904302120  990.0    1.0   NaN    37.0   NaN   NaN   \n",
      "747254           29440  201904302150    NaN    0.0   NaN    37.0   NaN   NaN   \n",
      "747255           29440  201904302200  360.0    0.0   NaN    36.0   NaN   NaN   \n",
      "747256           29440  201904302220  990.0    1.0   NaN    36.0   NaN   NaN   \n",
      "747257           29440  201904302250  990.0    1.0   NaN    36.0   NaN   NaN   \n",
      "747258           29440  201904302300  360.0    0.0   NaN    36.0   NaN   NaN   \n",
      "747259           29440  201904302320  990.0    1.0   NaN    34.0   NaN   NaN   \n",
      "747260           29440  201904302350  190.0    3.0   NaN    36.0   NaN   NaN   \n",
      "\n",
      "           TEMP_C      TIME_STR YEAR_MONTH                DATE  YEAR  MONTH  \n",
      "745098  -1.111111  201904010000     201904 2019-04-01 00:00:00  2019      4  \n",
      "745099   0.000000  201904010020     201904 2019-04-01 00:20:00  2019      4  \n",
      "745100  -1.111111  201904010050     201904 2019-04-01 00:50:00  2019      4  \n",
      "745101  -1.111111  201904010100     201904 2019-04-01 01:00:00  2019      4  \n",
      "745102  -1.111111  201904010120     201904 2019-04-01 01:20:00  2019      4  \n",
      "745103  -1.111111  201904010150     201904 2019-04-01 01:50:00  2019      4  \n",
      "745104  -1.111111  201904010200     201904 2019-04-01 02:00:00  2019      4  \n",
      "745105  -1.111111  201904010220     201904 2019-04-01 02:20:00  2019      4  \n",
      "745106  -2.222222  201904010250     201904 2019-04-01 02:50:00  2019      4  \n",
      "745107  -1.666667  201904010300     201904 2019-04-01 03:00:00  2019      4  \n",
      "745108  -1.111111  201904010320     201904 2019-04-01 03:20:00  2019      4  \n",
      "745109  -2.222222  201904010350     201904 2019-04-01 03:50:00  2019      4  \n",
      "745110  -1.666667  201904010400     201904 2019-04-01 04:00:00  2019      4  \n",
      "745111  -2.222222  201904010420     201904 2019-04-01 04:20:00  2019      4  \n",
      "745112  -1.111111  201904010450     201904 2019-04-01 04:50:00  2019      4  \n",
      "745113  -1.111111  201904010500     201904 2019-04-01 05:00:00  2019      4  \n",
      "745114  -1.111111  201904010520     201904 2019-04-01 05:20:00  2019      4  \n",
      "745115  -1.111111  201904010550     201904 2019-04-01 05:50:00  2019      4  \n",
      "745116  -0.555556  201904010600     201904 2019-04-01 06:00:00  2019      4  \n",
      "745117   0.000000  201904010620     201904 2019-04-01 06:20:00  2019      4  \n",
      "745118   0.000000  201904010650     201904 2019-04-01 06:50:00  2019      4  \n",
      "745119   0.555556  201904010700     201904 2019-04-01 07:00:00  2019      4  \n",
      "745120   1.111111  201904010720     201904 2019-04-01 07:20:00  2019      4  \n",
      "745121   1.111111  201904010750     201904 2019-04-01 07:50:00  2019      4  \n",
      "745122   1.666667  201904010800     201904 2019-04-01 08:00:00  2019      4  \n",
      "745123   2.222222  201904010820     201904 2019-04-01 08:20:00  2019      4  \n",
      "745124   2.777778  201904010850     201904 2019-04-01 08:50:00  2019      4  \n",
      "745125   2.777778  201904010900     201904 2019-04-01 09:00:00  2019      4  \n",
      "745126   2.777778  201904010920     201904 2019-04-01 09:20:00  2019      4  \n",
      "745127   3.888889  201904010950     201904 2019-04-01 09:50:00  2019      4  \n",
      "...           ...           ...        ...                 ...   ...    ...  \n",
      "747231  13.888889  201904301400     201904 2019-04-30 14:00:00  2019      4  \n",
      "747232  13.888889  201904301420     201904 2019-04-30 14:20:00  2019      4  \n",
      "747233  15.000000  201904301450     201904 2019-04-30 14:50:00  2019      4  \n",
      "747234  14.444444  201904301500     201904 2019-04-30 15:00:00  2019      4  \n",
      "747235  15.000000  201904301520     201904 2019-04-30 15:20:00  2019      4  \n",
      "747236  13.888889  201904301550     201904 2019-04-30 15:50:00  2019      4  \n",
      "747237  14.444444  201904301600     201904 2019-04-30 16:00:00  2019      4  \n",
      "747238  13.888889  201904301620     201904 2019-04-30 16:20:00  2019      4  \n",
      "747239  13.888889  201904301650     201904 2019-04-30 16:50:00  2019      4  \n",
      "747240  13.888889  201904301700     201904 2019-04-30 17:00:00  2019      4  \n",
      "747241  12.777778  201904301720     201904 2019-04-30 17:20:00  2019      4  \n",
      "747242  12.222222  201904301750     201904 2019-04-30 17:50:00  2019      4  \n",
      "747243  10.555556  201904301800     201904 2019-04-30 18:00:00  2019      4  \n",
      "747244  11.111111  201904301820     201904 2019-04-30 18:20:00  2019      4  \n",
      "747245  10.000000  201904301850     201904 2019-04-30 18:50:00  2019      4  \n",
      "747246   8.333333  201904301900     201904 2019-04-30 19:00:00  2019      4  \n",
      "747247   7.777778  201904301920     201904 2019-04-30 19:20:00  2019      4  \n",
      "747248   5.000000  201904301950     201904 2019-04-30 19:50:00  2019      4  \n",
      "747249   5.555556  201904302000     201904 2019-04-30 20:00:00  2019      4  \n",
      "747250   5.000000  201904302020     201904 2019-04-30 20:20:00  2019      4  \n",
      "747251   3.888889  201904302050     201904 2019-04-30 20:50:00  2019      4  \n",
      "747252   3.888889  201904302100     201904 2019-04-30 21:00:00  2019      4  \n",
      "747253   2.777778  201904302120     201904 2019-04-30 21:20:00  2019      4  \n",
      "747254   2.777778  201904302150     201904 2019-04-30 21:50:00  2019      4  \n",
      "747255   2.222222  201904302200     201904 2019-04-30 22:00:00  2019      4  \n",
      "747256   2.222222  201904302220     201904 2019-04-30 22:20:00  2019      4  \n",
      "747257   2.222222  201904302250     201904 2019-04-30 22:50:00  2019      4  \n",
      "747258   2.222222  201904302300     201904 2019-04-30 23:00:00  2019      4  \n",
      "747259   1.111111  201904302320     201904 2019-04-30 23:20:00  2019      4  \n",
      "747260   2.222222  201904302350     201904 2019-04-30 23:50:00  2019      4  \n",
      "\n",
      "[2163 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Specify the time of the first hour (as text)\n",
    "month = (2019, 4)\n",
    "\n",
    "# Select the group\n",
    "group1 = grouped.get_group(month)\n",
    "\n",
    "# Let's see what we have\n",
    "print(group1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahaa! As we can see, a single group contains a **DataFrame** with values only for that specific month. Let's check the DataType of this group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(group1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, one group is a pandas DataFrame! This is really useful, because we can now use all the familiar DataFrame methods for calculating statistics etc for this spesific group. \n",
    "We can, for example, calculate the average values for all variables using the statistical functions that we have seen already (e.g. mean, std, min, max, median, etc.).\n",
    "\n",
    "We can do that by using the `mean()` -function that we already used during the Lesson 5. \n",
    "\n",
    "- Let's calculate the mean for following attributes all at once:\n",
    "   - `DIR`, \n",
    "   - `SPEED`, \n",
    "   - `GUST`, \n",
    "   - `TEMP`, \n",
    "   - `TEMP_C`\n",
    "   - `MONTH` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIR       309.035306\n",
      "SPEED       5.932188\n",
      "GUST       15.868217\n",
      "TEMP_F     42.472030\n",
      "TEMP_C      5.817794\n",
      "MONTH       4.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Specify the columns that will be part of the calculation\n",
    "mean_cols = ['DIR', 'SPEED', 'GUST', 'TEMP_F', 'TEMP_C', 'MONTH']\n",
    "\n",
    "# Calculate the mean values all at one go\n",
    "mean_values = group1[mean_cols].mean()\n",
    "\n",
    "# Let's see what we have\n",
    "print(mean_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we saw how you can access data from a single group. For getting information about all groups (all months) we can a `for` -loop or methods available in the grouped object.\n",
    "\n",
    "**For-loops and grouped objects:**\n",
    "\n",
    "When iterating over the groups in our `DataFrameGroupBy` -object\n",
    "it is important to understand that a single group in our `DataFrameGroupBy` actually contains not only the actual values, but also information about the `key` that was used to do the grouping. Hence, when iterating over the data we need to assign the `key` and the values into separate variables.\n",
    "\n",
    "- Let's see how we can iterate over the groups and print the key and the data from a single group (again using `break` to only see what is happening).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key:\n",
      " (1906, 1)\n",
      "\n",
      "First rows of data in this group:\n",
      "    STATION_NUMBER          TIME    DIR  SPEED  GUST  TEMP_F  MAX  MIN  \\\n",
      "0           29440  190601010600   90.0    7.0   NaN    27.0  NaN  NaN   \n",
      "1           29440  190601011300    NaN    0.0   NaN    27.0  NaN  NaN   \n",
      "2           29440  190601012000    NaN    0.0   NaN    25.0  NaN  NaN   \n",
      "3           29440  190601020600    NaN    0.0   NaN    26.0  NaN  NaN   \n",
      "4           29440  190601021300  270.0    7.0   NaN    27.0  NaN  NaN   \n",
      "\n",
      "     TEMP_C      TIME_STR YEAR_MONTH                DATE  YEAR  MONTH  \n",
      "0 -2.777778  190601010600     190601 1906-01-01 06:00:00  1906      1  \n",
      "1 -2.777778  190601011300     190601 1906-01-01 13:00:00  1906      1  \n",
      "2 -3.888889  190601012000     190601 1906-01-01 20:00:00  1906      1  \n",
      "3 -3.333333  190601020600     190601 1906-01-02 06:00:00  1906      1  \n",
      "4 -2.777778  190601021300     190601 1906-01-02 13:00:00  1906      1  \n"
     ]
    }
   ],
   "source": [
    "# Iterate over groups\n",
    "for key, group in grouped:\n",
    "    # Print key and group\n",
    "    print(\"Key:\\n\", key)\n",
    "    print(\"\\nFirst rows of data in this group:\\n\", group.head())\n",
    "    \n",
    "    # Stop iteration with break command\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okey so from here we can see that the `key` contains the name of the group (year, month).\n",
    "\n",
    "- Let's see how we can create a DataFrame where we calculate the mean values for all those weather attributes that we were interested in. I will repeat slightly the earlier steps so that you can see and better understand what is happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame for the aggregated values\n",
    "monthly_data = pd.DataFrame()\n",
    "\n",
    "# The columns that we want to aggregate\n",
    "mean_cols = ['DIR', 'SPEED', 'GUST', 'TEMP_F', 'TEMP_C', \"MONTH\"]\n",
    "\n",
    "# Iterate over the groups\n",
    "for key, group in grouped:\n",
    "    \n",
    "   # Calculate mean\n",
    "   mean_values = group[mean_cols].mean()\n",
    "\n",
    "   # Add the key (i.e. the date+time information) into the aggregated values\n",
    "   mean_values['YEAR_MONTH'] = key\n",
    "\n",
    "   # Append the aggregated values into the DataFrame\n",
    "   monthly_data = monthly_data.append(mean_values, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's see what we have now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            DIR       GUST  MONTH      SPEED     TEMP_C     TEMP_F  YEAR_MONTH\n",
      "0    218.181818        NaN    1.0  13.204301  -3.596177  25.526882   (1906, 1)\n",
      "1    178.095238        NaN    2.0  13.142857  -3.445767  25.797619   (1906, 2)\n",
      "2    232.043011        NaN    3.0  15.021505  -5.107527  22.806452   (1906, 3)\n",
      "3    232.045455        NaN    4.0  13.811111   3.790123  38.822222   (1906, 4)\n",
      "4    192.820513        NaN    5.0  10.333333  13.070490  55.526882   (1906, 5)\n",
      "5    234.222222        NaN    6.0  12.922222  16.246914  61.244444   (1906, 6)\n",
      "6    226.923077        NaN    7.0  10.827957  18.805257  65.849462   (1906, 7)\n",
      "7    251.627907        NaN    8.0  11.623656  13.590203  56.462366   (1906, 8)\n",
      "8    236.986301        NaN    9.0   9.988889   8.611111  47.500000   (1906, 9)\n",
      "9    199.397590        NaN   10.0  12.365591   4.360812  39.849462  (1906, 10)\n",
      "10   199.166667        NaN   11.0  14.211111   0.296296  32.533333  (1906, 11)\n",
      "11   198.636364        NaN   12.0  15.516129  -4.086022  24.645161  (1906, 12)\n",
      "12   190.930233        NaN    1.0  16.344086  -9.904421  14.172043   (1907, 1)\n",
      "13   223.466667        NaN    2.0  15.108434  -5.535475  22.036145   (1907, 2)\n",
      "14   238.051948        NaN    3.0  10.763441  -1.344086  29.580645   (1907, 3)\n",
      "15   201.038961        NaN    4.0  10.433333   2.283951  36.111111   (1907, 4)\n",
      "16   244.823529        NaN    5.0  12.913978   7.048984  44.688172   (1907, 5)\n",
      "17   202.674419        NaN    6.0  11.633333  14.308642  57.755556   (1907, 6)\n",
      "18   215.238095        NaN    7.0  10.473118  16.923536  62.462366   (1907, 7)\n",
      "19   221.139241        NaN    8.0   9.645161  12.640382  54.752688   (1907, 8)\n",
      "20   258.953488        NaN    9.0  16.466667   9.185185  48.533333   (1907, 9)\n",
      "21   192.682927        NaN   10.0  10.408602   8.482676  47.268817  (1907, 10)\n",
      "22   204.222222        NaN   11.0  15.744444   0.641975  33.155556  (1907, 11)\n",
      "23   166.052632        NaN   12.0  11.000000 -11.992754  10.413043  (1907, 12)\n",
      "24   221.547619        NaN    1.0  11.376344  -6.284349  20.688172   (1908, 1)\n",
      "25   190.864198        NaN    2.0  10.546512  -5.245478  22.558140   (1908, 2)\n",
      "26   169.315068        NaN    3.0   6.537634  -4.342891  24.182796   (1908, 3)\n",
      "27   195.333333        NaN    4.0   6.222222   2.672840  36.811111   (1908, 4)\n",
      "28   259.718310        NaN    5.0   6.709677   8.052569  46.494624   (1908, 5)\n",
      "29   249.651163        NaN    6.0  20.011111  14.283951  57.711111   (1908, 6)\n",
      "..          ...        ...    ...        ...        ...        ...         ...\n",
      "571  340.875980  15.628492    5.0   6.872531   8.409816  47.137668   (2017, 5)\n",
      "572  379.561190  17.014451    6.0   6.904539  12.733344  54.920019   (2017, 6)\n",
      "573  359.269933  15.245136    7.0   6.318477  14.878319  58.780974   (2017, 7)\n",
      "574  331.270588  15.627178    8.0   6.489526  14.526758  58.148165   (2017, 8)\n",
      "575  304.676641  14.788660    9.0   5.399907  10.070834  50.127501   (2017, 9)\n",
      "576  277.448502  16.598854   10.0   6.535569   3.963063  39.133514  (2017, 10)\n",
      "577  215.835272  16.026846   11.0   7.165504   1.957475  35.523456  (2017, 11)\n",
      "578  237.338195  15.927536   12.0   7.908435  -0.497221  31.105002  (2017, 12)\n",
      "579  269.553613  17.351792    1.0   6.898274  -3.848810  25.072142   (2018, 1)\n",
      "580  224.710831  14.937500    2.0   5.870871  -9.752473  14.445549   (2018, 2)\n",
      "581  292.265435  15.392857    3.0   6.066968  -6.356461  20.558371   (2018, 3)\n",
      "582  350.141509  15.216981    4.0   5.704087   3.862159  38.951887   (2018, 4)\n",
      "583  422.810552  14.819095    5.0   5.387764  14.625079  58.325143   (2018, 5)\n",
      "584  445.827233  18.480337    6.0   7.056325  14.357283  57.843109   (2018, 6)\n",
      "585  408.614487  15.902778    7.0   5.607442  20.695197  69.251354   (2018, 7)\n",
      "586  396.655422  16.764179    8.0   6.515248  16.888990  62.400182   (2018, 8)\n",
      "587  290.531856  20.581481    9.0   7.879109  12.253005  54.055409   (2018, 9)\n",
      "588  256.174656  17.902685   10.0   7.452370   5.609417  42.096950  (2018, 10)\n",
      "589  303.893491  16.097473   11.0   6.950848   2.547624  36.585723  (2018, 11)\n",
      "590  281.960321  14.872807   12.0   6.531746  -2.959591  26.672736  (2018, 12)\n",
      "591  279.460600  17.300813    1.0   5.835289  -7.841929  17.884529   (2019, 1)\n",
      "592  252.858576  17.908511    2.0   9.232639  -1.682650  28.971230   (2019, 2)\n",
      "593  281.606481  17.462687    3.0   7.907805  -1.397007  29.485388   (2019, 3)\n",
      "594  309.035306  15.868217    4.0   5.932188   5.817794  42.472030   (2019, 4)\n",
      "595  367.198506  17.553719    5.0   7.738381   8.869752  47.965553   (2019, 5)\n",
      "596  370.992008  17.251852    6.0   8.138490  16.524111  61.743400   (2019, 6)\n",
      "597  294.433641  15.034722    7.0   5.785714  16.427753  61.569955   (2019, 7)\n",
      "598  320.335766  15.751678    8.0   6.769447  15.888138  60.598649   (2019, 8)\n",
      "599  306.491058  15.173285    9.0   6.363594   9.976743  49.958137   (2019, 9)\n",
      "600  239.577465  17.470588   10.0  10.169014   5.985915  42.774648  (2019, 10)\n",
      "\n",
      "[601 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(monthly_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Now we have aggregated our data and we have a new DataFrame called `monthly_data` where we have mean values for each month in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean for all groups at once**\n",
    "\n",
    "We can also achieve the same result by computing the mean of all columns for all groups in the grouped object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>STATION_NUMBER</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>GUST</th>\n",
       "      <th>TEMP_F</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>TEMP_C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">1906</th>\n",
       "      <th>1</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.906012e+11</td>\n",
       "      <td>218.181818</td>\n",
       "      <td>13.204301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.526882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.596177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.906021e+11</td>\n",
       "      <td>178.095238</td>\n",
       "      <td>13.142857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.797619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.445767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.906032e+11</td>\n",
       "      <td>232.043011</td>\n",
       "      <td>15.021505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.806452</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.107527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.906042e+11</td>\n",
       "      <td>232.045455</td>\n",
       "      <td>13.811111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.822222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.790123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.906052e+11</td>\n",
       "      <td>192.820513</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.526882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.070490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.906062e+11</td>\n",
       "      <td>234.222222</td>\n",
       "      <td>12.922222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.244444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.246914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.906072e+11</td>\n",
       "      <td>226.923077</td>\n",
       "      <td>10.827957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.849462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.805257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.906082e+11</td>\n",
       "      <td>251.627907</td>\n",
       "      <td>11.623656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56.462366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.590203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.906092e+11</td>\n",
       "      <td>236.986301</td>\n",
       "      <td>9.988889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.906102e+11</td>\n",
       "      <td>199.397590</td>\n",
       "      <td>12.365591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.849462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.360812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.906112e+11</td>\n",
       "      <td>199.166667</td>\n",
       "      <td>14.211111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.533333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.296296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.906122e+11</td>\n",
       "      <td>198.636364</td>\n",
       "      <td>15.516129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.645161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.086022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">1907</th>\n",
       "      <th>1</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.907012e+11</td>\n",
       "      <td>190.930233</td>\n",
       "      <td>16.344086</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.172043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.904421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.907021e+11</td>\n",
       "      <td>223.466667</td>\n",
       "      <td>15.108434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.036145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.535475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.907032e+11</td>\n",
       "      <td>238.051948</td>\n",
       "      <td>10.763441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.580645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.344086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.907042e+11</td>\n",
       "      <td>201.038961</td>\n",
       "      <td>10.433333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.111111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.283951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.907052e+11</td>\n",
       "      <td>244.823529</td>\n",
       "      <td>12.913978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.688172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.048984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.907062e+11</td>\n",
       "      <td>202.674419</td>\n",
       "      <td>11.633333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.755556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.308642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.907072e+11</td>\n",
       "      <td>215.238095</td>\n",
       "      <td>10.473118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.462366</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.923536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.907082e+11</td>\n",
       "      <td>221.139241</td>\n",
       "      <td>9.645161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.752688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.640382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.907092e+11</td>\n",
       "      <td>258.953488</td>\n",
       "      <td>16.466667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.533333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.185185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.907102e+11</td>\n",
       "      <td>192.682927</td>\n",
       "      <td>10.408602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.268817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.482676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.907112e+11</td>\n",
       "      <td>204.222222</td>\n",
       "      <td>15.744444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.155556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.641975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.907122e+11</td>\n",
       "      <td>166.052632</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.413043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-11.992754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">1908</th>\n",
       "      <th>1</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.908012e+11</td>\n",
       "      <td>221.547619</td>\n",
       "      <td>11.376344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.688172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.284349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.908022e+11</td>\n",
       "      <td>190.864198</td>\n",
       "      <td>10.546512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.558140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.245478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.908032e+11</td>\n",
       "      <td>169.315068</td>\n",
       "      <td>6.537634</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.182796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.342891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.908042e+11</td>\n",
       "      <td>195.333333</td>\n",
       "      <td>6.222222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.811111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.672840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.908052e+11</td>\n",
       "      <td>259.718310</td>\n",
       "      <td>6.709677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.494624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.052569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>1.908062e+11</td>\n",
       "      <td>249.651163</td>\n",
       "      <td>20.011111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.711111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.283951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">2017</th>\n",
       "      <th>5</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.017052e+11</td>\n",
       "      <td>340.875980</td>\n",
       "      <td>6.872531</td>\n",
       "      <td>15.628492</td>\n",
       "      <td>47.137668</td>\n",
       "      <td>53.580645</td>\n",
       "      <td>40.387097</td>\n",
       "      <td>8.409816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.017062e+11</td>\n",
       "      <td>379.561190</td>\n",
       "      <td>6.904539</td>\n",
       "      <td>17.014451</td>\n",
       "      <td>54.920019</td>\n",
       "      <td>60.566667</td>\n",
       "      <td>49.516667</td>\n",
       "      <td>12.733344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.017072e+11</td>\n",
       "      <td>359.269933</td>\n",
       "      <td>6.318477</td>\n",
       "      <td>15.245136</td>\n",
       "      <td>58.780974</td>\n",
       "      <td>64.345455</td>\n",
       "      <td>53.581818</td>\n",
       "      <td>14.878319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.017082e+11</td>\n",
       "      <td>331.270588</td>\n",
       "      <td>6.489526</td>\n",
       "      <td>15.627178</td>\n",
       "      <td>58.148165</td>\n",
       "      <td>62.229508</td>\n",
       "      <td>53.590164</td>\n",
       "      <td>14.526758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.017092e+11</td>\n",
       "      <td>304.676641</td>\n",
       "      <td>5.399907</td>\n",
       "      <td>14.788660</td>\n",
       "      <td>50.127501</td>\n",
       "      <td>53.300000</td>\n",
       "      <td>46.600000</td>\n",
       "      <td>10.070834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.017102e+11</td>\n",
       "      <td>277.448502</td>\n",
       "      <td>6.535569</td>\n",
       "      <td>16.598854</td>\n",
       "      <td>39.133514</td>\n",
       "      <td>41.918033</td>\n",
       "      <td>36.098361</td>\n",
       "      <td>3.963063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.017112e+11</td>\n",
       "      <td>215.835272</td>\n",
       "      <td>7.165504</td>\n",
       "      <td>16.026846</td>\n",
       "      <td>35.523456</td>\n",
       "      <td>37.200000</td>\n",
       "      <td>33.368421</td>\n",
       "      <td>1.957475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.017122e+11</td>\n",
       "      <td>237.338195</td>\n",
       "      <td>7.908435</td>\n",
       "      <td>15.927536</td>\n",
       "      <td>31.105002</td>\n",
       "      <td>33.016393</td>\n",
       "      <td>28.758065</td>\n",
       "      <td>-0.497221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">2018</th>\n",
       "      <th>1</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.018012e+11</td>\n",
       "      <td>269.553613</td>\n",
       "      <td>6.898274</td>\n",
       "      <td>17.351792</td>\n",
       "      <td>25.072142</td>\n",
       "      <td>26.816667</td>\n",
       "      <td>21.637931</td>\n",
       "      <td>-3.848810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.018021e+11</td>\n",
       "      <td>224.710831</td>\n",
       "      <td>5.870871</td>\n",
       "      <td>14.937500</td>\n",
       "      <td>14.445549</td>\n",
       "      <td>18.196429</td>\n",
       "      <td>10.196429</td>\n",
       "      <td>-9.752473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.018032e+11</td>\n",
       "      <td>292.265435</td>\n",
       "      <td>6.066968</td>\n",
       "      <td>15.392857</td>\n",
       "      <td>20.558371</td>\n",
       "      <td>25.491525</td>\n",
       "      <td>12.423729</td>\n",
       "      <td>-6.356461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.018042e+11</td>\n",
       "      <td>350.141509</td>\n",
       "      <td>5.704087</td>\n",
       "      <td>15.216981</td>\n",
       "      <td>38.951887</td>\n",
       "      <td>44.175439</td>\n",
       "      <td>32.844828</td>\n",
       "      <td>3.862159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.018052e+11</td>\n",
       "      <td>422.810552</td>\n",
       "      <td>5.387764</td>\n",
       "      <td>14.819095</td>\n",
       "      <td>58.325143</td>\n",
       "      <td>63.512195</td>\n",
       "      <td>48.658537</td>\n",
       "      <td>14.625079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.018062e+11</td>\n",
       "      <td>445.827233</td>\n",
       "      <td>7.056325</td>\n",
       "      <td>18.480337</td>\n",
       "      <td>57.843109</td>\n",
       "      <td>63.754717</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>14.357283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.018072e+11</td>\n",
       "      <td>408.614487</td>\n",
       "      <td>5.607442</td>\n",
       "      <td>15.902778</td>\n",
       "      <td>69.251354</td>\n",
       "      <td>75.262295</td>\n",
       "      <td>63.688525</td>\n",
       "      <td>20.695197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.018082e+11</td>\n",
       "      <td>396.655422</td>\n",
       "      <td>6.515248</td>\n",
       "      <td>16.764179</td>\n",
       "      <td>62.400182</td>\n",
       "      <td>67.833333</td>\n",
       "      <td>57.350000</td>\n",
       "      <td>16.888990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.018092e+11</td>\n",
       "      <td>290.531856</td>\n",
       "      <td>7.879109</td>\n",
       "      <td>20.581481</td>\n",
       "      <td>54.055409</td>\n",
       "      <td>57.833333</td>\n",
       "      <td>49.648148</td>\n",
       "      <td>12.253005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.018102e+11</td>\n",
       "      <td>256.174656</td>\n",
       "      <td>7.452370</td>\n",
       "      <td>17.902685</td>\n",
       "      <td>42.096950</td>\n",
       "      <td>45.229508</td>\n",
       "      <td>37.672131</td>\n",
       "      <td>5.609417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.018111e+11</td>\n",
       "      <td>303.893491</td>\n",
       "      <td>6.950848</td>\n",
       "      <td>16.097473</td>\n",
       "      <td>36.585723</td>\n",
       "      <td>38.510638</td>\n",
       "      <td>34.085106</td>\n",
       "      <td>2.547624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.018122e+11</td>\n",
       "      <td>281.960321</td>\n",
       "      <td>6.531746</td>\n",
       "      <td>14.872807</td>\n",
       "      <td>26.672736</td>\n",
       "      <td>27.901961</td>\n",
       "      <td>23.173077</td>\n",
       "      <td>-2.959591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">2019</th>\n",
       "      <th>1</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.019012e+11</td>\n",
       "      <td>279.460600</td>\n",
       "      <td>5.835289</td>\n",
       "      <td>17.300813</td>\n",
       "      <td>17.884529</td>\n",
       "      <td>21.474576</td>\n",
       "      <td>12.700000</td>\n",
       "      <td>-7.841929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.019021e+11</td>\n",
       "      <td>252.858576</td>\n",
       "      <td>9.232639</td>\n",
       "      <td>17.908511</td>\n",
       "      <td>28.971230</td>\n",
       "      <td>32.672727</td>\n",
       "      <td>24.545455</td>\n",
       "      <td>-1.682650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.019032e+11</td>\n",
       "      <td>281.606481</td>\n",
       "      <td>7.907805</td>\n",
       "      <td>17.462687</td>\n",
       "      <td>29.485388</td>\n",
       "      <td>32.870968</td>\n",
       "      <td>24.870968</td>\n",
       "      <td>-1.397007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.019042e+11</td>\n",
       "      <td>309.035306</td>\n",
       "      <td>5.932188</td>\n",
       "      <td>15.868217</td>\n",
       "      <td>42.472030</td>\n",
       "      <td>48.810345</td>\n",
       "      <td>35.847458</td>\n",
       "      <td>5.817794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.019052e+11</td>\n",
       "      <td>367.198506</td>\n",
       "      <td>7.738381</td>\n",
       "      <td>17.553719</td>\n",
       "      <td>47.965553</td>\n",
       "      <td>52.907407</td>\n",
       "      <td>43.462963</td>\n",
       "      <td>8.869752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.019062e+11</td>\n",
       "      <td>370.992008</td>\n",
       "      <td>8.138490</td>\n",
       "      <td>17.251852</td>\n",
       "      <td>61.743400</td>\n",
       "      <td>67.316667</td>\n",
       "      <td>55.600000</td>\n",
       "      <td>16.524111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.019072e+11</td>\n",
       "      <td>294.433641</td>\n",
       "      <td>5.785714</td>\n",
       "      <td>15.034722</td>\n",
       "      <td>61.569955</td>\n",
       "      <td>67.774194</td>\n",
       "      <td>55.903226</td>\n",
       "      <td>16.427753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.019082e+11</td>\n",
       "      <td>320.335766</td>\n",
       "      <td>6.769447</td>\n",
       "      <td>15.751678</td>\n",
       "      <td>60.598649</td>\n",
       "      <td>65.935484</td>\n",
       "      <td>55.016129</td>\n",
       "      <td>15.888138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.019092e+11</td>\n",
       "      <td>306.491058</td>\n",
       "      <td>6.363594</td>\n",
       "      <td>15.173285</td>\n",
       "      <td>49.958137</td>\n",
       "      <td>53.766667</td>\n",
       "      <td>45.350000</td>\n",
       "      <td>9.976743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29440.0</td>\n",
       "      <td>2.019100e+11</td>\n",
       "      <td>239.577465</td>\n",
       "      <td>10.169014</td>\n",
       "      <td>17.470588</td>\n",
       "      <td>42.774648</td>\n",
       "      <td>48.500000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>5.985915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>601 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            STATION_NUMBER          TIME         DIR      SPEED       GUST  \\\n",
       "YEAR MONTH                                                                   \n",
       "1906 1             29440.0  1.906012e+11  218.181818  13.204301        NaN   \n",
       "     2             29440.0  1.906021e+11  178.095238  13.142857        NaN   \n",
       "     3             29440.0  1.906032e+11  232.043011  15.021505        NaN   \n",
       "     4             29440.0  1.906042e+11  232.045455  13.811111        NaN   \n",
       "     5             29440.0  1.906052e+11  192.820513  10.333333        NaN   \n",
       "     6             29440.0  1.906062e+11  234.222222  12.922222        NaN   \n",
       "     7             29440.0  1.906072e+11  226.923077  10.827957        NaN   \n",
       "     8             29440.0  1.906082e+11  251.627907  11.623656        NaN   \n",
       "     9             29440.0  1.906092e+11  236.986301   9.988889        NaN   \n",
       "     10            29440.0  1.906102e+11  199.397590  12.365591        NaN   \n",
       "     11            29440.0  1.906112e+11  199.166667  14.211111        NaN   \n",
       "     12            29440.0  1.906122e+11  198.636364  15.516129        NaN   \n",
       "1907 1             29440.0  1.907012e+11  190.930233  16.344086        NaN   \n",
       "     2             29440.0  1.907021e+11  223.466667  15.108434        NaN   \n",
       "     3             29440.0  1.907032e+11  238.051948  10.763441        NaN   \n",
       "     4             29440.0  1.907042e+11  201.038961  10.433333        NaN   \n",
       "     5             29440.0  1.907052e+11  244.823529  12.913978        NaN   \n",
       "     6             29440.0  1.907062e+11  202.674419  11.633333        NaN   \n",
       "     7             29440.0  1.907072e+11  215.238095  10.473118        NaN   \n",
       "     8             29440.0  1.907082e+11  221.139241   9.645161        NaN   \n",
       "     9             29440.0  1.907092e+11  258.953488  16.466667        NaN   \n",
       "     10            29440.0  1.907102e+11  192.682927  10.408602        NaN   \n",
       "     11            29440.0  1.907112e+11  204.222222  15.744444        NaN   \n",
       "     12            29440.0  1.907122e+11  166.052632  11.000000        NaN   \n",
       "1908 1             29440.0  1.908012e+11  221.547619  11.376344        NaN   \n",
       "     2             29440.0  1.908022e+11  190.864198  10.546512        NaN   \n",
       "     3             29440.0  1.908032e+11  169.315068   6.537634        NaN   \n",
       "     4             29440.0  1.908042e+11  195.333333   6.222222        NaN   \n",
       "     5             29440.0  1.908052e+11  259.718310   6.709677        NaN   \n",
       "     6             29440.0  1.908062e+11  249.651163  20.011111        NaN   \n",
       "...                    ...           ...         ...        ...        ...   \n",
       "2017 5             29440.0  2.017052e+11  340.875980   6.872531  15.628492   \n",
       "     6             29440.0  2.017062e+11  379.561190   6.904539  17.014451   \n",
       "     7             29440.0  2.017072e+11  359.269933   6.318477  15.245136   \n",
       "     8             29440.0  2.017082e+11  331.270588   6.489526  15.627178   \n",
       "     9             29440.0  2.017092e+11  304.676641   5.399907  14.788660   \n",
       "     10            29440.0  2.017102e+11  277.448502   6.535569  16.598854   \n",
       "     11            29440.0  2.017112e+11  215.835272   7.165504  16.026846   \n",
       "     12            29440.0  2.017122e+11  237.338195   7.908435  15.927536   \n",
       "2018 1             29440.0  2.018012e+11  269.553613   6.898274  17.351792   \n",
       "     2             29440.0  2.018021e+11  224.710831   5.870871  14.937500   \n",
       "     3             29440.0  2.018032e+11  292.265435   6.066968  15.392857   \n",
       "     4             29440.0  2.018042e+11  350.141509   5.704087  15.216981   \n",
       "     5             29440.0  2.018052e+11  422.810552   5.387764  14.819095   \n",
       "     6             29440.0  2.018062e+11  445.827233   7.056325  18.480337   \n",
       "     7             29440.0  2.018072e+11  408.614487   5.607442  15.902778   \n",
       "     8             29440.0  2.018082e+11  396.655422   6.515248  16.764179   \n",
       "     9             29440.0  2.018092e+11  290.531856   7.879109  20.581481   \n",
       "     10            29440.0  2.018102e+11  256.174656   7.452370  17.902685   \n",
       "     11            29440.0  2.018111e+11  303.893491   6.950848  16.097473   \n",
       "     12            29440.0  2.018122e+11  281.960321   6.531746  14.872807   \n",
       "2019 1             29440.0  2.019012e+11  279.460600   5.835289  17.300813   \n",
       "     2             29440.0  2.019021e+11  252.858576   9.232639  17.908511   \n",
       "     3             29440.0  2.019032e+11  281.606481   7.907805  17.462687   \n",
       "     4             29440.0  2.019042e+11  309.035306   5.932188  15.868217   \n",
       "     5             29440.0  2.019052e+11  367.198506   7.738381  17.553719   \n",
       "     6             29440.0  2.019062e+11  370.992008   8.138490  17.251852   \n",
       "     7             29440.0  2.019072e+11  294.433641   5.785714  15.034722   \n",
       "     8             29440.0  2.019082e+11  320.335766   6.769447  15.751678   \n",
       "     9             29440.0  2.019092e+11  306.491058   6.363594  15.173285   \n",
       "     10            29440.0  2.019100e+11  239.577465  10.169014  17.470588   \n",
       "\n",
       "               TEMP_F        MAX        MIN     TEMP_C  \n",
       "YEAR MONTH                                              \n",
       "1906 1      25.526882        NaN        NaN  -3.596177  \n",
       "     2      25.797619        NaN        NaN  -3.445767  \n",
       "     3      22.806452        NaN        NaN  -5.107527  \n",
       "     4      38.822222        NaN        NaN   3.790123  \n",
       "     5      55.526882        NaN        NaN  13.070490  \n",
       "     6      61.244444        NaN        NaN  16.246914  \n",
       "     7      65.849462        NaN        NaN  18.805257  \n",
       "     8      56.462366        NaN        NaN  13.590203  \n",
       "     9      47.500000        NaN        NaN   8.611111  \n",
       "     10     39.849462        NaN        NaN   4.360812  \n",
       "     11     32.533333        NaN        NaN   0.296296  \n",
       "     12     24.645161        NaN        NaN  -4.086022  \n",
       "1907 1      14.172043        NaN        NaN  -9.904421  \n",
       "     2      22.036145        NaN        NaN  -5.535475  \n",
       "     3      29.580645        NaN        NaN  -1.344086  \n",
       "     4      36.111111        NaN        NaN   2.283951  \n",
       "     5      44.688172        NaN        NaN   7.048984  \n",
       "     6      57.755556        NaN        NaN  14.308642  \n",
       "     7      62.462366        NaN        NaN  16.923536  \n",
       "     8      54.752688        NaN        NaN  12.640382  \n",
       "     9      48.533333        NaN        NaN   9.185185  \n",
       "     10     47.268817        NaN        NaN   8.482676  \n",
       "     11     33.155556        NaN        NaN   0.641975  \n",
       "     12     10.413043        NaN        NaN -11.992754  \n",
       "1908 1      20.688172        NaN        NaN  -6.284349  \n",
       "     2      22.558140        NaN        NaN  -5.245478  \n",
       "     3      24.182796        NaN        NaN  -4.342891  \n",
       "     4      36.811111        NaN        NaN   2.672840  \n",
       "     5      46.494624        NaN        NaN   8.052569  \n",
       "     6      57.711111        NaN        NaN  14.283951  \n",
       "...               ...        ...        ...        ...  \n",
       "2017 5      47.137668  53.580645  40.387097   8.409816  \n",
       "     6      54.920019  60.566667  49.516667  12.733344  \n",
       "     7      58.780974  64.345455  53.581818  14.878319  \n",
       "     8      58.148165  62.229508  53.590164  14.526758  \n",
       "     9      50.127501  53.300000  46.600000  10.070834  \n",
       "     10     39.133514  41.918033  36.098361   3.963063  \n",
       "     11     35.523456  37.200000  33.368421   1.957475  \n",
       "     12     31.105002  33.016393  28.758065  -0.497221  \n",
       "2018 1      25.072142  26.816667  21.637931  -3.848810  \n",
       "     2      14.445549  18.196429  10.196429  -9.752473  \n",
       "     3      20.558371  25.491525  12.423729  -6.356461  \n",
       "     4      38.951887  44.175439  32.844828   3.862159  \n",
       "     5      58.325143  63.512195  48.658537  14.625079  \n",
       "     6      57.843109  63.754717  51.000000  14.357283  \n",
       "     7      69.251354  75.262295  63.688525  20.695197  \n",
       "     8      62.400182  67.833333  57.350000  16.888990  \n",
       "     9      54.055409  57.833333  49.648148  12.253005  \n",
       "     10     42.096950  45.229508  37.672131   5.609417  \n",
       "     11     36.585723  38.510638  34.085106   2.547624  \n",
       "     12     26.672736  27.901961  23.173077  -2.959591  \n",
       "2019 1      17.884529  21.474576  12.700000  -7.841929  \n",
       "     2      28.971230  32.672727  24.545455  -1.682650  \n",
       "     3      29.485388  32.870968  24.870968  -1.397007  \n",
       "     4      42.472030  48.810345  35.847458   5.817794  \n",
       "     5      47.965553  52.907407  43.462963   8.869752  \n",
       "     6      61.743400  67.316667  55.600000  16.524111  \n",
       "     7      61.569955  67.774194  55.903226  16.427753  \n",
       "     8      60.598649  65.935484  55.016129  15.888138  \n",
       "     9      49.958137  53.766667  45.350000   9.976743  \n",
       "     10     42.774648  48.500000  41.000000   5.985915  \n",
       "\n",
       "[601 rows x 9 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting warm months\n",
    "\n",
    "Now, we have aggregated our data on monthly level and all we need to do is to check which years had the warmest April temperatures. A simple approach is to select all aprils from the data, group the data and check which group(s) have the highest mean value:\n",
    "\n",
    "- select all records that are from April (regardless of the year):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "aprils = data[data[\"MONTH\"]==4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- take a subset of columns that might contain interesting information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "aprils = aprils[['STATION_NUMBER','TEMP_F', 'TEMP_C','YEAR', 'MONTH']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- group by year and month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = aprils.groupby(by=[\"YEAR\", \"MONTH\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- calculate mean for each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>STATION_NUMBER</th>\n",
       "      <th>TEMP_F</th>\n",
       "      <th>TEMP_C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <th>4</th>\n",
       "      <td>29440</td>\n",
       "      <td>38.822222</td>\n",
       "      <td>3.790123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <th>4</th>\n",
       "      <td>29440</td>\n",
       "      <td>36.111111</td>\n",
       "      <td>2.283951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <th>4</th>\n",
       "      <td>29440</td>\n",
       "      <td>36.811111</td>\n",
       "      <td>2.672840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <th>4</th>\n",
       "      <td>29440</td>\n",
       "      <td>31.977778</td>\n",
       "      <td>-0.012346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <th>4</th>\n",
       "      <td>29440</td>\n",
       "      <td>39.833333</td>\n",
       "      <td>4.351852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            STATION_NUMBER     TEMP_F    TEMP_C\n",
       "YEAR MONTH                                     \n",
       "1906 4               29440  38.822222  3.790123\n",
       "1907 4               29440  36.111111  2.283951\n",
       "1908 4               29440  36.811111  2.672840\n",
       "1909 4               29440  31.977778 -0.012346\n",
       "1910 4               29440  39.833333  4.351852"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_mean = grouped.mean()\n",
    "monthly_mean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check the highest temperature values (sort the data frame in a descending order):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>STATION_NUMBER</th>\n",
       "      <th>TEMP_F</th>\n",
       "      <th>TEMP_C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <th>4</th>\n",
       "      <td>29440</td>\n",
       "      <td>42.472030</td>\n",
       "      <td>5.817794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <th>4</th>\n",
       "      <td>29440</td>\n",
       "      <td>41.918084</td>\n",
       "      <td>5.510047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <th>4</th>\n",
       "      <td>29440</td>\n",
       "      <td>41.369647</td>\n",
       "      <td>5.205360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <th>4</th>\n",
       "      <td>29440</td>\n",
       "      <td>41.290730</td>\n",
       "      <td>5.161517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <th>4</th>\n",
       "      <td>29440</td>\n",
       "      <td>41.249676</td>\n",
       "      <td>5.138709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <th>4</th>\n",
       "      <td>29440</td>\n",
       "      <td>41.132353</td>\n",
       "      <td>5.073529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <th>4</th>\n",
       "      <td>29440</td>\n",
       "      <td>41.016183</td>\n",
       "      <td>5.008991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <th>4</th>\n",
       "      <td>29440</td>\n",
       "      <td>40.962343</td>\n",
       "      <td>4.979079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <th>4</th>\n",
       "      <td>29440</td>\n",
       "      <td>40.777778</td>\n",
       "      <td>4.876543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <th>4</th>\n",
       "      <td>29440</td>\n",
       "      <td>40.695291</td>\n",
       "      <td>4.830717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            STATION_NUMBER     TEMP_F    TEMP_C\n",
       "YEAR MONTH                                     \n",
       "2019 4               29440  42.472030  5.817794\n",
       "1990 4               29440  41.918084  5.510047\n",
       "1989 4               29440  41.369647  5.205360\n",
       "2011 4               29440  41.290730  5.161517\n",
       "2004 4               29440  41.249676  5.138709\n",
       "2002 4               29440  41.132353  5.073529\n",
       "1983 4               29440  41.016183  5.008991\n",
       "2008 4               29440  40.962343  4.979079\n",
       "2000 4               29440  40.777778  4.876543\n",
       "1999 4               29440  40.695291  4.830717"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_mean.sort_values(by=\"TEMP_C\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did April 2019 rank at the Tampere Pirkkala observation station ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeating the data analysis with larger dataset\n",
    "\n",
    "\n",
    "Finally, let's repeat the data analysis steps above for all the available data we have (!!). First, confirm the path to the **folder** where all the input data are located. \n",
    "The idea is, that we will repeat the analysis process for each input file using a (rather long) for loop! Here we have all the main analysis steps with some additional output info - all in one long code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATION NUMBER: 29440\n",
      "NUMBER OF OBSERVATIONS: 757983\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "2019 4               29440  42.472030  5.817794\n",
      "1990 4               29440  41.918084  5.510047\n",
      "1989 4               29440  41.369647  5.205360\n",
      "2011 4               29440  41.290730  5.161517\n",
      "2004 4               29440  41.249676  5.138709\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read selected columns of  data using varying amount of spaces as separator and specifying * characters as NoData values\n",
    "data = pd.read_csv(fp, delim_whitespace=True, usecols=['USAF','YR--MODAHRMN', 'DIR', 'SPD', 'GUS','TEMP', 'MAX', 'MIN'], na_values=['*', '**', '***', '****', '*****', '******'])\n",
    "\n",
    "# Rename the columns\n",
    "new_names = {'USAF':'STATION_NUMBER','YR--MODAHRMN': 'TIME', 'SPD': 'SPEED', 'GUS': 'GUST', 'TEMP':'TEMP_F'}\n",
    "data = data.rename(columns=new_names)\n",
    "\n",
    "#Print info about the current input file:\n",
    "print(\"STATION NUMBER:\", data.at[0,\"STATION_NUMBER\"])\n",
    "print(\"NUMBER OF OBSERVATIONS:\", len(data))\n",
    "\n",
    "# Create column\n",
    "col_name = 'TEMP_C'\n",
    "data[col_name] = None\n",
    "\n",
    "# Convert tempetarues from Fahrenheits to Celsius\n",
    "data[\"TEMP_C\"] = data[\"TEMP_F\"].apply(fahr_to_celsius)\n",
    "\n",
    "# Convert TIME to string \n",
    "data['TIME_STR'] = data['TIME'].astype(str)\n",
    "\n",
    "# Parse year and month\n",
    "data['MONTH'] = data['TIME_STR'].str.slice(start=5, stop=6).astype(int)\n",
    "data['YEAR'] = data['TIME_STR'].str.slice(start=0, stop=4).astype(int)\n",
    "\n",
    "# Extract observations for the months of April \n",
    "aprils = data[data['MONTH']==4]\n",
    "\n",
    "# Take a subset of columns\n",
    "aprils = aprils[['STATION_NUMBER','TEMP_F', 'TEMP_C', 'YEAR', 'MONTH']]\n",
    "\n",
    "# Group by year and month\n",
    "grouped = aprils.groupby(by=[\"YEAR\", \"MONTH\"])\n",
    "\n",
    "# Get mean values for each group\n",
    "monthly_mean = grouped.mean()\n",
    "\n",
    "# Print info\n",
    "print(monthly_mean.sort_values(by=\"TEMP_C\", ascending=False).head(5))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `glob()` function from the module `glob` to list our input files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(r'data/0*txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note**\n",
    "\n",
    "Note that we're using the \\* character as a wildcard, so any file that starts with `data/0` and ends with `txt` will be added to the list of files we will iterate over. We specifically use `data/0` as the starting part of the file names to avoid having our metadata files included in the list!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in the list 15\n",
      "['data\\\\028360.txt', 'data\\\\028690.txt', 'data\\\\028750.txt', 'data\\\\028970.txt', 'data\\\\029070.txt', 'data\\\\029110.txt', 'data\\\\029170.txt', 'data\\\\029350.txt', 'data\\\\029440.txt', 'data\\\\029500.txt', 'data\\\\029700.txt', 'data\\\\029720.txt', 'data\\\\029740.txt', 'data\\\\029810.txt', 'data\\\\029820.txt']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of files in the list\", len(file_list))\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you should have all the relevant file names in a list, and we can loop over the list using a for-loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\028360.txt\n",
      "data\\028690.txt\n",
      "data\\028750.txt\n",
      "data\\028970.txt\n",
      "data\\029070.txt\n",
      "data\\029110.txt\n",
      "data\\029170.txt\n",
      "data\\029350.txt\n",
      "data\\029440.txt\n",
      "data\\029500.txt\n",
      "data\\029700.txt\n",
      "data\\029720.txt\n",
      "data\\029740.txt\n",
      "data\\029810.txt\n",
      "data\\029820.txt\n"
     ]
    }
   ],
   "source": [
    "for fp in file_list:\n",
    "    print(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATION NUMBER: 28360\n",
      "NUMBER OF OBSERVATIONS: 193825\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "1937 4               28360  38.738095  3.743386\n",
      "2011 4               28360  36.699571  2.610873\n",
      "1921 4               28360  36.622222  2.567901\n",
      "2002 4               28360  36.500000  2.500000\n",
      "2019 4               28360  34.979138  1.655076\n",
      "\n",
      "\n",
      "STATION NUMBER: 28690\n",
      "NUMBER OF OBSERVATIONS: 542788\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "2011 4               28690  35.430640  1.905911\n",
      "2019 4               28690  35.215114  1.786174\n",
      "2016 4               28690  35.031103  1.683946\n",
      "1989 4               28690  34.612766  1.451537\n",
      "2002 4               28690  34.279855  1.266586\n",
      "\n",
      "\n",
      "STATION NUMBER: 28750\n",
      "NUMBER OF OBSERVATIONS: 474562\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "1989 4               28750  39.008403  3.893557\n",
      "1983 4               28750  38.758475  3.754708\n",
      "2019 4               28750  38.651599  3.695333\n",
      "2002 4               28750  38.270419  3.483566\n",
      "1994 4               28750  38.145833  3.414352\n",
      "\n",
      "\n",
      "STATION NUMBER: 28970\n",
      "NUMBER OF OBSERVATIONS: 555740\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "1921 4               28970  41.688889  5.382716\n",
      "1999 4               28970  39.073600  3.929778\n",
      "2019 4               28970  38.706456  3.725809\n",
      "1989 4               28970  38.362869  3.534927\n",
      "2011 4               28970  38.094172  3.385651\n",
      "\n",
      "\n",
      "STATION NUMBER: 29070\n",
      "NUMBER OF OBSERVATIONS: 83567\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "2014 4               29070  35.437326  1.909626\n",
      "2015 4               29070  34.437209  1.354005\n",
      "2004 4               29070  34.347032  1.303907\n",
      "2016 4               29070  34.303199  1.279555\n",
      "2008 4               29070  34.241667  1.245370\n",
      "\n",
      "\n",
      "STATION NUMBER: 29110\n",
      "NUMBER OF OBSERVATIONS: 483784\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "1921 4               29110  42.166667  5.648148\n",
      "2004 4               29110  41.682699  5.379277\n",
      "1989 4               29110  41.420168  5.233427\n",
      "1937 4               29110  40.671429  4.817460\n",
      "2019 4               29110  40.636300  4.797945\n",
      "\n",
      "\n",
      "STATION NUMBER: 29170\n",
      "NUMBER OF OBSERVATIONS: 561097\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "1937 4               29170  43.289157  6.271754\n",
      "2019 4               29170  40.666820  4.814900\n",
      "2011 4               29170  40.015962  4.453312\n",
      "2001 4               29170  39.713228  4.285126\n",
      "1906 4               29170  39.688889  4.271605\n",
      "\n",
      "\n",
      "STATION NUMBER: 29350\n",
      "NUMBER OF OBSERVATIONS: 559667\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "1921 4               29350  45.144444  7.302469\n",
      "1925 4               29350  40.777778  4.876543\n",
      "2011 4               29350  40.670108  4.816727\n",
      "2019 4               29350  40.585002  4.769446\n",
      "2001 4               29350  39.662827  4.257126\n",
      "\n",
      "\n",
      "STATION NUMBER: 29440\n",
      "NUMBER OF OBSERVATIONS: 757983\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "2019 4               29440  42.472030  5.817794\n",
      "1990 4               29440  41.918084  5.510047\n",
      "1989 4               29440  41.369647  5.205360\n",
      "2011 4               29440  41.290730  5.161517\n",
      "2004 4               29440  41.249676  5.138709\n",
      "\n",
      "\n",
      "STATION NUMBER: 29500\n",
      "NUMBER OF OBSERVATIONS: 103105\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "2019 4               29500  41.639777  5.355432\n",
      "2008 4               29500  40.838936  4.910520\n",
      "2014 4               29500  40.226415  4.570231\n",
      "2016 4               29500  39.176634  3.987019\n",
      "2011 4               29500  38.647826  3.693237\n",
      "\n",
      "\n",
      "STATION NUMBER: 29700\n",
      "NUMBER OF OBSERVATIONS: 473881\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "1921 4               29700  42.811111  6.006173\n",
      "2000 4               29700  42.375587  5.764215\n",
      "1990 4               29700  42.054167  5.585648\n",
      "2019 4               29700  41.548747  5.304859\n",
      "2004 4               29700  41.493392  5.274107\n",
      "\n",
      "\n",
      "STATION NUMBER: 29720\n",
      "NUMBER OF OBSERVATIONS: 843688\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "2019 4               29720  43.558414  6.421341\n",
      "1990 4               29720  43.313576  6.285320\n",
      "2000 4               29720  42.663169  5.923983\n",
      "2008 4               29720  42.349642  5.749801\n",
      "2004 4               29720  41.903492  5.501940\n",
      "\n",
      "\n",
      "STATION NUMBER: 29740\n",
      "NUMBER OF OBSERVATIONS: 931767\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "2000 4               29740  43.479793  6.377663\n",
      "2019 4               29740  43.464070  6.368928\n",
      "1990 4               29740  43.375078  6.319488\n",
      "2008 4               29740  43.341429  6.300794\n",
      "2011 4               29740  42.750702  5.972612\n",
      "\n",
      "\n",
      "STATION NUMBER: 29810\n",
      "NUMBER OF OBSERVATIONS: 199330\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "1990 4               29810  41.157895  5.087719\n",
      "2019 4               29810  40.783032  4.879462\n",
      "2014 4               29810  40.058036  4.476687\n",
      "2008 4               29810  40.044881  4.469378\n",
      "2016 4               29810  39.270308  4.039060\n",
      "\n",
      "\n",
      "STATION NUMBER: 29820\n",
      "NUMBER OF OBSERVATIONS: 198334\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "2019 4               29820  41.182197  5.101221\n",
      "1990 4               29820  41.144681  5.080378\n",
      "2014 4               29820  40.497908  4.721060\n",
      "2008 4               29820  39.941423  4.411901\n",
      "1913 4               29820  39.622222  4.234568\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Repeat the analysis steps for each input file:\n",
    "for fp in file_list:\n",
    "\n",
    "    # Read selected columns of  data using varying amount of spaces as separator and specifying * characters as NoData values\n",
    "    data = pd.read_csv(fp, delim_whitespace=True, usecols=['USAF','YR--MODAHRMN', 'DIR', 'SPD', 'GUS','TEMP', 'MAX', 'MIN'], na_values=['*', '**', '***', '****', '*****', '******'])\n",
    "\n",
    "    # Rename the columns\n",
    "    new_names = {'USAF':'STATION_NUMBER','YR--MODAHRMN': 'TIME', 'SPD': 'SPEED', 'GUS': 'GUST', 'TEMP':'TEMP_F'}\n",
    "    data = data.rename(columns=new_names)\n",
    "\n",
    "    #Print info about the current input file:\n",
    "    print(\"STATION NUMBER:\", data.at[0,\"STATION_NUMBER\"])\n",
    "    print(\"NUMBER OF OBSERVATIONS:\", len(data))\n",
    "\n",
    "    # Create column\n",
    "    col_name = 'TEMP_C'\n",
    "    data[col_name] = None\n",
    "\n",
    "    # Convert tempetarues from Fahrenheits to Celsius\n",
    "    data[\"TEMP_C\"] = data[\"TEMP_F\"].apply(fahr_to_celsius)\n",
    "\n",
    "    # Convert TIME to string \n",
    "    data['TIME_STR'] = data['TIME'].astype(str)\n",
    "\n",
    "    # Parse year and month\n",
    "    data['MONTH'] = data['TIME_STR'].str.slice(start=5, stop=6).astype(int)\n",
    "    data['YEAR'] = data['TIME_STR'].str.slice(start=0, stop=4).astype(int)\n",
    "\n",
    "    # Extract observations for the months of April \n",
    "    aprils = data[data['MONTH']==4]\n",
    "\n",
    "    # Take a subset of columns\n",
    "    aprils = aprils[['STATION_NUMBER','TEMP_F', 'TEMP_C', 'YEAR', 'MONTH']]\n",
    "\n",
    "    # Group by year and month\n",
    "    grouped = aprils.groupby(by=[\"YEAR\", \"MONTH\"])\n",
    "\n",
    "    # Get mean values for each group\n",
    "    monthly_mean = grouped.mean()\n",
    "\n",
    "    # Print info\n",
    "    print(monthly_mean.sort_values(by=\"TEMP_C\", ascending=False).head(5))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about now, how did April 2019 rank across different stations?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
