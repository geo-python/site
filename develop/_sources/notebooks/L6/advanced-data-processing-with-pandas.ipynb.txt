{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing with Pandas, part 2\n",
    "\n",
    "This week we will continue developing our skills using [pandas](https://pandas.pydata.org/) to process real data. \n",
    "\n",
    "Case: April 2019 happened to be the second warmest April on record globally. \n",
    "In this lesson, we will use our data manipulation and analysis skills to analyze weather data from Finland, and see if April 2019 was exceptionally warm also here.\n",
    "\n",
    "We will cover a number of useful techniques in pandas including:\n",
    "\n",
    "- renaming columns\n",
    "- iterating data frame rows and applying functions\n",
    "- data aggregation\n",
    "- repeating the analysis task for several input files \n",
    "\n",
    "\n",
    "## Input data\n",
    "In the lesson this week we are using weather observation data from Finland downloaded from NOAA. We have data for 15 different weather obsercation stations from Finland. \n",
    "\n",
    "\n",
    "**METADATA:**\n",
    "\n",
    "- List of available stations: [metadata/6367598020644stn.txt](metadata/6367598020644stn.txt)\n",
    "- More details about weather observatios per station: [metadata/6367598020644inv.txt](metadata/6367598020644inv.txt)\n",
    "- Data description (column names): [metadata/3505doc.txt](metadata/3505doc.txt)\n",
    "\n",
    "\n",
    "The input data for this week is separated with varying amount of spaces (fixed width). The first lines and columns of the data looks like following:\n",
    "\n",
    "``` \n",
    "    \n",
    "      USAF  WBAN YR--MODAHRMN DIR SPD GUS CLG SKC L M H  VSB MW MW MW MW AW AW AW AW W TEMP DEWP    SLP  ... SD\n",
    "    028360 99999 191701010600 360   5 *** *** SCT * * *  0.0 ** ** ** ** ** ** ** ** *    3 ****  986.0  ... ** \n",
    "    028360 99999 191701011300 ***   0 *** *** OVC * * *  0.0 ** ** ** ** ** ** ** ** *  -14 ****  986.6  ... ** \n",
    "    028360 99999 191701012000 ***   0 *** *** BKN * * *  0.0 ** ** ** ** ** ** ** ** *   -7 ****  986.6  ... ** \n",
    "    028360 99999 191701020600 360   2 *** *** OVC * * *  0.0 ** ** ** ** ** ** ** ** *  -14 ****  984.7  ... ** \n",
    "\n",
    "    \n",
    "```\n",
    "\n",
    "**We will develop our analysis workflow using data for one station. Then' we will repeat the same process for all the stations.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data\n",
    "In order to get startet, let's import pandas: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, you should have already had a look at the input file and how it is structured. We can notice at least two things we need to consider when reading in the data:\n",
    "\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**NOTE: Input data structure**\n",
    "\n",
    "- **Delimiter:** The data are **separated with varying amount of spaces**. If you check out the documentation for the [read_csv() method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html), you can see that there are two different ways of doing this. We can either use the `sep` or `delim_whitespace` parameter;  `sep='\\s+'` or `delim_whitespace=True` but not both. In this case, we prefer to use `delim_whitespace`.\n",
    "\n",
    "- **No Data values:** No data values in the NOAA data are coded with varyingg number of `*`. We can tell pandas to consider those characters as NaNs by specifying `na_values=['*', '**', '***', '****', '*****', '******']`.\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\HYapp\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (29,30,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "fp = r\"C:\\LocalData\\VUOKKHEI\\codes\\Geo-Python\\data\\weather_data\\029350.txt\"\n",
    "\n",
    "# Read data using varying amount of spaces as separator and specifying * characters as NoData values\n",
    "data = pd.read_csv(fp, delim_whitespace=True, na_values=['*', '**', '***', '****', '*****', '******'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's see how the data looks by printing the first five rows with `head()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    USAF   WBAN  YR--MODAHRMN    DIR  SPD  GUS  CLG  SKC   L   M ...    SLP  \\\n",
      "0  29350  99999  191701010600  320.0  5.0  NaN  NaN  CLR NaN NaN ...  993.2   \n",
      "1  29350  99999  191701011300  320.0  7.0  NaN  NaN  CLR NaN NaN ...  995.1   \n",
      "2  29350  99999  191701012000  320.0  5.0  NaN  NaN  SCT NaN NaN ...  996.8   \n",
      "3  29350  99999  191701021300    NaN  0.0  NaN  NaN  OVC NaN NaN ...  996.7   \n",
      "4  29350  99999  191701022000    NaN  0.0  NaN  NaN  CLR NaN NaN ...  997.0   \n",
      "\n",
      "   ALT  STP  MAX  MIN  PCP01  PCP06  PCP24  PCPXX  SD  \n",
      "0  NaN  NaN  NaN  NaN    NaN    NaN    NaN    NaN NaN  \n",
      "1  NaN  NaN  NaN  NaN    NaN    NaN    NaN    NaN NaN  \n",
      "2  NaN  NaN  NaN  NaN    NaN    NaN    NaN    NaN NaN  \n",
      "3  NaN  NaN  NaN  NaN    NaN    NaN    NaN    NaN NaN  \n",
      "4  NaN  NaN  NaN  NaN    NaN    NaN    NaN    NaN NaN  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All seems ok. However, we won't be needing all of the 33 columns for detecting warm temperatures in April. We can check all column names by running `data.columns`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['USAF', 'WBAN', 'YR--MODAHRMN', 'DIR', 'SPD', 'GUS', 'CLG', 'SKC', 'L',\n",
       "       'M', 'H', 'VSB', 'MW', 'MW.1', 'MW.2', 'MW.3', 'AW', 'AW.1', 'AW.2',\n",
       "       'AW.3', 'W', 'TEMP', 'DEWP', 'SLP', 'ALT', 'STP', 'MAX', 'MIN', 'PCP01',\n",
       "       'PCP06', 'PCP24', 'PCPXX', 'SD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description for all these columns is available in the metadata file [metadata/3505doc.txt](metadata/3505doc.txt). \n",
    "\n",
    "**Let's read in the data one more time.** This time, we will read in only some of the columns using the `usecols` parameter. Let's read in columns that might be somehow useful to our analysis, or at least that contain some values that are meaningful to us, including the station name, timestamp, and data about wind and temperature: `'USAF','YR--MODAHRMN', 'DIR', 'SPD', 'GUS','TEMP', 'MAX', 'MIN'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USAF</th>\n",
       "      <th>YR--MODAHRMN</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPD</th>\n",
       "      <th>GUS</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701010600</td>\n",
       "      <td>320.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701011300</td>\n",
       "      <td>320.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701012000</td>\n",
       "      <td>320.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701021300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701022000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    USAF  YR--MODAHRMN    DIR  SPD  GUS  TEMP  MAX  MIN\n",
       "0  29350  191701010600  320.0  5.0  NaN   6.0  NaN  NaN\n",
       "1  29350  191701011300  320.0  7.0  NaN   2.0  NaN  NaN\n",
       "2  29350  191701012000  320.0  5.0  NaN  -8.0  NaN  NaN\n",
       "3  29350  191701021300    NaN  0.0  NaN  -4.0  NaN  NaN\n",
       "4  29350  191701022000    NaN  0.0  NaN -12.0  NaN  NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(fp, delim_whitespace=True, usecols=['USAF','YR--MODAHRMN', 'DIR', 'SPD', 'GUS','TEMP', 'MAX', 'MIN'], na_values=['*', '**', '***', '****', '*****', '******'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so we can see that the data was successfully read to the DataFrame and we also seemed to be able to convert the asterix (\\*) characters into `NaN` -values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renaming columns\n",
    "\n",
    "Check again the column names in our DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['USAF', 'YR--MODAHRMN', 'DIR', 'SPD', 'GUS', 'TEMP', 'MAX', 'MIN'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column names that we have are somewhat ackward. Let's change them into more intuitive ones. \n",
    "This can be done easily using the `rename()` -method and a dictionary that lists old and new column names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Dictionaries**\n",
    "\n",
    "[Dictionary](https://docs.python.org/2/tutorial/datastructures.html#dictionaries) is a spesific data structure in Python for storing key-value pairs. During this course, we will use dictionaries mainly when renaming columns in a pandas series, but dictionaries are useful for many different purposes! For more information about Python dictionaries, check out [this tutorial](https://realpython.com/python-dicts/).\n",
    "    \n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define the new column names using a [dictionary](https://www.tutorialspoint.com/python/python_dictionary.htm) where we determine \"`key: value`\" -pairs, in which the original column name (the one which will be replaced) is the key, and the new column name is the value.\n",
    "\n",
    "- Let's change:\n",
    "   \n",
    "   - `YR--MODAHRMN` column into `TIME`, \n",
    "   - `SPD` into `SPEED`, and\n",
    "   - `GUS` into `GUST`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SPD': 'SPEED', 'YR--MODAHRMN': 'TIME', 'GUS': 'GUST'}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Create the dictionary with old and new names\n",
    "new_names = {'YR--MODAHRMN': 'TIME', 'SPD': 'SPEED', 'GUS': 'GUST'}\n",
    "\n",
    "# Let's see what they look like and what is the type\n",
    "print(new_names)\n",
    "print(type(new_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above we can see that we have successfully created a dictionary that is of type `dict`. \n",
    "\n",
    "- Now we can change the column names by passing that dictionary into parameter `columns` in `rename()` -function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['USAF', 'TIME', 'DIR', 'SPEED', 'GUST', 'TEMP', 'MAX', 'MIN'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Rename the columns\n",
    "data = data.rename(columns=new_names)\n",
    "\n",
    "# Print the new columns\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect, now our column names are more easy to understand and use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**TASK: Renaming columns**\n",
    "\n",
    "The temperature values are again in Fahrenheit. As you might guess, we will soon convert these temperatures in to Celsius. In order to avoid confusion with the columns, rename column `TEMP` into `TEMP_F`. Also, we could rename `USAF` as`STATION_NUMBER`.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_NUMBER</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>GUST</th>\n",
       "      <th>TEMP_F</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701010600</td>\n",
       "      <td>320.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701011300</td>\n",
       "      <td>320.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701012000</td>\n",
       "      <td>320.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701021300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701022000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATION_NUMBER          TIME    DIR  SPEED  GUST  TEMP_F  MAX  MIN\n",
       "0           29350  191701010600  320.0    5.0   NaN     6.0  NaN  NaN\n",
       "1           29350  191701011300  320.0    7.0   NaN     2.0  NaN  NaN\n",
       "2           29350  191701012000  320.0    5.0   NaN    -8.0  NaN  NaN\n",
       "3           29350  191701021300    NaN    0.0   NaN    -4.0  NaN  NaN\n",
       "4           29350  191701022000    NaN    0.0   NaN   -12.0  NaN  NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the dictionary with old and new names\n",
    "new_names = {'USAF':'STATION_NUMBER', 'TEMP': 'TEMP_F'}\n",
    "\n",
    "# Rename the columns\n",
    "data = data.rename(columns=new_names)\n",
    "\n",
    "# Check the output\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check dataframe properties\n",
    "\n",
    "As we learned last week, it's always a good idea to check basic properties of the input data before proceeding with data analysis. Let's check:\n",
    "\n",
    "- How many rows and columns we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(559667, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Top and bottom rows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_NUMBER</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>GUST</th>\n",
       "      <th>TEMP_F</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701010600</td>\n",
       "      <td>320.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701011300</td>\n",
       "      <td>320.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701012000</td>\n",
       "      <td>320.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701021300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701022000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATION_NUMBER          TIME    DIR  SPEED  GUST  TEMP_F  MAX  MIN\n",
       "0           29350  191701010600  320.0    5.0   NaN     6.0  NaN  NaN\n",
       "1           29350  191701011300  320.0    7.0   NaN     2.0  NaN  NaN\n",
       "2           29350  191701012000  320.0    5.0   NaN    -8.0  NaN  NaN\n",
       "3           29350  191701021300    NaN    0.0   NaN    -4.0  NaN  NaN\n",
       "4           29350  191701022000    NaN    0.0   NaN   -12.0  NaN  NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_NUMBER</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>GUST</th>\n",
       "      <th>TEMP_F</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>559662</th>\n",
       "      <td>29350</td>\n",
       "      <td>201910012220</td>\n",
       "      <td>990.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559663</th>\n",
       "      <td>29350</td>\n",
       "      <td>201910012250</td>\n",
       "      <td>990.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559664</th>\n",
       "      <td>29350</td>\n",
       "      <td>201910012300</td>\n",
       "      <td>260.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559665</th>\n",
       "      <td>29350</td>\n",
       "      <td>201910012320</td>\n",
       "      <td>990.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559666</th>\n",
       "      <td>29350</td>\n",
       "      <td>201910012350</td>\n",
       "      <td>990.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        STATION_NUMBER          TIME    DIR  SPEED  GUST  TEMP_F  MAX  MIN\n",
       "559662           29350  201910012220  990.0    5.0   NaN    37.0  NaN  NaN\n",
       "559663           29350  201910012250  990.0    7.0   NaN    37.0  NaN  NaN\n",
       "559664           29350  201910012300  260.0    4.0   NaN    38.0  NaN  NaN\n",
       "559665           29350  201910012320  990.0    7.0   NaN    37.0  NaN  NaN\n",
       "559666           29350  201910012350  990.0    5.0   NaN    37.0  NaN  NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Data types of the columns: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATION_NUMBER      int64\n",
       "TIME                int64\n",
       "DIR               float64\n",
       "SPEED             float64\n",
       "GUST              float64\n",
       "TEMP_F            float64\n",
       "MAX               float64\n",
       "MIN               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Descriptive statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       STATION_NUMBER          TIME            DIR          SPEED  \\\n",
      "count        559667.0  5.596670e+05  519843.000000  553514.000000   \n",
      "mean          29350.0  2.002912e+11     282.237183       6.235060   \n",
      "std               0.0  1.800321e+09     247.127478       4.216836   \n",
      "min           29350.0  1.917010e+11       1.000000       0.000000   \n",
      "25%           29350.0  2.001122e+11     140.000000       3.000000   \n",
      "50%           29350.0  2.008061e+11     220.000000       6.000000   \n",
      "75%           29350.0  2.013110e+11     320.000000       9.000000   \n",
      "max           29350.0  2.019100e+11     990.000000      66.000000   \n",
      "\n",
      "              GUST         TEMP_F           MAX           MIN  \n",
      "count  9916.000000  555794.000000  30271.000000  30268.000000  \n",
      "mean     21.325534      39.039754     43.731030     32.457975  \n",
      "std       7.367612      18.833681     19.378822     18.427926  \n",
      "min      11.000000     -37.000000    -28.000000    -48.000000  \n",
      "25%      15.000000      28.000000     30.000000     23.000000  \n",
      "50%      21.000000      39.000000     43.000000     33.000000  \n",
      "75%      26.000000      54.000000     60.000000     46.000000  \n",
      "max      54.000000      95.000000     94.000000     81.000000  \n"
     ]
    }
   ],
   "source": [
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that there are varying number of observations per column (see the `count` -information), because some of the columns have missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using your own functions in pandas \n",
    "\n",
    "Now it's again time to convert temperatures from Fahrenheit to Celsius! Yes, we have already done this many times before, but this time we will learn how to apply self-made functions to data in a pandas DataFrame.\n",
    "**In short, our task is to define a function for the temperature conversion, and to apply this function for each Celsius value on each row of the DataFrame. Output celsius values should be stored in a new column called** `TEMP_C`.\n",
    "\n",
    "Knowing how to use your own function in pandas can be really useful when doing your own analyses. Here, we will introduce two different approaches for using function in pandas. First, we will see how we can apply the function row-by-row using a `for`-loop and the `DataFrame.iterrows()`-method, and then we will learn how to apply the method to all rows at once using [DataFrame.apply](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.apply.html).\n",
    "\n",
    "For both of these approaches, we first need to define our temperature conversion function from Fahrenheit to Celsius:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fahr_to_celsius(temp_fahrenheit):\n",
    "    \"\"\"\n",
    "    Function to convert Fahrenheit temperature into Celsius.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    temp_fahrenheit: int | float\n",
    "        Input temperature in Fahrenheit (should be a number)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    Temperature in Celsius (float)\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the Fahrenheit into Celsius and return it\n",
    "    converted_temp = (temp_fahrenheit - 32) / 1.8\n",
    "    return converted_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** with such a simple example, we could use the function direcly on a column in the DataFrame in order to conver the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_NUMBER</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>GUST</th>\n",
       "      <th>TEMP_F</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>TEMP_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701010600</td>\n",
       "      <td>320.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701011300</td>\n",
       "      <td>320.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701012000</td>\n",
       "      <td>320.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701021300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701022000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-24.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATION_NUMBER          TIME    DIR  SPEED  GUST  TEMP_F  MAX  MIN  \\\n",
       "0           29350  191701010600  320.0    5.0   NaN     6.0  NaN  NaN   \n",
       "1           29350  191701011300  320.0    7.0   NaN     2.0  NaN  NaN   \n",
       "2           29350  191701012000  320.0    5.0   NaN    -8.0  NaN  NaN   \n",
       "3           29350  191701021300    NaN    0.0   NaN    -4.0  NaN  NaN   \n",
       "4           29350  191701022000    NaN    0.0   NaN   -12.0  NaN  NaN   \n",
       "\n",
       "      TEMP_C  \n",
       "0 -14.444444  \n",
       "1 -16.666667  \n",
       "2 -22.222222  \n",
       "3 -20.000000  \n",
       "4 -24.444444  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"TEMP_C\"] = fahr_to_celsius(data[\"TEMP_F\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to do something more complicated, we need to know how to apply the function row-by-row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating over rows\n",
    "\n",
    "We can iterate over the rows of Pandas DataFrame by using the `iterrows()` -method and use the function one row at a time.\n",
    "\n",
    "\n",
    "When iterating over the rows in our `DataFrame`, it is noteworthy to understand that the Pandas actually keeps track on the `index` value as well. Hence, the contents of a single row actually contains not only the values, but also the `index` of that row (each row is a pandas Series!). \n",
    "\n",
    "- Let's see how `iterrows()` works by printing out the `TEMP` value on each row using a `for`-loop:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0\n",
      "Temp F: 6.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the rows\n",
    "for idx, row in data.iterrows():\n",
    "    # Print the index value\n",
    "    print('Index:', idx)\n",
    "    \n",
    "    # Print the row\n",
    "    print('Temp F:', row[\"TEMP_F\"], \"\\n\")\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**break**\n",
    "\n",
    "When developing a for-loop, you don't always need to go trough the whole loop if you just want to test things out. \n",
    "[break](https://www.tutorialspoint.com/python/python_break_statement.htm) statement in Python terminates the current loop after the first iteration and we used it here just to test check out the values on the first row.\n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the `idx` variable indeed contains the index value at position 0 (the first row) and the `row` variable contains all the data from that given row stored as a pandas `Series`.\n",
    "\n",
    "- Let's now create an empty column `TEMP_C` for the Celsius temperatures and update the values into that column using the `fahr_to_celsius` function we defined earlier:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty column for the DataFrame where the values will be stored\n",
    "new_column = \"TEMP_C\"\n",
    "data[new_column] = None\n",
    "\n",
    "# Iterate over the rows \n",
    "for idx, row in data.iterrows():\n",
    "    # Convert the Fahrenheit to Celsius\n",
    "    celsius = fahr_to_celsius(row['TEMP_F'])\n",
    "    \n",
    "    # Update the value of 'Celsius' column with the converted value\n",
    "    data.at[idx, new_column] = celsius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**.at or .loc?**\n",
    "\n",
    "Here, you could also use `data.loc[idx, new_column] = celsius` to achieve the same result. \n",
    "    \n",
    "If you only need to access a single value in a DataFrame, [DataFrame.at](https://pandas.pydata.org/pandas-docs/version/0.25/reference/api/pandas.DataFrame.at.html) is faster compared to [DataFrame.loc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html) which is designed for accessing groups of rows and columns.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's see what we have now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_NUMBER</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>GUST</th>\n",
       "      <th>TEMP_F</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>TEMP_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701010600</td>\n",
       "      <td>320.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.4444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701011300</td>\n",
       "      <td>320.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16.6667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701012000</td>\n",
       "      <td>320.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701021300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701022000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-24.4444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701030600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701031300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-17.7778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701032000</td>\n",
       "      <td>320.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16.6667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701040600</td>\n",
       "      <td>110.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701041300</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.4444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATION_NUMBER          TIME    DIR  SPEED  GUST  TEMP_F  MAX  MIN   TEMP_C\n",
       "0           29350  191701010600  320.0    5.0   NaN     6.0  NaN  NaN -14.4444\n",
       "1           29350  191701011300  320.0    7.0   NaN     2.0  NaN  NaN -16.6667\n",
       "2           29350  191701012000  320.0    5.0   NaN    -8.0  NaN  NaN -22.2222\n",
       "3           29350  191701021300    NaN    0.0   NaN    -4.0  NaN  NaN      -20\n",
       "4           29350  191701022000    NaN    0.0   NaN   -12.0  NaN  NaN -24.4444\n",
       "5           29350  191701030600    NaN    0.0   NaN    -8.0  NaN  NaN -22.2222\n",
       "6           29350  191701031300    NaN    0.0   NaN     0.0  NaN  NaN -17.7778\n",
       "7           29350  191701032000  320.0    5.0   NaN     2.0  NaN  NaN -16.6667\n",
       "8           29350  191701040600  110.0   14.0   NaN     5.0  NaN  NaN      -15\n",
       "9           29350  191701041300   70.0    2.0   NaN     6.0  NaN  NaN -14.4444"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now we have converted our temperatures into Celsius by using our self-made function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas DataFrames and Series also have a dedicated method `.apply()` for applying functions on columns (or rows!). When using `.apply()`, we pass the function name (without parenthesis!) as an argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_NUMBER</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>GUST</th>\n",
       "      <th>TEMP_F</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>TEMP_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701010600</td>\n",
       "      <td>320.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701011300</td>\n",
       "      <td>320.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701012000</td>\n",
       "      <td>320.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701021300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701022000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-24.444444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATION_NUMBER          TIME    DIR  SPEED  GUST  TEMP_F  MAX  MIN  \\\n",
       "0           29350  191701010600  320.0    5.0   NaN     6.0  NaN  NaN   \n",
       "1           29350  191701011300  320.0    7.0   NaN     2.0  NaN  NaN   \n",
       "2           29350  191701012000  320.0    5.0   NaN    -8.0  NaN  NaN   \n",
       "3           29350  191701021300    NaN    0.0   NaN    -4.0  NaN  NaN   \n",
       "4           29350  191701022000    NaN    0.0   NaN   -12.0  NaN  NaN   \n",
       "\n",
       "      TEMP_C  \n",
       "0 -14.444444  \n",
       "1 -16.666667  \n",
       "2 -22.222222  \n",
       "3 -20.000000  \n",
       "4 -24.444444  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"TEMP_C\"] = data[\"TEMP_F\"].apply(fahr_to_celsius)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** pay attention which column you are applying the function on! Running this code: `data.apply(fahr_to_celsius)` would not give an error, but the results also don't make much sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Should I use .iterrows() or .apply()?**\n",
    "\n",
    "We are teaching the `.iterrows()` method because it helps to understand the structure of a DataFrame and the process of looping trough DataFrame rows. However, using `.apply()` is often more efficient in terms of execution time. \n",
    "    \n",
    "    \n",
    "At this point, the most important thing is that you understand what happens when you are modifying the values in a pandas DataFrame. When doing the course exercises, either of these approaches is ok!\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing dates\n",
    "\n",
    "We will eventually want to group our data based on month in order to see if April temperatures in 2019 were higher than average. Currently, the date and time information is stored in the column `TIME`:\n",
    "\n",
    "`YR--MODAHRMN = YEAR-MONTH-DAY-HOUR-MINUTE IN GREENWICH MEAN TIME (GMT)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a closer look at the date and time information we have by checking the values in that column, and their data type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    191701010600\n",
       "1    191701011300\n",
       "2    191701012000\n",
       "3    191701021300\n",
       "4    191701022000\n",
       "5    191701030600\n",
       "6    191701031300\n",
       "7    191701032000\n",
       "8    191701040600\n",
       "9    191701041300\n",
       "Name: TIME, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"TIME\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "559657    201910012050\n",
       "559658    201910012100\n",
       "559659    201910012120\n",
       "559660    201910012150\n",
       "559661    201910012200\n",
       "559662    201910012220\n",
       "559663    201910012250\n",
       "559664    201910012300\n",
       "559665    201910012320\n",
       "559666    201910012350\n",
       "Name: TIME, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"TIME\"].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `TIME` column contains several observations per day (and even several observations per hour). The timestamp for the first observation is `191701010600`, i.e. from 1st of January 1917, and the timestamp for the latest observation is `201910012350` (from last week, by the time of writing this!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"TIME\"].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the information is stored as integer values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several different options for proceeding from here. The bottom line is, that we would want to **aggregate the data on a monthly level**, and in order to do so we need to \"label\" each row of data based on the month when the record was observed. \n",
    "In practice, we could create a new column (or an index), which contains information about the month (including the year, but excluding hours and minutes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String slicing\n",
    "\n",
    "One approach would be to convert the date and time information into character strings and \"cut\" the needed information from the [string objects](https://docs.python.org/3/tutorial/introduction.html#strings). If we look at the latest time stamp in the data (`201910012350`), you can see that there is a systematic pattern `YEAR-MONTH-DAY-HOUR-MINUTE`. Four first characters represent the year, and six first characters are year + month!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'201910'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date = \"201910012350\"\n",
    "date[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing this in pandas requires two steps:\n",
    "  1. Convert the `TIME` column from `int` into `str` datatype.\n",
    "  2. Slice the correct range of characters from the character string using [pandas.Series.str.slice()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.slice.html)\n",
    "\n",
    "- Let's convert the time into string. And check that the data type changes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Convert to string\n",
    "data['TIME_STR'] = data['TIME'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   STATION_NUMBER          TIME    DIR  SPEED  GUST  TEMP_F  MAX  MIN  \\\n",
      "0           29350  191701010600  320.0    5.0   NaN     6.0  NaN  NaN   \n",
      "1           29350  191701011300  320.0    7.0   NaN     2.0  NaN  NaN   \n",
      "2           29350  191701012000  320.0    5.0   NaN    -8.0  NaN  NaN   \n",
      "3           29350  191701021300    NaN    0.0   NaN    -4.0  NaN  NaN   \n",
      "4           29350  191701022000    NaN    0.0   NaN   -12.0  NaN  NaN   \n",
      "\n",
      "      TEMP_C      TIME_STR MONTH_STR  \n",
      "0 -14.444444  191701010600    191701  \n",
      "1 -16.666667  191701011300    191701  \n",
      "2 -22.222222  191701012000    191701  \n",
      "3 -20.000000  191701021300    191701  \n",
      "4 -24.444444  191701022000    191701  \n"
     ]
    }
   ],
   "source": [
    "# SLice the string\n",
    "data['MONTH_STR'] = data['TIME_STR'].str.slice(start=0, stop=6)\n",
    "\n",
    "# Let's see what we have\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Now we have \"labeled\" the rows based on information about day of the year and hour of the day. However, let's have a look at a more clever way of dealing with dates and times.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Pandas datetime**\n",
    "\n",
    "In pandas, we can convert dates and times into a new data type [datetime](https://docs.python.org/3.7/library/datetime.html) using [pandas.to_datetime](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html) function. First, it is important to understand the structure of the input data in order to avoid erroneous conversions, and that's why we first learned string slicing before introducing the datetime functionalities. \n",
    "    \n",
    "Here is one example of how to convert the `TIME_STR`-column in our data set to datetime:\n",
    "    \n",
    "```\n",
    "# Convert to datetime\n",
    "data[\"DATE\"] = pd.to_datetime(data[\"TIME_STR\"])\n",
    "\n",
    "```\n",
    "   \n",
    "        \n",
    "If needed, you can use the `format` parameter to define the output datetime format according to [strftime(format) method](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior). together with `exact=False`, for example like this: \n",
    "    \n",
    "```\n",
    "# Convert to datetime\n",
    "data[\"DATE\"] = pd.to_datetime(data[\"TIME_STR\"], format='%Y%m%d%H', exact=False)\n",
    "\n",
    "```\n",
    "In this example, `exact=False` drops out minutes and secods, because they are not included in the specified formatting.\n",
    " \n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   1917-01-01 06:00:00\n",
       "1   1917-01-01 13:00:00\n",
       "2   1917-01-01 20:00:00\n",
       "3   1917-01-02 13:00:00\n",
       "4   1917-01-02 20:00:00\n",
       "Name: DATE, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to datetime\n",
    "data[\"DATE\"] = pd.to_datetime(data[\"TIME_STR\"])\n",
    "data[\"DATE\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: in this case, the data type of the values is `datetime`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Pandas Series datetime properties**\n",
    "    \n",
    "There are several methods available for accessing information about the properties of datetime values. Read more from the pandas documentation about [datetime properties](https://pandas.pydata.org/pandas-docs/stable/reference/series.html#datetime-properties).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can extract different time units based on the datetime-column using the [pandas.Series.dt accessor](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1917\n",
       "1         1917\n",
       "2         1917\n",
       "3         1917\n",
       "4         1917\n",
       "5         1917\n",
       "6         1917\n",
       "7         1917\n",
       "8         1917\n",
       "9         1917\n",
       "10        1917\n",
       "11        1917\n",
       "12        1917\n",
       "13        1917\n",
       "14        1917\n",
       "15        1917\n",
       "16        1917\n",
       "17        1917\n",
       "18        1917\n",
       "19        1917\n",
       "20        1917\n",
       "21        1917\n",
       "22        1917\n",
       "23        1917\n",
       "24        1917\n",
       "25        1917\n",
       "26        1917\n",
       "27        1917\n",
       "28        1917\n",
       "29        1917\n",
       "          ... \n",
       "559637    2019\n",
       "559638    2019\n",
       "559639    2019\n",
       "559640    2019\n",
       "559641    2019\n",
       "559642    2019\n",
       "559643    2019\n",
       "559644    2019\n",
       "559645    2019\n",
       "559646    2019\n",
       "559647    2019\n",
       "559648    2019\n",
       "559649    2019\n",
       "559650    2019\n",
       "559651    2019\n",
       "559652    2019\n",
       "559653    2019\n",
       "559654    2019\n",
       "559655    2019\n",
       "559656    2019\n",
       "559657    2019\n",
       "559658    2019\n",
       "559659    2019\n",
       "559660    2019\n",
       "559661    2019\n",
       "559662    2019\n",
       "559663    2019\n",
       "559664    2019\n",
       "559665    2019\n",
       "559666    2019\n",
       "Name: DATE, Length: 559667, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['DATE'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also combine the datetime functionalities with other methods from pandas. For example, we can check the number of unique years in our input data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['DATE'].dt.year.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**TASK:**\n",
    "\n",
    "- Create two new columns: `YEAR` and `MONTH` based on the date column\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_NUMBER</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>GUST</th>\n",
       "      <th>TEMP_F</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>TEMP_C</th>\n",
       "      <th>TIME_STR</th>\n",
       "      <th>MONTH_STR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701010600</td>\n",
       "      <td>320.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.444444</td>\n",
       "      <td>191701010600</td>\n",
       "      <td>191701</td>\n",
       "      <td>1917-01-01 06:00:00</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701011300</td>\n",
       "      <td>320.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16.666667</td>\n",
       "      <td>191701011300</td>\n",
       "      <td>191701</td>\n",
       "      <td>1917-01-01 13:00:00</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701012000</td>\n",
       "      <td>320.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.222222</td>\n",
       "      <td>191701012000</td>\n",
       "      <td>191701</td>\n",
       "      <td>1917-01-01 20:00:00</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701021300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>191701021300</td>\n",
       "      <td>191701</td>\n",
       "      <td>1917-01-02 13:00:00</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701022000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-24.444444</td>\n",
       "      <td>191701022000</td>\n",
       "      <td>191701</td>\n",
       "      <td>1917-01-02 20:00:00</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATION_NUMBER          TIME    DIR  SPEED  GUST  TEMP_F  MAX  MIN  \\\n",
       "0           29350  191701010600  320.0    5.0   NaN     6.0  NaN  NaN   \n",
       "1           29350  191701011300  320.0    7.0   NaN     2.0  NaN  NaN   \n",
       "2           29350  191701012000  320.0    5.0   NaN    -8.0  NaN  NaN   \n",
       "3           29350  191701021300    NaN    0.0   NaN    -4.0  NaN  NaN   \n",
       "4           29350  191701022000    NaN    0.0   NaN   -12.0  NaN  NaN   \n",
       "\n",
       "      TEMP_C      TIME_STR MONTH_STR                DATE  YEAR  MONTH  \n",
       "0 -14.444444  191701010600    191701 1917-01-01 06:00:00  1917      1  \n",
       "1 -16.666667  191701011300    191701 1917-01-01 13:00:00  1917      1  \n",
       "2 -22.222222  191701012000    191701 1917-01-01 20:00:00  1917      1  \n",
       "3 -20.000000  191701021300    191701 1917-01-02 13:00:00  1917      1  \n",
       "4 -24.444444  191701022000    191701 1917-01-02 20:00:00  1917      1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['YEAR'] = data['DATE'].dt.year\n",
    "data['MONTH'] = data['DATE'].dt.month\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating data in Pandas by grouping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will learn how to use [pandas.DataFrame.groupby](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) which is a handy method for compressing large amounts of data and computing statistics for subgroups.\n",
    "\n",
    "Our practical task is to calculate the average temperatures for each month\n",
    "\n",
    "This can be done by aggregating the data, i.e.:\n",
    "\n",
    "  1. **grouping the data** based on year and month\n",
    "  2. Calculating the average for each month (each group) either by using a for-loop or directly from the grouped object\n",
    "  3. Storing those values into **a new DataFrame** `monthly_data`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start grouping the data, let's once more check how our input data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows: 559667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION_NUMBER</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>GUST</th>\n",
       "      <th>TEMP_F</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>TEMP_C</th>\n",
       "      <th>TIME_STR</th>\n",
       "      <th>MONTH_STR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701010600</td>\n",
       "      <td>320.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.444444</td>\n",
       "      <td>191701010600</td>\n",
       "      <td>191701</td>\n",
       "      <td>1917-01-01 06:00:00</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701011300</td>\n",
       "      <td>320.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-16.666667</td>\n",
       "      <td>191701011300</td>\n",
       "      <td>191701</td>\n",
       "      <td>1917-01-01 13:00:00</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701012000</td>\n",
       "      <td>320.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-22.222222</td>\n",
       "      <td>191701012000</td>\n",
       "      <td>191701</td>\n",
       "      <td>1917-01-01 20:00:00</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701021300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-20.000000</td>\n",
       "      <td>191701021300</td>\n",
       "      <td>191701</td>\n",
       "      <td>1917-01-02 13:00:00</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29350</td>\n",
       "      <td>191701022000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-24.444444</td>\n",
       "      <td>191701022000</td>\n",
       "      <td>191701</td>\n",
       "      <td>1917-01-02 20:00:00</td>\n",
       "      <td>1917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATION_NUMBER          TIME    DIR  SPEED  GUST  TEMP_F  MAX  MIN  \\\n",
       "0           29350  191701010600  320.0    5.0   NaN     6.0  NaN  NaN   \n",
       "1           29350  191701011300  320.0    7.0   NaN     2.0  NaN  NaN   \n",
       "2           29350  191701012000  320.0    5.0   NaN    -8.0  NaN  NaN   \n",
       "3           29350  191701021300    NaN    0.0   NaN    -4.0  NaN  NaN   \n",
       "4           29350  191701022000    NaN    0.0   NaN   -12.0  NaN  NaN   \n",
       "\n",
       "      TEMP_C      TIME_STR MONTH_STR                DATE  YEAR  MONTH  \n",
       "0 -14.444444  191701010600    191701 1917-01-01 06:00:00  1917      1  \n",
       "1 -16.666667  191701011300    191701 1917-01-01 13:00:00  1917      1  \n",
       "2 -22.222222  191701012000    191701 1917-01-01 20:00:00  1917      1  \n",
       "3 -20.000000  191701021300    191701 1917-01-02 13:00:00  1917      1  \n",
       "4 -24.444444  191701022000    191701 1917-01-02 20:00:00  1917      1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"number of rows:\", len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have quite a few rows of weather data, and several observations per day (and even per hour). **Our goal is to create an aggreated data frame that would have only one row per month!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's **group** our data based on unique year and month combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = data.groupby([\"YEAR\", \"MONTH\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**NOTE:**\n",
    "    \n",
    "Here you could also group the data based on the `MONTH_STR` column to achieve the same result:\n",
    "    \n",
    "```\n",
    "# Group the data \n",
    "grouped = data.groupby('MONTH_STR')\n",
    "```\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's see what we have now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:\n",
      " <class 'pandas.core.groupby.groupby.DataFrameGroupBy'>\n",
      "Length:\n",
      " 826\n"
     ]
    }
   ],
   "source": [
    "# What is the type?\n",
    "print(\"Type:\\n\", type(grouped))\n",
    "\n",
    "# How many?\n",
    "print(\"Length:\\n\", len(grouped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okey, interesting. Now we have a new object with type `DataFrameGroupBy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**TASK:**\n",
    "\n",
    "Think: what does the number of groups (length of the grouped object) tell us?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "826"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer: the length of the grouped object should be the same as\n",
    "data[\"MONTH_STR\"].nunique()\n",
    "\n",
    "# in other words, the number of groups is the number of unique year and month combinations in our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several methods we can use for extracting information from the grouped data. See [documentation for Pandas GroupBy objects](https://pandas.pydata.org/pandas-docs/stable/reference/groupby.html) for a comprehensive overview. \n",
    "\n",
    "**Checking group names:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the \"names\" of each group (comment out the next row if you want to print out the result!)\n",
    "#grouped.groups.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accessing data for one group:**\n",
    "\n",
    "- Let's check the contents for a group representing August 2019 (name of that group is `(2019, 4)` if you grouped the data based on datetime columns `YEAR` and `MONTH`). We can get the values of that hour from the grouped object using the `get_group()` -method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        STATION_NUMBER          TIME    DIR  SPEED  GUST  TEMP_F   MAX   MIN  \\\n",
      "546832           29350  201904010000  290.0    9.0   NaN    29.0   NaN   NaN   \n",
      "546833           29350  201904010050  330.0    6.0   NaN    28.0   NaN   NaN   \n",
      "546834           29350  201904010100  280.0    9.0   NaN    29.0   NaN   NaN   \n",
      "546835           29350  201904010120  310.0    7.0   NaN    28.0   NaN   NaN   \n",
      "546836           29350  201904010150  320.0    3.0   NaN    27.0   NaN   NaN   \n",
      "546837           29350  201904010200  290.0    2.0   NaN    28.0   NaN   NaN   \n",
      "546838           29350  201904010220  290.0    5.0   NaN    27.0   NaN   NaN   \n",
      "546839           29350  201904010250  300.0    6.0   NaN    27.0   NaN   NaN   \n",
      "546840           29350  201904010300  300.0    9.0   NaN    28.0   NaN   NaN   \n",
      "546841           29350  201904010320  320.0    8.0   NaN    27.0   NaN   NaN   \n",
      "546842           29350  201904010350  310.0   10.0   NaN    27.0   NaN   NaN   \n",
      "546843           29350  201904010400  300.0   13.0   NaN    28.0   NaN   NaN   \n",
      "546844           29350  201904010420  290.0   13.0   NaN    28.0   NaN   NaN   \n",
      "546845           29350  201904010450  290.0   13.0   NaN    28.0   NaN   NaN   \n",
      "546846           29350  201904010500  290.0   13.0   NaN    29.0   NaN   NaN   \n",
      "546847           29350  201904010520  300.0   14.0   NaN    28.0   NaN   NaN   \n",
      "546848           29350  201904010550  300.0   15.0   NaN    28.0   NaN   NaN   \n",
      "546849           29350  201904010600  300.0   16.0   NaN    30.0  33.0  24.0   \n",
      "546850           29350  201904010620  300.0   15.0   NaN    30.0   NaN   NaN   \n",
      "546851           29350  201904010650  300.0   17.0   NaN    30.0   NaN   NaN   \n",
      "546852           29350  201904010700  310.0   16.0   NaN    31.0   NaN   NaN   \n",
      "546853           29350  201904010720  300.0   14.0   NaN    32.0   NaN   NaN   \n",
      "546854           29350  201904010750  300.0   11.0   NaN    32.0   NaN   NaN   \n",
      "546855           29350  201904010800  290.0   11.0   NaN    34.0   NaN   NaN   \n",
      "546856           29350  201904010820  290.0   14.0   NaN    34.0   NaN   NaN   \n",
      "546857           29350  201904010850  290.0   14.0   NaN    34.0   NaN   NaN   \n",
      "546858           29350  201904010900  300.0   16.0   NaN    35.0   NaN   NaN   \n",
      "546859           29350  201904010920  990.0   13.0   NaN    36.0   NaN   NaN   \n",
      "546860           29350  201904010950  270.0   17.0   NaN    36.0   NaN   NaN   \n",
      "546861           29350  201904011000  280.0    9.0   NaN    37.0   NaN   NaN   \n",
      "...                ...           ...    ...    ...   ...     ...   ...   ...   \n",
      "548949           29350  201904301400  240.0    4.0   NaN    59.0   NaN   NaN   \n",
      "548950           29350  201904301420  990.0    8.0   NaN    61.0   NaN   NaN   \n",
      "548951           29350  201904301450  990.0    8.0   NaN    61.0   NaN   NaN   \n",
      "548952           29350  201904301500  290.0    7.0   NaN    62.0   NaN   NaN   \n",
      "548953           29350  201904301520  280.0    9.0   NaN    61.0   NaN   NaN   \n",
      "548954           29350  201904301550  990.0   10.0   NaN    61.0   NaN   NaN   \n",
      "548955           29350  201904301600  260.0    7.0   NaN    61.0   NaN   NaN   \n",
      "548956           29350  201904301620  990.0    8.0   NaN    59.0   NaN   NaN   \n",
      "548957           29350  201904301650  990.0    7.0   NaN    57.0   NaN   NaN   \n",
      "548958           29350  201904301700  230.0    4.0   NaN    57.0   NaN   NaN   \n",
      "548959           29350  201904301720  990.0   10.0   NaN    57.0   NaN   NaN   \n",
      "548960           29350  201904301750  270.0   10.0   NaN    55.0   NaN   NaN   \n",
      "548961           29350  201904301800  270.0    9.0   NaN    54.0  62.0  46.0   \n",
      "548962           29350  201904301820  270.0    9.0   NaN    54.0   NaN   NaN   \n",
      "548963           29350  201904301850  260.0    8.0   NaN    52.0   NaN   NaN   \n",
      "548964           29350  201904301900  270.0    7.0   NaN    52.0   NaN   NaN   \n",
      "548965           29350  201904301920  270.0    7.0   NaN    50.0   NaN   NaN   \n",
      "548966           29350  201904301950  260.0    9.0   NaN    50.0   NaN   NaN   \n",
      "548967           29350  201904302000  270.0    7.0   NaN    49.0   NaN   NaN   \n",
      "548968           29350  201904302020  280.0    8.0   NaN    48.0   NaN   NaN   \n",
      "548969           29350  201904302050  260.0    6.0   NaN    48.0   NaN   NaN   \n",
      "548970           29350  201904302100  260.0    4.0   NaN    47.0   NaN   NaN   \n",
      "548971           29350  201904302120  260.0    6.0   NaN    46.0   NaN   NaN   \n",
      "548972           29350  201904302150  990.0    3.0   NaN    45.0   NaN   NaN   \n",
      "548973           29350  201904302200  280.0    4.0   NaN    45.0   NaN   NaN   \n",
      "548974           29350  201904302220  990.0    2.0   NaN    43.0   NaN   NaN   \n",
      "548975           29350  201904302250  990.0    1.0   NaN    41.0   NaN   NaN   \n",
      "548976           29350  201904302300  240.0    2.0   NaN    40.0   NaN   NaN   \n",
      "548977           29350  201904302320  990.0    2.0   NaN    39.0   NaN   NaN   \n",
      "548978           29350  201904302350  110.0    2.0   NaN    37.0   NaN   NaN   \n",
      "\n",
      "           TEMP_C      TIME_STR MONTH_STR                DATE  YEAR  MONTH  \n",
      "546832  -1.666667  201904010000    201904 2019-04-01 00:00:00  2019      4  \n",
      "546833  -2.222222  201904010050    201904 2019-04-01 00:50:00  2019      4  \n",
      "546834  -1.666667  201904010100    201904 2019-04-01 01:00:00  2019      4  \n",
      "546835  -2.222222  201904010120    201904 2019-04-01 01:20:00  2019      4  \n",
      "546836  -2.777778  201904010150    201904 2019-04-01 01:50:00  2019      4  \n",
      "546837  -2.222222  201904010200    201904 2019-04-01 02:00:00  2019      4  \n",
      "546838  -2.777778  201904010220    201904 2019-04-01 02:20:00  2019      4  \n",
      "546839  -2.777778  201904010250    201904 2019-04-01 02:50:00  2019      4  \n",
      "546840  -2.222222  201904010300    201904 2019-04-01 03:00:00  2019      4  \n",
      "546841  -2.777778  201904010320    201904 2019-04-01 03:20:00  2019      4  \n",
      "546842  -2.777778  201904010350    201904 2019-04-01 03:50:00  2019      4  \n",
      "546843  -2.222222  201904010400    201904 2019-04-01 04:00:00  2019      4  \n",
      "546844  -2.222222  201904010420    201904 2019-04-01 04:20:00  2019      4  \n",
      "546845  -2.222222  201904010450    201904 2019-04-01 04:50:00  2019      4  \n",
      "546846  -1.666667  201904010500    201904 2019-04-01 05:00:00  2019      4  \n",
      "546847  -2.222222  201904010520    201904 2019-04-01 05:20:00  2019      4  \n",
      "546848  -2.222222  201904010550    201904 2019-04-01 05:50:00  2019      4  \n",
      "546849  -1.111111  201904010600    201904 2019-04-01 06:00:00  2019      4  \n",
      "546850  -1.111111  201904010620    201904 2019-04-01 06:20:00  2019      4  \n",
      "546851  -1.111111  201904010650    201904 2019-04-01 06:50:00  2019      4  \n",
      "546852  -0.555556  201904010700    201904 2019-04-01 07:00:00  2019      4  \n",
      "546853   0.000000  201904010720    201904 2019-04-01 07:20:00  2019      4  \n",
      "546854   0.000000  201904010750    201904 2019-04-01 07:50:00  2019      4  \n",
      "546855   1.111111  201904010800    201904 2019-04-01 08:00:00  2019      4  \n",
      "546856   1.111111  201904010820    201904 2019-04-01 08:20:00  2019      4  \n",
      "546857   1.111111  201904010850    201904 2019-04-01 08:50:00  2019      4  \n",
      "546858   1.666667  201904010900    201904 2019-04-01 09:00:00  2019      4  \n",
      "546859   2.222222  201904010920    201904 2019-04-01 09:20:00  2019      4  \n",
      "546860   2.222222  201904010950    201904 2019-04-01 09:50:00  2019      4  \n",
      "546861   2.777778  201904011000    201904 2019-04-01 10:00:00  2019      4  \n",
      "...           ...           ...       ...                 ...   ...    ...  \n",
      "548949  15.000000  201904301400    201904 2019-04-30 14:00:00  2019      4  \n",
      "548950  16.111111  201904301420    201904 2019-04-30 14:20:00  2019      4  \n",
      "548951  16.111111  201904301450    201904 2019-04-30 14:50:00  2019      4  \n",
      "548952  16.666667  201904301500    201904 2019-04-30 15:00:00  2019      4  \n",
      "548953  16.111111  201904301520    201904 2019-04-30 15:20:00  2019      4  \n",
      "548954  16.111111  201904301550    201904 2019-04-30 15:50:00  2019      4  \n",
      "548955  16.111111  201904301600    201904 2019-04-30 16:00:00  2019      4  \n",
      "548956  15.000000  201904301620    201904 2019-04-30 16:20:00  2019      4  \n",
      "548957  13.888889  201904301650    201904 2019-04-30 16:50:00  2019      4  \n",
      "548958  13.888889  201904301700    201904 2019-04-30 17:00:00  2019      4  \n",
      "548959  13.888889  201904301720    201904 2019-04-30 17:20:00  2019      4  \n",
      "548960  12.777778  201904301750    201904 2019-04-30 17:50:00  2019      4  \n",
      "548961  12.222222  201904301800    201904 2019-04-30 18:00:00  2019      4  \n",
      "548962  12.222222  201904301820    201904 2019-04-30 18:20:00  2019      4  \n",
      "548963  11.111111  201904301850    201904 2019-04-30 18:50:00  2019      4  \n",
      "548964  11.111111  201904301900    201904 2019-04-30 19:00:00  2019      4  \n",
      "548965  10.000000  201904301920    201904 2019-04-30 19:20:00  2019      4  \n",
      "548966  10.000000  201904301950    201904 2019-04-30 19:50:00  2019      4  \n",
      "548967   9.444444  201904302000    201904 2019-04-30 20:00:00  2019      4  \n",
      "548968   8.888889  201904302020    201904 2019-04-30 20:20:00  2019      4  \n",
      "548969   8.888889  201904302050    201904 2019-04-30 20:50:00  2019      4  \n",
      "548970   8.333333  201904302100    201904 2019-04-30 21:00:00  2019      4  \n",
      "548971   7.777778  201904302120    201904 2019-04-30 21:20:00  2019      4  \n",
      "548972   7.222222  201904302150    201904 2019-04-30 21:50:00  2019      4  \n",
      "548973   7.222222  201904302200    201904 2019-04-30 22:00:00  2019      4  \n",
      "548974   6.111111  201904302220    201904 2019-04-30 22:20:00  2019      4  \n",
      "548975   5.000000  201904302250    201904 2019-04-30 22:50:00  2019      4  \n",
      "548976   4.444444  201904302300    201904 2019-04-30 23:00:00  2019      4  \n",
      "548977   3.888889  201904302320    201904 2019-04-30 23:20:00  2019      4  \n",
      "548978   2.777778  201904302350    201904 2019-04-30 23:50:00  2019      4  \n",
      "\n",
      "[2147 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Specify the time of the first hour (as text)\n",
    "month = (2019, 4)\n",
    "\n",
    "# Select the group\n",
    "group1 = grouped.get_group(month)\n",
    "\n",
    "# Let's see what we have\n",
    "print(group1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahaa! As we can see, a single group contains a **DataFrame** with values only for that specific month. Let's check the DataType of this group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(group1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, one group is a pandas DataFrame! This is really useful, because we can now use all the familiar DataFrame methods for calculating statistics etc for this spesific group. \n",
    "We can, for example, calculate the average values for all variables using the statistical functions that we have seen already (e.g. mean, std, min, max, median, etc.).\n",
    "\n",
    "We can do that by using the `mean()` -function that we already used during the Lesson 5. \n",
    "\n",
    "- Let's calculate the mean for following attributes all at once:\n",
    "   - `DIR`, \n",
    "   - `SPEED`, \n",
    "   - `GUST`, \n",
    "   - `TEMP`, \n",
    "   - `TEMP_C`\n",
    "   - `MONTH` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIR       399.197218\n",
      "SPEED       6.020893\n",
      "GUST       21.416667\n",
      "TEMP_F     40.585002\n",
      "TEMP_C      4.769446\n",
      "MONTH       4.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Specify the columns that will be part of the calculation\n",
    "mean_cols = ['DIR', 'SPEED', 'GUST', 'TEMP_F', 'TEMP_C', 'MONTH']\n",
    "\n",
    "# Calculate the mean values all at one go\n",
    "mean_values = group1[mean_cols].mean()\n",
    "\n",
    "# Let's see what we have\n",
    "print(mean_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice, now we have averaged our data and e.g. the mean Celsius temperature seems to be about right when comparing to the original values above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we saw how you can access data from a single group. For getting information about all groups (all months)we can a `for` -loop or methods available in the grouped object.\n",
    "\n",
    "**For-loops and grouped objects:**\n",
    "\n",
    "When iterating over the groups in our `DataFrameGroupBy` -object\n",
    "it is important to understand that a single group in our `DataFrameGroupBy` actually contains not only the actual values, but also information about the `key` that was used to do the grouping. Hence, when iterating over the data we need to assign the `key` and the values into separate variables.\n",
    "\n",
    "- Let's see how we can iterate over the groups and print the key and the data from a single group (again using `break` to only see what is happening).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key:\n",
      " (1917, 1)\n",
      "\n",
      "First rows of data in this group:\n",
      "    STATION_NUMBER          TIME    DIR  SPEED  GUST  TEMP_F  MAX  MIN  \\\n",
      "0           29350  191701010600  320.0    5.0   NaN     6.0  NaN  NaN   \n",
      "1           29350  191701011300  320.0    7.0   NaN     2.0  NaN  NaN   \n",
      "2           29350  191701012000  320.0    5.0   NaN    -8.0  NaN  NaN   \n",
      "3           29350  191701021300    NaN    0.0   NaN    -4.0  NaN  NaN   \n",
      "4           29350  191701022000    NaN    0.0   NaN   -12.0  NaN  NaN   \n",
      "\n",
      "      TEMP_C      TIME_STR MONTH_STR                DATE  YEAR  MONTH  \n",
      "0 -14.444444  191701010600    191701 1917-01-01 06:00:00  1917      1  \n",
      "1 -16.666667  191701011300    191701 1917-01-01 13:00:00  1917      1  \n",
      "2 -22.222222  191701012000    191701 1917-01-01 20:00:00  1917      1  \n",
      "3 -20.000000  191701021300    191701 1917-01-02 13:00:00  1917      1  \n",
      "4 -24.444444  191701022000    191701 1917-01-02 20:00:00  1917      1  \n"
     ]
    }
   ],
   "source": [
    "# Iterate over groups\n",
    "for key, group in grouped:\n",
    "    # Print key and group\n",
    "    print(\"Key:\\n\", key)\n",
    "    print(\"\\nFirst rows of data in this group:\\n\", group.head())\n",
    "    \n",
    "    # Stop iteration with break command\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okey so from here we can see that the `key` contains the name of the group (year, month).\n",
    "\n",
    "- Let's see how we can create a DataFrame where we calculate the mean values for all those weather attributes that we were interested in. I will repeate slightly the earlier steps so that you can see and better understand what is happening.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty DataFrame for the aggregated values\n",
    "hourly_data = pd.DataFrame()\n",
    "\n",
    "# The columns that we want to aggregate\n",
    "mean_cols = ['DIR', 'SPEED', 'GUST', 'TEMP_F', 'TEMP_C', \"MONTH\"]\n",
    "\n",
    "# Iterate over the groups\n",
    "for key, group in grouped:\n",
    "   # Aggregate the data\n",
    "   mean_values = group[mean_cols].mean()\n",
    "\n",
    "   # Add the key (i.e. the date+time information) into the aggregated values\n",
    "   mean_values['YEAR_MONTH'] = key\n",
    "\n",
    "   # Append the aggregated values into the DataFrame\n",
    "   hourly_data = hourly_data.append(mean_values, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's see what we have now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            DIR       GUST  MONTH      SPEED     TEMP_C     TEMP_F  YEAR_MONTH\n",
      "0    226.250000        NaN    1.0   7.184783 -10.996377  12.206522   (1917, 1)\n",
      "1    215.945946        NaN    2.0  11.738095 -14.212963   6.416667   (1917, 2)\n",
      "2    185.769231        NaN    3.0   9.032258 -10.890084  12.397849   (1917, 3)\n",
      "3    173.717949        NaN    4.0   8.611111   0.746914  33.344444   (1917, 4)\n",
      "4    261.851852        NaN    5.0  11.591398   6.911589  44.440860   (1917, 5)\n",
      "5    211.315789        NaN    6.0   7.777778  17.820988  64.077778   (1917, 6)\n",
      "6    225.487805        NaN    7.0   6.677419  16.612903  61.903226   (1917, 7)\n",
      "7    161.971831        NaN    8.0   6.150538  18.500597  65.301075   (1917, 8)\n",
      "8    237.027027        NaN    9.0   9.966667   9.098765  48.377778   (1917, 9)\n",
      "9    162.619048        NaN   10.0  12.784946   6.164875  43.096774  (1917, 10)\n",
      "10   199.529412        NaN   11.0  13.322222  -0.364198  31.344444  (1917, 11)\n",
      "11   186.956522        NaN   12.0   8.096774  -5.746714  21.655914  (1917, 12)\n",
      "12   213.924051        NaN    1.0  11.580645 -12.968937   8.655914   (1918, 1)\n",
      "13   201.285714        NaN    2.0   8.011905  -7.810847  17.940476   (1918, 2)\n",
      "14   229.714286        NaN    3.0   8.838710  -3.130227  26.365591   (1918, 3)\n",
      "15   171.692308        NaN    4.0   6.244444   3.783951  38.811111   (1918, 4)\n",
      "16   213.294118        NaN    5.0   9.913978   8.160096  46.688172   (1918, 5)\n",
      "17   211.666667        NaN    6.0  10.800000  12.938272  55.288889   (1918, 6)\n",
      "18   195.810811        NaN    7.0   7.860215  18.207885  64.774194   (1918, 7)\n",
      "19   205.909091        NaN    8.0   6.182796  12.431302  54.376344   (1918, 8)\n",
      "20   190.142857        NaN    9.0   9.444444   8.604938  47.488889   (1918, 9)\n",
      "21   185.925926        NaN   10.0   9.408602   6.063321  42.913978  (1918, 10)\n",
      "22   189.610390        NaN   11.0  10.363636   1.445707  34.602273  (1918, 11)\n",
      "23   149.746835        NaN   12.0  10.333333  -5.537634  22.032258  (1918, 12)\n",
      "24   129.589041        NaN    1.0   6.526882  -6.057348  21.096774   (1919, 1)\n",
      "25   241.551724        NaN    2.0   7.702381 -11.170635  11.892857   (1919, 2)\n",
      "26   202.750000        NaN    3.0  12.688172  -7.072879  19.268817   (1919, 3)\n",
      "27   198.030303        NaN    4.0   9.149425   1.104651  33.988372   (1919, 4)\n",
      "28   211.617647        NaN    5.0   7.827957  10.585424  51.053763   (1919, 5)\n",
      "29   189.846154        NaN    6.0   8.275862  15.421456  59.758621   (1919, 6)\n",
      "..          ...        ...    ...        ...        ...        ...         ...\n",
      "796  405.082453  17.250000    5.0   7.452416   6.882535  44.388564   (2017, 5)\n",
      "797  406.696117  18.533613    6.0   7.273412  12.455373  54.419672   (2017, 6)\n",
      "798  395.458746  14.882353    7.0   5.807256  14.436690  57.986042   (2017, 7)\n",
      "799  425.223558  15.767196    8.0   5.856287  14.093661  57.368590   (2017, 8)\n",
      "800  346.161481  15.480000    9.0   5.072941   9.104895  48.388811   (2017, 9)\n",
      "801  305.445283  16.729469   10.0   6.762276   3.596545  38.473780  (2017, 10)\n",
      "802  363.135977  15.989189   11.0   6.149673   0.780164  33.404295  (2017, 11)\n",
      "803  353.396004  16.781116   12.0   7.093086  -1.333083  29.600451  (2017, 12)\n",
      "804  343.304731  16.835294    1.0   6.006312  -5.228581  22.588553   (2018, 1)\n",
      "805  278.572392  14.370968    2.0   6.137827 -11.126866  11.971642   (2018, 2)\n",
      "806  357.101570  25.312500    3.0   6.394347  -7.250687  18.948764   (2018, 3)\n",
      "807  375.255561  23.125000    4.0   5.652785   2.984090  37.371362   (2018, 4)\n",
      "808  421.332520  24.476190    5.0   6.625115  13.666265  56.599276   (2018, 5)\n",
      "809  433.026392  27.115942    6.0   8.346118  13.970058  57.146104   (2018, 6)\n",
      "810  363.347531  20.000000    7.0   6.089236  20.188452  68.339213   (2018, 7)\n",
      "811  473.589453  24.724138    8.0   5.978913  16.576768  61.838182   (2018, 8)\n",
      "812  445.613356  23.695238    9.0   6.511075  11.428909  52.572036   (2018, 9)\n",
      "813  405.446437  18.812500   10.0   6.158283   4.383959  39.891125  (2018, 10)\n",
      "814  421.499102  22.871795   11.0   6.546313   1.686590  35.035861  (2018, 11)\n",
      "815  315.282321  26.000000   12.0   6.215385  -4.089957  24.638078  (2018, 12)\n",
      "816  358.878037  27.666667    1.0   6.080845 -10.344629  13.379667   (2019, 1)\n",
      "817  380.936620  31.093333    2.0   8.733899  -3.324484  26.015928   (2019, 2)\n",
      "818  388.804775  26.846154    3.0   8.178588  -2.338365  27.790942   (2019, 3)\n",
      "819  399.197218  21.416667    4.0   6.020893   4.769446  40.585002   (2019, 4)\n",
      "820  426.542763  26.754386    5.0   7.283957   7.926650  46.267970   (2019, 5)\n",
      "821  541.790176  23.243902    6.0   7.209586  15.643554  60.158397   (2019, 6)\n",
      "822  516.388684  18.555556    7.0   6.825789  15.403457  59.726223   (2019, 7)\n",
      "823  487.433531  21.923077    8.0   6.374659  14.214327  57.585788   (2019, 8)\n",
      "824  435.173012  16.500000    9.0   5.931363   8.643044  47.557480   (2019, 9)\n",
      "825  488.700000  13.200000   10.0   6.700000   5.538462  41.969231  (2019, 10)\n",
      "\n",
      "[826 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(hourly_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Now we have aggregated our data based on daily averages and we have a new DataFrame called `hourly_data` where all those aggregated values are stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean for all groups at once**\n",
    "\n",
    "We can also achieve the same result by computing the mean of all columns for all groups in the grouped object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>STATION_NUMBER</th>\n",
       "      <th>TIME</th>\n",
       "      <th>DIR</th>\n",
       "      <th>SPEED</th>\n",
       "      <th>GUST</th>\n",
       "      <th>TEMP_F</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "      <th>TEMP_C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">1917</th>\n",
       "      <th>1</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.917012e+11</td>\n",
       "      <td>226.250000</td>\n",
       "      <td>7.184783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.206522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.996377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.917021e+11</td>\n",
       "      <td>215.945946</td>\n",
       "      <td>11.738095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.416667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.212963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.917032e+11</td>\n",
       "      <td>185.769231</td>\n",
       "      <td>9.032258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.397849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-10.890084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.917042e+11</td>\n",
       "      <td>173.717949</td>\n",
       "      <td>8.611111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.344444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.917052e+11</td>\n",
       "      <td>261.851852</td>\n",
       "      <td>11.591398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.440860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.911589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.917062e+11</td>\n",
       "      <td>211.315789</td>\n",
       "      <td>7.777778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.077778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.820988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.917072e+11</td>\n",
       "      <td>225.487805</td>\n",
       "      <td>6.677419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.903226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.612903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.917082e+11</td>\n",
       "      <td>161.971831</td>\n",
       "      <td>6.150538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.301075</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.500597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.917092e+11</td>\n",
       "      <td>237.027027</td>\n",
       "      <td>9.966667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.377778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.098765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.917102e+11</td>\n",
       "      <td>162.619048</td>\n",
       "      <td>12.784946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.096774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.164875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.917112e+11</td>\n",
       "      <td>199.529412</td>\n",
       "      <td>13.322222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.344444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.364198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.917122e+11</td>\n",
       "      <td>186.956522</td>\n",
       "      <td>8.096774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.655914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.746714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">1918</th>\n",
       "      <th>1</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.918012e+11</td>\n",
       "      <td>213.924051</td>\n",
       "      <td>11.580645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.655914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.968937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.918021e+11</td>\n",
       "      <td>201.285714</td>\n",
       "      <td>8.011905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.940476</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.810847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.918032e+11</td>\n",
       "      <td>229.714286</td>\n",
       "      <td>8.838710</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.365591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.130227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.918042e+11</td>\n",
       "      <td>171.692308</td>\n",
       "      <td>6.244444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.811111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.783951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.918052e+11</td>\n",
       "      <td>213.294118</td>\n",
       "      <td>9.913978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.688172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.160096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.918062e+11</td>\n",
       "      <td>211.666667</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.288889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.938272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.918072e+11</td>\n",
       "      <td>195.810811</td>\n",
       "      <td>7.860215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.774194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.207885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.918082e+11</td>\n",
       "      <td>205.909091</td>\n",
       "      <td>6.182796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.376344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.431302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.918092e+11</td>\n",
       "      <td>190.142857</td>\n",
       "      <td>9.444444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.488889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.604938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.918102e+11</td>\n",
       "      <td>185.925926</td>\n",
       "      <td>9.408602</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.913978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.063321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.918112e+11</td>\n",
       "      <td>189.610390</td>\n",
       "      <td>10.363636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.602273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.445707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.918122e+11</td>\n",
       "      <td>149.746835</td>\n",
       "      <td>10.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.032258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.537634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">1919</th>\n",
       "      <th>1</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.919012e+11</td>\n",
       "      <td>129.589041</td>\n",
       "      <td>6.526882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.096774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.057348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.919021e+11</td>\n",
       "      <td>241.551724</td>\n",
       "      <td>7.702381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.892857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-11.170635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.919032e+11</td>\n",
       "      <td>202.750000</td>\n",
       "      <td>12.688172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.268817</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.072879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.919042e+11</td>\n",
       "      <td>198.030303</td>\n",
       "      <td>9.149425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.988372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.104651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.919052e+11</td>\n",
       "      <td>211.617647</td>\n",
       "      <td>7.827957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.053763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.585424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>1.919062e+11</td>\n",
       "      <td>189.846154</td>\n",
       "      <td>8.275862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.758621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.421456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">2017</th>\n",
       "      <th>5</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.017052e+11</td>\n",
       "      <td>405.082453</td>\n",
       "      <td>7.452416</td>\n",
       "      <td>17.250000</td>\n",
       "      <td>44.388564</td>\n",
       "      <td>50.850000</td>\n",
       "      <td>37.816667</td>\n",
       "      <td>6.882535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.017062e+11</td>\n",
       "      <td>406.696117</td>\n",
       "      <td>7.273412</td>\n",
       "      <td>18.533613</td>\n",
       "      <td>54.419672</td>\n",
       "      <td>60.683333</td>\n",
       "      <td>48.683333</td>\n",
       "      <td>12.455373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.017072e+11</td>\n",
       "      <td>395.458746</td>\n",
       "      <td>5.807256</td>\n",
       "      <td>14.882353</td>\n",
       "      <td>57.986042</td>\n",
       "      <td>63.822581</td>\n",
       "      <td>52.774194</td>\n",
       "      <td>14.436690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.017082e+11</td>\n",
       "      <td>425.223558</td>\n",
       "      <td>5.856287</td>\n",
       "      <td>15.767196</td>\n",
       "      <td>57.368590</td>\n",
       "      <td>62.032787</td>\n",
       "      <td>52.327869</td>\n",
       "      <td>14.093661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.017092e+11</td>\n",
       "      <td>346.161481</td>\n",
       "      <td>5.072941</td>\n",
       "      <td>15.480000</td>\n",
       "      <td>48.388811</td>\n",
       "      <td>52.150000</td>\n",
       "      <td>44.216667</td>\n",
       "      <td>9.104895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.017102e+11</td>\n",
       "      <td>305.445283</td>\n",
       "      <td>6.762276</td>\n",
       "      <td>16.729469</td>\n",
       "      <td>38.473780</td>\n",
       "      <td>40.862069</td>\n",
       "      <td>36.068966</td>\n",
       "      <td>3.596545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.017112e+11</td>\n",
       "      <td>363.135977</td>\n",
       "      <td>6.149673</td>\n",
       "      <td>15.989189</td>\n",
       "      <td>33.404295</td>\n",
       "      <td>34.983333</td>\n",
       "      <td>31.016667</td>\n",
       "      <td>0.780164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.017122e+11</td>\n",
       "      <td>353.396004</td>\n",
       "      <td>7.093086</td>\n",
       "      <td>16.781116</td>\n",
       "      <td>29.600451</td>\n",
       "      <td>31.258065</td>\n",
       "      <td>27.774194</td>\n",
       "      <td>-1.333083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">2018</th>\n",
       "      <th>1</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.018012e+11</td>\n",
       "      <td>343.304731</td>\n",
       "      <td>6.006312</td>\n",
       "      <td>16.835294</td>\n",
       "      <td>22.588553</td>\n",
       "      <td>25.016129</td>\n",
       "      <td>18.806452</td>\n",
       "      <td>-5.228581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.018021e+11</td>\n",
       "      <td>278.572392</td>\n",
       "      <td>6.137827</td>\n",
       "      <td>14.370968</td>\n",
       "      <td>11.971642</td>\n",
       "      <td>16.109091</td>\n",
       "      <td>5.363636</td>\n",
       "      <td>-11.126866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.018032e+11</td>\n",
       "      <td>357.101570</td>\n",
       "      <td>6.394347</td>\n",
       "      <td>25.312500</td>\n",
       "      <td>18.948764</td>\n",
       "      <td>24.096774</td>\n",
       "      <td>10.387097</td>\n",
       "      <td>-7.250687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.018042e+11</td>\n",
       "      <td>375.255561</td>\n",
       "      <td>5.652785</td>\n",
       "      <td>23.125000</td>\n",
       "      <td>37.371362</td>\n",
       "      <td>42.745763</td>\n",
       "      <td>31.796610</td>\n",
       "      <td>2.984090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.018052e+11</td>\n",
       "      <td>421.332520</td>\n",
       "      <td>6.625115</td>\n",
       "      <td>24.476190</td>\n",
       "      <td>56.599276</td>\n",
       "      <td>64.966667</td>\n",
       "      <td>48.166667</td>\n",
       "      <td>13.666265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.018062e+11</td>\n",
       "      <td>433.026392</td>\n",
       "      <td>8.346118</td>\n",
       "      <td>27.115942</td>\n",
       "      <td>57.146104</td>\n",
       "      <td>63.644068</td>\n",
       "      <td>51.067797</td>\n",
       "      <td>13.970058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.018072e+11</td>\n",
       "      <td>363.347531</td>\n",
       "      <td>6.089236</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>68.339213</td>\n",
       "      <td>75.065574</td>\n",
       "      <td>62.081967</td>\n",
       "      <td>20.188452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.018082e+11</td>\n",
       "      <td>473.589453</td>\n",
       "      <td>5.978913</td>\n",
       "      <td>24.724138</td>\n",
       "      <td>61.838182</td>\n",
       "      <td>68.233333</td>\n",
       "      <td>55.900000</td>\n",
       "      <td>16.576768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.018092e+11</td>\n",
       "      <td>445.613356</td>\n",
       "      <td>6.511075</td>\n",
       "      <td>23.695238</td>\n",
       "      <td>52.572036</td>\n",
       "      <td>57.092593</td>\n",
       "      <td>47.796296</td>\n",
       "      <td>11.428909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.018102e+11</td>\n",
       "      <td>405.446437</td>\n",
       "      <td>6.158283</td>\n",
       "      <td>18.812500</td>\n",
       "      <td>39.891125</td>\n",
       "      <td>43.327869</td>\n",
       "      <td>34.524590</td>\n",
       "      <td>4.383959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.018111e+11</td>\n",
       "      <td>421.499102</td>\n",
       "      <td>6.546313</td>\n",
       "      <td>22.871795</td>\n",
       "      <td>35.035861</td>\n",
       "      <td>37.319149</td>\n",
       "      <td>32.382979</td>\n",
       "      <td>1.686590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.018122e+11</td>\n",
       "      <td>315.282321</td>\n",
       "      <td>6.215385</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>24.638078</td>\n",
       "      <td>26.854839</td>\n",
       "      <td>22.048387</td>\n",
       "      <td>-4.089957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">2019</th>\n",
       "      <th>1</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.019012e+11</td>\n",
       "      <td>358.878037</td>\n",
       "      <td>6.080845</td>\n",
       "      <td>27.666667</td>\n",
       "      <td>13.379667</td>\n",
       "      <td>17.516129</td>\n",
       "      <td>8.532258</td>\n",
       "      <td>-10.344629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.019021e+11</td>\n",
       "      <td>380.936620</td>\n",
       "      <td>8.733899</td>\n",
       "      <td>31.093333</td>\n",
       "      <td>26.015928</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>21.089286</td>\n",
       "      <td>-3.324484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.019032e+11</td>\n",
       "      <td>388.804775</td>\n",
       "      <td>8.178588</td>\n",
       "      <td>26.846154</td>\n",
       "      <td>27.790942</td>\n",
       "      <td>31.516129</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>-2.338365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.019042e+11</td>\n",
       "      <td>399.197218</td>\n",
       "      <td>6.020893</td>\n",
       "      <td>21.416667</td>\n",
       "      <td>40.585002</td>\n",
       "      <td>46.916667</td>\n",
       "      <td>33.050000</td>\n",
       "      <td>4.769446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.019052e+11</td>\n",
       "      <td>426.542763</td>\n",
       "      <td>7.283957</td>\n",
       "      <td>26.754386</td>\n",
       "      <td>46.267970</td>\n",
       "      <td>51.870370</td>\n",
       "      <td>41.481481</td>\n",
       "      <td>7.926650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.019062e+11</td>\n",
       "      <td>541.790176</td>\n",
       "      <td>7.209586</td>\n",
       "      <td>23.243902</td>\n",
       "      <td>60.158397</td>\n",
       "      <td>66.966102</td>\n",
       "      <td>54.576271</td>\n",
       "      <td>15.643554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.019072e+11</td>\n",
       "      <td>516.388684</td>\n",
       "      <td>6.825789</td>\n",
       "      <td>18.555556</td>\n",
       "      <td>59.726223</td>\n",
       "      <td>66.967213</td>\n",
       "      <td>53.766667</td>\n",
       "      <td>15.403457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.019082e+11</td>\n",
       "      <td>487.433531</td>\n",
       "      <td>6.374659</td>\n",
       "      <td>21.923077</td>\n",
       "      <td>57.585788</td>\n",
       "      <td>64.177419</td>\n",
       "      <td>52.135593</td>\n",
       "      <td>14.214327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.019092e+11</td>\n",
       "      <td>435.173012</td>\n",
       "      <td>5.931363</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>47.557480</td>\n",
       "      <td>52.650000</td>\n",
       "      <td>43.033333</td>\n",
       "      <td>8.643044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29350.0</td>\n",
       "      <td>2.019100e+11</td>\n",
       "      <td>488.700000</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>13.200000</td>\n",
       "      <td>41.969231</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>5.538462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>826 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            STATION_NUMBER          TIME         DIR      SPEED       GUST  \\\n",
       "YEAR MONTH                                                                   \n",
       "1917 1             29350.0  1.917012e+11  226.250000   7.184783        NaN   \n",
       "     2             29350.0  1.917021e+11  215.945946  11.738095        NaN   \n",
       "     3             29350.0  1.917032e+11  185.769231   9.032258        NaN   \n",
       "     4             29350.0  1.917042e+11  173.717949   8.611111        NaN   \n",
       "     5             29350.0  1.917052e+11  261.851852  11.591398        NaN   \n",
       "     6             29350.0  1.917062e+11  211.315789   7.777778        NaN   \n",
       "     7             29350.0  1.917072e+11  225.487805   6.677419        NaN   \n",
       "     8             29350.0  1.917082e+11  161.971831   6.150538        NaN   \n",
       "     9             29350.0  1.917092e+11  237.027027   9.966667        NaN   \n",
       "     10            29350.0  1.917102e+11  162.619048  12.784946        NaN   \n",
       "     11            29350.0  1.917112e+11  199.529412  13.322222        NaN   \n",
       "     12            29350.0  1.917122e+11  186.956522   8.096774        NaN   \n",
       "1918 1             29350.0  1.918012e+11  213.924051  11.580645        NaN   \n",
       "     2             29350.0  1.918021e+11  201.285714   8.011905        NaN   \n",
       "     3             29350.0  1.918032e+11  229.714286   8.838710        NaN   \n",
       "     4             29350.0  1.918042e+11  171.692308   6.244444        NaN   \n",
       "     5             29350.0  1.918052e+11  213.294118   9.913978        NaN   \n",
       "     6             29350.0  1.918062e+11  211.666667  10.800000        NaN   \n",
       "     7             29350.0  1.918072e+11  195.810811   7.860215        NaN   \n",
       "     8             29350.0  1.918082e+11  205.909091   6.182796        NaN   \n",
       "     9             29350.0  1.918092e+11  190.142857   9.444444        NaN   \n",
       "     10            29350.0  1.918102e+11  185.925926   9.408602        NaN   \n",
       "     11            29350.0  1.918112e+11  189.610390  10.363636        NaN   \n",
       "     12            29350.0  1.918122e+11  149.746835  10.333333        NaN   \n",
       "1919 1             29350.0  1.919012e+11  129.589041   6.526882        NaN   \n",
       "     2             29350.0  1.919021e+11  241.551724   7.702381        NaN   \n",
       "     3             29350.0  1.919032e+11  202.750000  12.688172        NaN   \n",
       "     4             29350.0  1.919042e+11  198.030303   9.149425        NaN   \n",
       "     5             29350.0  1.919052e+11  211.617647   7.827957        NaN   \n",
       "     6             29350.0  1.919062e+11  189.846154   8.275862        NaN   \n",
       "...                    ...           ...         ...        ...        ...   \n",
       "2017 5             29350.0  2.017052e+11  405.082453   7.452416  17.250000   \n",
       "     6             29350.0  2.017062e+11  406.696117   7.273412  18.533613   \n",
       "     7             29350.0  2.017072e+11  395.458746   5.807256  14.882353   \n",
       "     8             29350.0  2.017082e+11  425.223558   5.856287  15.767196   \n",
       "     9             29350.0  2.017092e+11  346.161481   5.072941  15.480000   \n",
       "     10            29350.0  2.017102e+11  305.445283   6.762276  16.729469   \n",
       "     11            29350.0  2.017112e+11  363.135977   6.149673  15.989189   \n",
       "     12            29350.0  2.017122e+11  353.396004   7.093086  16.781116   \n",
       "2018 1             29350.0  2.018012e+11  343.304731   6.006312  16.835294   \n",
       "     2             29350.0  2.018021e+11  278.572392   6.137827  14.370968   \n",
       "     3             29350.0  2.018032e+11  357.101570   6.394347  25.312500   \n",
       "     4             29350.0  2.018042e+11  375.255561   5.652785  23.125000   \n",
       "     5             29350.0  2.018052e+11  421.332520   6.625115  24.476190   \n",
       "     6             29350.0  2.018062e+11  433.026392   8.346118  27.115942   \n",
       "     7             29350.0  2.018072e+11  363.347531   6.089236  20.000000   \n",
       "     8             29350.0  2.018082e+11  473.589453   5.978913  24.724138   \n",
       "     9             29350.0  2.018092e+11  445.613356   6.511075  23.695238   \n",
       "     10            29350.0  2.018102e+11  405.446437   6.158283  18.812500   \n",
       "     11            29350.0  2.018111e+11  421.499102   6.546313  22.871795   \n",
       "     12            29350.0  2.018122e+11  315.282321   6.215385  26.000000   \n",
       "2019 1             29350.0  2.019012e+11  358.878037   6.080845  27.666667   \n",
       "     2             29350.0  2.019021e+11  380.936620   8.733899  31.093333   \n",
       "     3             29350.0  2.019032e+11  388.804775   8.178588  26.846154   \n",
       "     4             29350.0  2.019042e+11  399.197218   6.020893  21.416667   \n",
       "     5             29350.0  2.019052e+11  426.542763   7.283957  26.754386   \n",
       "     6             29350.0  2.019062e+11  541.790176   7.209586  23.243902   \n",
       "     7             29350.0  2.019072e+11  516.388684   6.825789  18.555556   \n",
       "     8             29350.0  2.019082e+11  487.433531   6.374659  21.923077   \n",
       "     9             29350.0  2.019092e+11  435.173012   5.931363  16.500000   \n",
       "     10            29350.0  2.019100e+11  488.700000   6.700000  13.200000   \n",
       "\n",
       "               TEMP_F        MAX        MIN     TEMP_C  \n",
       "YEAR MONTH                                              \n",
       "1917 1      12.206522        NaN        NaN -10.996377  \n",
       "     2       6.416667        NaN        NaN -14.212963  \n",
       "     3      12.397849        NaN        NaN -10.890084  \n",
       "     4      33.344444        NaN        NaN   0.746914  \n",
       "     5      44.440860        NaN        NaN   6.911589  \n",
       "     6      64.077778        NaN        NaN  17.820988  \n",
       "     7      61.903226        NaN        NaN  16.612903  \n",
       "     8      65.301075        NaN        NaN  18.500597  \n",
       "     9      48.377778        NaN        NaN   9.098765  \n",
       "     10     43.096774        NaN        NaN   6.164875  \n",
       "     11     31.344444        NaN        NaN  -0.364198  \n",
       "     12     21.655914        NaN        NaN  -5.746714  \n",
       "1918 1       8.655914        NaN        NaN -12.968937  \n",
       "     2      17.940476        NaN        NaN  -7.810847  \n",
       "     3      26.365591        NaN        NaN  -3.130227  \n",
       "     4      38.811111        NaN        NaN   3.783951  \n",
       "     5      46.688172        NaN        NaN   8.160096  \n",
       "     6      55.288889        NaN        NaN  12.938272  \n",
       "     7      64.774194        NaN        NaN  18.207885  \n",
       "     8      54.376344        NaN        NaN  12.431302  \n",
       "     9      47.488889        NaN        NaN   8.604938  \n",
       "     10     42.913978        NaN        NaN   6.063321  \n",
       "     11     34.602273        NaN        NaN   1.445707  \n",
       "     12     22.032258        NaN        NaN  -5.537634  \n",
       "1919 1      21.096774        NaN        NaN  -6.057348  \n",
       "     2      11.892857        NaN        NaN -11.170635  \n",
       "     3      19.268817        NaN        NaN  -7.072879  \n",
       "     4      33.988372        NaN        NaN   1.104651  \n",
       "     5      51.053763        NaN        NaN  10.585424  \n",
       "     6      59.758621        NaN        NaN  15.421456  \n",
       "...               ...        ...        ...        ...  \n",
       "2017 5      44.388564  50.850000  37.816667   6.882535  \n",
       "     6      54.419672  60.683333  48.683333  12.455373  \n",
       "     7      57.986042  63.822581  52.774194  14.436690  \n",
       "     8      57.368590  62.032787  52.327869  14.093661  \n",
       "     9      48.388811  52.150000  44.216667   9.104895  \n",
       "     10     38.473780  40.862069  36.068966   3.596545  \n",
       "     11     33.404295  34.983333  31.016667   0.780164  \n",
       "     12     29.600451  31.258065  27.774194  -1.333083  \n",
       "2018 1      22.588553  25.016129  18.806452  -5.228581  \n",
       "     2      11.971642  16.109091   5.363636 -11.126866  \n",
       "     3      18.948764  24.096774  10.387097  -7.250687  \n",
       "     4      37.371362  42.745763  31.796610   2.984090  \n",
       "     5      56.599276  64.966667  48.166667  13.666265  \n",
       "     6      57.146104  63.644068  51.067797  13.970058  \n",
       "     7      68.339213  75.065574  62.081967  20.188452  \n",
       "     8      61.838182  68.233333  55.900000  16.576768  \n",
       "     9      52.572036  57.092593  47.796296  11.428909  \n",
       "     10     39.891125  43.327869  34.524590   4.383959  \n",
       "     11     35.035861  37.319149  32.382979   1.686590  \n",
       "     12     24.638078  26.854839  22.048387  -4.089957  \n",
       "2019 1      13.379667  17.516129   8.532258 -10.344629  \n",
       "     2      26.015928  30.000000  21.089286  -3.324484  \n",
       "     3      27.790942  31.516129  22.500000  -2.338365  \n",
       "     4      40.585002  46.916667  33.050000   4.769446  \n",
       "     5      46.267970  51.870370  41.481481   7.926650  \n",
       "     6      60.158397  66.966102  54.576271  15.643554  \n",
       "     7      59.726223  66.967213  53.766667  15.403457  \n",
       "     8      57.585788  64.177419  52.135593  14.214327  \n",
       "     9      47.557480  52.650000  43.033333   8.643044  \n",
       "     10     41.969231  51.000000  49.000000   5.538462  \n",
       "\n",
       "[826 rows x 9 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting warm months\n",
    "\n",
    "Now, we have aggregated our data on monthly level and all we need to do is to check which years had the warmest April temperatures. A simple approach is to select all aprils from the data, group the data and check which group(s) have the highest mean value:\n",
    "\n",
    "- select all records that are from April (regardless of the year):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "aprils = data[data[\"MONTH\"]==4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- take a subset of columns that might contain interesting information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "aprils = aprils[['STATION_NUMBER','TEMP_F', 'TEMP_C','YEAR', 'MONTH']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- group by year and month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = aprils.groupby(by=[\"YEAR\", \"MONTH\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- calculate mean for each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>STATION_NUMBER</th>\n",
       "      <th>TEMP_F</th>\n",
       "      <th>TEMP_C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <th>4</th>\n",
       "      <td>29350</td>\n",
       "      <td>33.344444</td>\n",
       "      <td>0.746914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <th>4</th>\n",
       "      <td>29350</td>\n",
       "      <td>38.811111</td>\n",
       "      <td>3.783951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <th>4</th>\n",
       "      <td>29350</td>\n",
       "      <td>33.988372</td>\n",
       "      <td>1.104651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <th>4</th>\n",
       "      <td>29350</td>\n",
       "      <td>39.277778</td>\n",
       "      <td>4.043210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <th>4</th>\n",
       "      <td>29350</td>\n",
       "      <td>45.144444</td>\n",
       "      <td>7.302469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            STATION_NUMBER     TEMP_F    TEMP_C\n",
       "YEAR MONTH                                     \n",
       "1917 4               29350  33.344444  0.746914\n",
       "1918 4               29350  38.811111  3.783951\n",
       "1919 4               29350  33.988372  1.104651\n",
       "1920 4               29350  39.277778  4.043210\n",
       "1921 4               29350  45.144444  7.302469"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_mean = grouped.mean()\n",
    "monthly_mean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check the highest temperature values (sort the data frame in a descending order):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>STATION_NUMBER</th>\n",
       "      <th>TEMP_F</th>\n",
       "      <th>TEMP_C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <th>4</th>\n",
       "      <td>29350</td>\n",
       "      <td>45.144444</td>\n",
       "      <td>7.302469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <th>4</th>\n",
       "      <td>29350</td>\n",
       "      <td>40.777778</td>\n",
       "      <td>4.876543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <th>4</th>\n",
       "      <td>29350</td>\n",
       "      <td>40.670108</td>\n",
       "      <td>4.816727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <th>4</th>\n",
       "      <td>29350</td>\n",
       "      <td>40.585002</td>\n",
       "      <td>4.769446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <th>4</th>\n",
       "      <td>29350</td>\n",
       "      <td>39.662827</td>\n",
       "      <td>4.257126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <th>4</th>\n",
       "      <td>29350</td>\n",
       "      <td>39.277778</td>\n",
       "      <td>4.043210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <th>4</th>\n",
       "      <td>29350</td>\n",
       "      <td>39.075949</td>\n",
       "      <td>3.931083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <th>4</th>\n",
       "      <td>29350</td>\n",
       "      <td>38.983356</td>\n",
       "      <td>3.879642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <th>4</th>\n",
       "      <td>29350</td>\n",
       "      <td>38.811111</td>\n",
       "      <td>3.783951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <th>4</th>\n",
       "      <td>29350</td>\n",
       "      <td>38.713256</td>\n",
       "      <td>3.729587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            STATION_NUMBER     TEMP_F    TEMP_C\n",
       "YEAR MONTH                                     \n",
       "1921 4               29350  45.144444  7.302469\n",
       "1925 4               29350  40.777778  4.876543\n",
       "2011 4               29350  40.670108  4.816727\n",
       "2019 4               29350  40.585002  4.769446\n",
       "2001 4               29350  39.662827  4.257126\n",
       "1920 4               29350  39.277778  4.043210\n",
       "1990 4               29350  39.075949  3.931083\n",
       "1999 4               29350  38.983356  3.879642\n",
       "1918 4               29350  38.811111  3.783951\n",
       "2007 4               29350  38.713256  3.729587"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monthly_mean.sort_values(by=\"TEMP_C\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did April 2019 rank at this observation station ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeating the data analysis with larger dataset\n",
    "\n",
    "\n",
    "Finally, let's repeat the data analysis steps above for all the available data we have (!!). First, confirm the path to the **folder** where all the input data are located. \n",
    "The idea is, that we will repeat the analysis process for each input file using a (rather long) for-loop! Here are all the main alaysis steps with some additional print out info - all in one long code cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATION NUMBER: 29350\n",
      "NUMBER OF OBSERVATIONS: 559667\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "1921 4               29350  45.144444  7.302469\n",
      "1925 4               29350  40.777778  4.876543\n",
      "2011 4               29350  40.670108  4.816727\n",
      "2019 4               29350  40.585002  4.769446\n",
      "2001 4               29350  39.662827  4.257126\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read selected columns of  data using varying amount of spaces as separator and specifying * characters as NoData values\n",
    "data = pd.read_csv(fp, delim_whitespace=True, usecols=['USAF','YR--MODAHRMN', 'DIR', 'SPD', 'GUS','TEMP', 'MAX', 'MIN'], na_values=['*', '**', '***', '****', '*****', '******'])\n",
    "\n",
    "# Rename the columns\n",
    "new_names = {'USAF':'STATION_NUMBER','YR--MODAHRMN': 'TIME', 'SPD': 'SPEED', 'GUS': 'GUST', 'TEMP':'TEMP_F'}\n",
    "data = data.rename(columns=new_names)\n",
    "\n",
    "#Print info about the current input file:\n",
    "print(\"STATION NUMBER:\", data.at[0,\"STATION_NUMBER\"])\n",
    "print(\"NUMBER OF OBSERVATIONS:\", len(data))\n",
    "\n",
    "# Create column\n",
    "col_name = 'TEMP_C'\n",
    "data[col_name] = None\n",
    "\n",
    "# Convert tempetarues from Fahrenheits to Celsius\n",
    "data[\"TEMP_C\"] = data[\"TEMP_F\"].apply(fahr_to_celsius)\n",
    "\n",
    "# Convert TIME to string \n",
    "data['TIME_STR'] = data['TIME'].astype(str)\n",
    "\n",
    "# Parse year and month\n",
    "data['MONTH'] = data['TIME_STR'].str.slice(start=5, stop=6).astype(int)\n",
    "data['YEAR'] = data['TIME_STR'].str.slice(start=0, stop=4).astype(int)\n",
    "\n",
    "# Extract observations for the months of April \n",
    "aprils = data[data['MONTH']==4]\n",
    "\n",
    "# Take a subset of columns\n",
    "aprils = aprils[['STATION_NUMBER','TEMP_F', 'TEMP_C', 'YEAR', 'MONTH']]\n",
    "\n",
    "# Group by year and month\n",
    "grouped = aprils.groupby(by=[\"YEAR\", \"MONTH\"])\n",
    "\n",
    "# Get mean values for each group\n",
    "monthly_mean = grouped.mean()\n",
    "\n",
    "# Print info\n",
    "print(monthly_mean.sort_values(by=\"TEMP_C\", ascending=False).head(5))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use `glob()` -function from module `glob` to list our input files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(r'C:\\LocalData\\VUOKKHEI\\codes\\Geo-Python\\data\\weather_data\\*txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in the list 15\n",
      "['C:\\\\LocalData\\\\VUOKKHEI\\\\codes\\\\Geo-Python\\\\data\\\\weather_data\\\\028360.txt', 'C:\\\\LocalData\\\\VUOKKHEI\\\\codes\\\\Geo-Python\\\\data\\\\weather_data\\\\028690.txt', 'C:\\\\LocalData\\\\VUOKKHEI\\\\codes\\\\Geo-Python\\\\data\\\\weather_data\\\\028750.txt', 'C:\\\\LocalData\\\\VUOKKHEI\\\\codes\\\\Geo-Python\\\\data\\\\weather_data\\\\028970.txt', 'C:\\\\LocalData\\\\VUOKKHEI\\\\codes\\\\Geo-Python\\\\data\\\\weather_data\\\\029070.txt', 'C:\\\\LocalData\\\\VUOKKHEI\\\\codes\\\\Geo-Python\\\\data\\\\weather_data\\\\029110.txt', 'C:\\\\LocalData\\\\VUOKKHEI\\\\codes\\\\Geo-Python\\\\data\\\\weather_data\\\\029170.txt', 'C:\\\\LocalData\\\\VUOKKHEI\\\\codes\\\\Geo-Python\\\\data\\\\weather_data\\\\029350.txt', 'C:\\\\LocalData\\\\VUOKKHEI\\\\codes\\\\Geo-Python\\\\data\\\\weather_data\\\\029440.txt', 'C:\\\\LocalData\\\\VUOKKHEI\\\\codes\\\\Geo-Python\\\\data\\\\weather_data\\\\029500.txt', 'C:\\\\LocalData\\\\VUOKKHEI\\\\codes\\\\Geo-Python\\\\data\\\\weather_data\\\\029700.txt', 'C:\\\\LocalData\\\\VUOKKHEI\\\\codes\\\\Geo-Python\\\\data\\\\weather_data\\\\029720.txt', 'C:\\\\LocalData\\\\VUOKKHEI\\\\codes\\\\Geo-Python\\\\data\\\\weather_data\\\\029740.txt', 'C:\\\\LocalData\\\\VUOKKHEI\\\\codes\\\\Geo-Python\\\\data\\\\weather_data\\\\029810.txt', 'C:\\\\LocalData\\\\VUOKKHEI\\\\codes\\\\Geo-Python\\\\data\\\\weather_data\\\\029820.txt']\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of files in the list\", len(file_list))\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you should have all the relevant file names in a list, and we can loop over the list using a for-loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\LocalData\\VUOKKHEI\\codes\\Geo-Python\\data\\weather_data\\028360.txt\n",
      "C:\\LocalData\\VUOKKHEI\\codes\\Geo-Python\\data\\weather_data\\028690.txt\n",
      "C:\\LocalData\\VUOKKHEI\\codes\\Geo-Python\\data\\weather_data\\028750.txt\n",
      "C:\\LocalData\\VUOKKHEI\\codes\\Geo-Python\\data\\weather_data\\028970.txt\n",
      "C:\\LocalData\\VUOKKHEI\\codes\\Geo-Python\\data\\weather_data\\029070.txt\n",
      "C:\\LocalData\\VUOKKHEI\\codes\\Geo-Python\\data\\weather_data\\029110.txt\n",
      "C:\\LocalData\\VUOKKHEI\\codes\\Geo-Python\\data\\weather_data\\029170.txt\n",
      "C:\\LocalData\\VUOKKHEI\\codes\\Geo-Python\\data\\weather_data\\029350.txt\n",
      "C:\\LocalData\\VUOKKHEI\\codes\\Geo-Python\\data\\weather_data\\029440.txt\n",
      "C:\\LocalData\\VUOKKHEI\\codes\\Geo-Python\\data\\weather_data\\029500.txt\n",
      "C:\\LocalData\\VUOKKHEI\\codes\\Geo-Python\\data\\weather_data\\029700.txt\n",
      "C:\\LocalData\\VUOKKHEI\\codes\\Geo-Python\\data\\weather_data\\029720.txt\n",
      "C:\\LocalData\\VUOKKHEI\\codes\\Geo-Python\\data\\weather_data\\029740.txt\n",
      "C:\\LocalData\\VUOKKHEI\\codes\\Geo-Python\\data\\weather_data\\029810.txt\n",
      "C:\\LocalData\\VUOKKHEI\\codes\\Geo-Python\\data\\weather_data\\029820.txt\n"
     ]
    }
   ],
   "source": [
    "for fp in file_list:\n",
    "    print(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATION NUMBER: 28360\n",
      "NUMBER OF OBSERVATIONS: 193825\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "1937 4               28360  38.738095  3.743386\n",
      "2011 4               28360  36.699571  2.610873\n",
      "1921 4               28360  36.622222  2.567901\n",
      "2002 4               28360  36.500000  2.500000\n",
      "2019 4               28360  34.979138  1.655076\n",
      "\n",
      "\n",
      "STATION NUMBER: 28690\n",
      "NUMBER OF OBSERVATIONS: 542788\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "2011 4               28690  35.430640  1.905911\n",
      "2019 4               28690  35.215114  1.786174\n",
      "2016 4               28690  35.031103  1.683946\n",
      "1989 4               28690  34.612766  1.451537\n",
      "2002 4               28690  34.279855  1.266586\n",
      "\n",
      "\n",
      "STATION NUMBER: 28750\n",
      "NUMBER OF OBSERVATIONS: 474562\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "1989 4               28750  39.008403  3.893557\n",
      "1983 4               28750  38.758475  3.754708\n",
      "2019 4               28750  38.651599  3.695333\n",
      "2002 4               28750  38.270419  3.483566\n",
      "1994 4               28750  38.145833  3.414352\n",
      "\n",
      "\n",
      "STATION NUMBER: 28970\n",
      "NUMBER OF OBSERVATIONS: 555740\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "1921 4               28970  41.688889  5.382716\n",
      "1999 4               28970  39.073600  3.929778\n",
      "2019 4               28970  38.706456  3.725809\n",
      "1989 4               28970  38.362869  3.534927\n",
      "2011 4               28970  38.094172  3.385651\n",
      "\n",
      "\n",
      "STATION NUMBER: 29070\n",
      "NUMBER OF OBSERVATIONS: 83567\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "2014 4               29070  35.437326  1.909626\n",
      "2015 4               29070  34.437209  1.354005\n",
      "2004 4               29070  34.347032  1.303907\n",
      "2016 4               29070  34.303199  1.279555\n",
      "2008 4               29070  34.241667  1.245370\n",
      "\n",
      "\n",
      "STATION NUMBER: 29110\n",
      "NUMBER OF OBSERVATIONS: 483784\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "1921 4               29110  42.166667  5.648148\n",
      "2004 4               29110  41.682699  5.379277\n",
      "1989 4               29110  41.420168  5.233427\n",
      "1937 4               29110  40.671429  4.817460\n",
      "2019 4               29110  40.636300  4.797945\n",
      "\n",
      "\n",
      "STATION NUMBER: 29170\n",
      "NUMBER OF OBSERVATIONS: 561097\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "1937 4               29170  43.289157  6.271754\n",
      "2019 4               29170  40.666820  4.814900\n",
      "2011 4               29170  40.015962  4.453312\n",
      "2001 4               29170  39.713228  4.285126\n",
      "1906 4               29170  39.688889  4.271605\n",
      "\n",
      "\n",
      "STATION NUMBER: 29350\n",
      "NUMBER OF OBSERVATIONS: 559667\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "1921 4               29350  45.144444  7.302469\n",
      "1925 4               29350  40.777778  4.876543\n",
      "2011 4               29350  40.670108  4.816727\n",
      "2019 4               29350  40.585002  4.769446\n",
      "2001 4               29350  39.662827  4.257126\n",
      "\n",
      "\n",
      "STATION NUMBER: 29440\n",
      "NUMBER OF OBSERVATIONS: 757983\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "2019 4               29440  42.472030  5.817794\n",
      "1990 4               29440  41.918084  5.510047\n",
      "1989 4               29440  41.369647  5.205360\n",
      "2011 4               29440  41.290730  5.161517\n",
      "2004 4               29440  41.249676  5.138709\n",
      "\n",
      "\n",
      "STATION NUMBER: 29500\n",
      "NUMBER OF OBSERVATIONS: 103105\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "2019 4               29500  41.639777  5.355432\n",
      "2008 4               29500  40.838936  4.910520\n",
      "2014 4               29500  40.226415  4.570231\n",
      "2016 4               29500  39.176634  3.987019\n",
      "2011 4               29500  38.647826  3.693237\n",
      "\n",
      "\n",
      "STATION NUMBER: 29700\n",
      "NUMBER OF OBSERVATIONS: 473881\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "1921 4               29700  42.811111  6.006173\n",
      "2000 4               29700  42.375587  5.764215\n",
      "1990 4               29700  42.054167  5.585648\n",
      "2019 4               29700  41.548747  5.304859\n",
      "2004 4               29700  41.493392  5.274107\n",
      "\n",
      "\n",
      "STATION NUMBER: 29720\n",
      "NUMBER OF OBSERVATIONS: 843688\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "2019 4               29720  43.558414  6.421341\n",
      "1990 4               29720  43.313576  6.285320\n",
      "2000 4               29720  42.663169  5.923983\n",
      "2008 4               29720  42.349642  5.749801\n",
      "2004 4               29720  41.903492  5.501940\n",
      "\n",
      "\n",
      "STATION NUMBER: 29740\n",
      "NUMBER OF OBSERVATIONS: 931767\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "2000 4               29740  43.479793  6.377663\n",
      "2019 4               29740  43.464070  6.368928\n",
      "1990 4               29740  43.375078  6.319488\n",
      "2008 4               29740  43.341429  6.300794\n",
      "2011 4               29740  42.750702  5.972612\n",
      "\n",
      "\n",
      "STATION NUMBER: 29810\n",
      "NUMBER OF OBSERVATIONS: 199330\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "1990 4               29810  41.157895  5.087719\n",
      "2019 4               29810  40.783032  4.879462\n",
      "2014 4               29810  40.058036  4.476687\n",
      "2008 4               29810  40.044881  4.469378\n",
      "2016 4               29810  39.270308  4.039060\n",
      "\n",
      "\n",
      "STATION NUMBER: 29820\n",
      "NUMBER OF OBSERVATIONS: 198334\n",
      "            STATION_NUMBER     TEMP_F    TEMP_C\n",
      "YEAR MONTH                                     \n",
      "2019 4               29820  41.182197  5.101221\n",
      "1990 4               29820  41.144681  5.080378\n",
      "2014 4               29820  40.497908  4.721060\n",
      "2008 4               29820  39.941423  4.411901\n",
      "1913 4               29820  39.622222  4.234568\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Repeat the analysis steps for each input file:\n",
    "for fp in file_list:\n",
    "\n",
    "    # Read selected columns of  data using varying amount of spaces as separator and specifying * characters as NoData values\n",
    "    data = pd.read_csv(fp, delim_whitespace=True, usecols=['USAF','YR--MODAHRMN', 'DIR', 'SPD', 'GUS','TEMP', 'MAX', 'MIN'], na_values=['*', '**', '***', '****', '*****', '******'])\n",
    "\n",
    "    # Rename the columns\n",
    "    new_names = {'USAF':'STATION_NUMBER','YR--MODAHRMN': 'TIME', 'SPD': 'SPEED', 'GUS': 'GUST', 'TEMP':'TEMP_F'}\n",
    "    data = data.rename(columns=new_names)\n",
    "\n",
    "    #Print info about the current input file:\n",
    "    print(\"STATION NUMBER:\", data.at[0,\"STATION_NUMBER\"])\n",
    "    print(\"NUMBER OF OBSERVATIONS:\", len(data))\n",
    "\n",
    "    # Create column\n",
    "    col_name = 'TEMP_C'\n",
    "    data[col_name] = None\n",
    "\n",
    "    # Convert tempetarues from Fahrenheits to Celsius\n",
    "    data[\"TEMP_C\"] = data[\"TEMP_F\"].apply(fahr_to_celsius)\n",
    "\n",
    "    # Convert TIME to string \n",
    "    data['TIME_STR'] = data['TIME'].astype(str)\n",
    "\n",
    "    # Parse year and month\n",
    "    data['MONTH'] = data['TIME_STR'].str.slice(start=5, stop=6).astype(int)\n",
    "    data['YEAR'] = data['TIME_STR'].str.slice(start=0, stop=4).astype(int)\n",
    "\n",
    "    # Extract observations for the months of April \n",
    "    aprils = data[data['MONTH']==4]\n",
    "\n",
    "    # Take a subset of columns\n",
    "    aprils = aprils[['STATION_NUMBER','TEMP_F', 'TEMP_C', 'YEAR', 'MONTH']]\n",
    "\n",
    "    # Group by year and month\n",
    "    grouped = aprils.groupby(by=[\"YEAR\", \"MONTH\"])\n",
    "\n",
    "    # Get mean values for each group\n",
    "    monthly_mean = grouped.mean()\n",
    "\n",
    "    # Print info\n",
    "    print(monthly_mean.sort_values(by=\"TEMP_C\", ascending=False).head(5))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about now, how did April 2019 rank across different stations?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
